[{"slug":"2020-add-sitemap-to-phoenix-elixir-project","category":"blog","title":"Add a sitemap to a Phoenix project","description":"A review of writing my first integration and what I wish I'd known","tags":["sitemap","phoenix"],"body":"\nThis explains what I had to do in my own Phoenix project to render a `/sitemap.xml` file for Google to more effectively crawl my website.\n\nFirst I had to make sure all of the content I wanted crawled existed under the URLs I expected and then used a [sitemap generator](https://www.mysitemapgenerator.com/) to create the sitemap.xml file. I just had to enter the live URL of my project and it produced the downloadable file.\n\nAfter that, in my app, I added a `root.xml.eex` template in `templates/layouts` so my app has a place to find root xml rendering. File contents:\n`/lib/dev_decks_web/templates/layout/root.xml.eex`\n```elixir\n<%= @inner_content %>\n```\n\nFrom there I used the code I had written in my app for handling static pages to add the route, controller action and sitemap template. The contents of the sitemap template are a copy and paste from the sitemap generator file:\n\n<h3>Route</h3>\n`/lib/dev_decks_web/router.ex`\n```elixir\nscope \"/\", DevDecksWeb do\n  pipe_through :browser\n\n  get \"/sitemap.xml\", PageController, :sitemap\nend\n```\n\n<h3>Controller</h3>\n`/lib/dev_decks_web/controllers/page_controller.ex`\n```elixir\ndefmodule DevDecksWeb.PageController do\n  use DevDecksWeb, :controller\n\n  def sitemap(conn, _params) do\n    conn\n    |> put_resp_content_type(\"text/xml\")\n    |> render(\"sitemap.xml\")\n  end\nend\n```\n\n<h3>Template</h3>\n`/lib/dev_decks_web/templates/page/sitemap.xml.eex`\n```elixir\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n\t\t<urlset xmlns=\"http://www.sitemaps.org/schemas/sitemap/0.9\">\n<url>\n\t<loc>https://tinytechtuts.com/</loc>\n\t<lastmod>2020-12-22T18:58:52+01:00</lastmod>\n\t<priority>1.0</priority>\n</url>\n\n....\n```\n\nAfter that I was able to route to `/sitemap.xml` in the browser and see the contents of my XML file and Google has since been able to do the same.\n"},{"slug":"2020-autoloading-eager-loading","category":"blog","title":"When does a Rails application load and read my code?","description":"Learn about auto loading and eager loading rails classes","tags":["rails"],"body":"\n<h3>Load</h3>\nTo begin executing our programs, Rails needs to have access to our ruby code. To accomplish this the application server loads the program code into it's memory for storage during execution. From there our server's processor (it's CPU) can access the code quickly and begin running our program to accomplish some end user goal.\n\nWhen it loads this code into memory is different based on which environment the code is running in. In a Rails dev or test environment our code is autoloaded, which means it is loaded into memory when it is needed as the program is executing.\n\nIn a staging or production environment our code is eager loaded. This means when our server starts up it loads the code (the *.rb files and their classes, global variables, etc.) into memory right away. This way when someone uses our application in one of these environments they will have faster response times because the code is already accessible from memory.\n\n<h3>Read</h3>\nOur code is read at run-time, aka when our program is executing, not to be confused with a run-time which is a type of software programmers use. At runtime our code is read by the server and eventually responds to the user with either requested data or an error.\n\n<br />\nResources I found useful when building this:\nhttps://stackoverflow.com/questions/27833647/whats-the-impact-of-eager-load-true\n\n"},{"slug":"2020-darkmodejs-tips","category":"blog","title":"3 tips for using Darkmode.js in your application","description":"Learn some tips on how to more effectively use Darkmode.js","tags":["javascript"],"body":"\nThis post assumes you are using [Darkmode.js](https://darkmodejs.learn.uno/) as an npm package. It is also only a list of quick tips I wish I had when first getting started with the library and not a full tutorial.\n\n<h3>1) How to override a default Darkmode style</h3>\nI needed this specifically for elements that exist outside of the normal DOM because Darkmode.js does not apply styles to them. These are elements positioned absolute or fixed, which for my example was the footer. To apply styles to the footer for darkmode you have to specify the css within the `.darkmode--activated` class.\n\n```css\n.darkmode--activated footer {\n  div {\n    color: white;\n  }\n}\n```\n\n<h3>2) How to ignore an element when Darkmode is activated</h3>\nAdd a class of `darkmode-ignore` to the element you'd like to avoid being affected by the package. For DevDecks that was the color palette on the settings page. I wanted those colors to be constant and not affected by the package.\n```html\n<div class=\"darkmode-ignore color-item <%= if @settings[\"color\"] == \"#020887\" do \"selected\" end %>\" id=\"020887\" style=\"--color: #020887\">\n  <div class=\"setting-color\" style=\"--color: #020887\"></div><span>Blue</span>\n</div>\n```\n\n<h3>3) How to toggle between a light and dark image</h3>\nIf changing the color of your image is not feasible through CSS you might need to change the image entirely for a lighter one when darkmode is enabled. The CSS below assumes `#logo` is an image tag and it changes the url to point to the source of the white image when darkmode is enabled:\n```css\n.darkmode--activated #logo {\n  content: url(\"/images/logo_white.svg\");\n}\n```\nAnd then have another CSS declaration for when darkmode is not enabled which sets the image source back to the default value:\n```css\n#logo {\n  content: url(\"/images/logo.svg\");\n}\n```\n\n\n"},{"slug":"2020-gigalixir-deploy-no-cache","category":"blog","title":"Deploying a clean build to Gigalixir","description":"Update elixir version with Gigalixir","tags":["gigalixir","elixir"],"body":"\nI needed to update the Elixir version for the DevDecks app, for production app builds I use Gigalixir and Mix releases. To get version updated I had to first update the elixir_version value in `elixir_buildpack.config` and add an always_rebuild value set to `true`.\n\n```txt\nelixir_buildpack.config\n\nalways_rebuild=true\n\nelixir_version=1.10.4\nerlang_version=22.3.1\n```\n\nThen when I pushed this change to Gigalixir I added an extra http header of `GIGALIXIR-CLEAN: true`. Which on the on the command line, which looks like:\n```\ngit -c http.extraheader=\"GIGALIXIR-CLEAN: true\" push gigalixir master\n```\n\nThis was in place of the command I run otherwise which is `git push gigalixir master` if when doing a regular deploy.\n\nAfter making these changes I the Elixir version for DevDecks was updated."},{"slug":"2020-iterate-collection-with-index-in-elixir-template","category":"blog","title":"Iterate a collection with indexes in Phoenix template","description":"How to iterate a collection with indexes in Phoenix template","tags":["elixir","phoenix"],"body":"\nWhen I started looking into this I was already iterating over a collection with an Elixir comprehension like this:\n\n```elixir\n<%= for card <- @cards do %>\n  <div>\n    # card markup without indexes\n  </div>\n<% end %>\n```\n\nI thought I might just be able to add an index to the comprehension but that's not how [comprehensions work](https://elixir-lang.org/getting-started/comprehensions.html).\n\nInstead I needed to pipe the collection into the `Enum.with_index` function and then pipe the result of that into the `Enum.map` function like so:\n\n```elixir\n<%= @cards |> Enum.with_index |> Enum.map(fn({card, index}) ->  %>\n  <div>\n    <div id=\"card\" style=\"--color: <%= @settings[\"color\"] %>; ; display: <%= if index == @card_index do \"flex\" else \"none\" end %>\">\n    </div>\n  </div>\n<% end) %>\n```\n\nThe result of the map call the entire collection of generated markup, you can see where I use the index value to determine the display property for each card.\n\n<br />\nResources I found useful when building this:\n- https://programming-idioms.org/idiom/7/iterate-over-list-indexes-and-values/920/elixir"},{"slug":"2020-liveview-conn-vs-socket","category":"blog","title":"Route static paths across LiveView and App templates","description":"Learn how to route static paths across LiveView and App code","tags":["liveview","elixir"],"body":"\n*TLDR: Use your Endpoint module directly to route static paths in either eex or leex templates.*\n\nWhen using Phoenix LiveView I needed to share navigation html across two layout files:\n1) `app.html.eex`\n2) `live.html.leex`\n\nPhoenix provides a file to do this out of the box which will render markup for both app and live templates:\n`root.html.leex`\n\nThe issue I had was static routing to images. This is due the Router module using either Plug `@conn` and LiveView's `@socket` for connections depending on the file.\n\n<div>At first I had two nav's for each file:</div>\n\n```html\n<!-- app.html.eex -->\n\n<nav id=\"nav\">\n  <a href=\"/\"><img class=\"logo\" src=\"<%= Routes.static_path(@conn, \"/images/logo.svg\")%>\" /></a>\n\n  <!-- rest of nav -->\n</nav>\n```\n\n```html\n<!-- live.html.leex -->\n\n<nav id=\"nav\">\n  <a href=\"/\"><img class=\"logo\" src=\"<%= Routes.static_path(@socket, \"/images/logo.svg\")%>\" /></a>\n\n  <!-- rest of nav -->\n</nav>\n```\n\nTo update this I found that if you use the Phoenix Endpoint module instead of individual connection objects to route to static assets you only need one nav located in `root.html.leex`:\n\n```html\n<!-- root.html.leex -->\n\n<nav id=\"nav\">\n  <a href=\"/\"><img class=\"logo\" src=\"<%= Routes.static_path(DevDecksWeb.Endpoint, \"/images/logo.svg\")%>\" /></a>\n\n  <!-- rest of nav -->\n</nav>\n```"},{"slug":"2020-nimblepub-images","category":"blog","title":"How to use images in NimblePublisher posts","description":"Learn how to use images in NimblePublisher blog posts","tags":["cms","elixir"],"body":"\nAs of this writing I am using Phoenix and NimblePublisher to write these posts. To load images in these posts I use image tags that point to this path in my application directory:\n`my_app_name/assets/static/images/blog/:year/:month/:image_file`.\n\nAnd the image tag in the *.md posts will use the relative path to the image file and that looks like:\n`<image src=\"/images/blog/my_picture.png\" alt=\"my_picture\" />`.\n\nOr using markdown:\n`![alt my_picture](/images/blog/2020/december/my_picture.jpg)`\n\nExplicit example in a post:\n```\n%{\n  title: \"How to add post scheduling to NimblePublisher\",\n  description: \"Learn how to schedule posts using NimblePublisher\",\n  tags: ~w(elixir Phoenix CMS),\n}\n---\n<image src=\"/images/blog/my_picture.png\" alt=\"my_picture\" />\n```\nIt took me some time to get the routing right for images when I was building this CMS. I hope you found this to be useful.\n"},{"slug":"2020-seo-guide","category":"blog","title":"Lessons learned about on-page SEO for developers from a developer in 2021","description":"Lessons learned about SEO for my elixir web app","tags":["seo","phoenix"],"body":"\n*I'm writing this at the end of December 2020 going into 2021, for anyone with a keen eye.\n\n<h3>1) Have one H1 heading tag at the top of each page.</h3>\n\nThis is important is Google's eyes because it gives more detail about the content that will follow on the remainder of the page. There's advice on the web not to have more than one <h1> tag on each page and I follow that as well.\n\n<h3>2) Add unique meta tags and page titles for each page.</h3>\n\nI wrote a post about how to accomplish this in a Phoenix app here [here](https://tinytechtuts.com/2020-seo-in-elixir/).\n\n<h3>3) More content, fewer pages.</h3>\n\nQuery parameters were a [bad choice](https://www.searchenginejournal.com/technical-seo/url-parameter-handling).\n\nI made the decision to add the question text for each decks card as a query parameter, and update that query parameter each time you changed to a new card in the app. I thought there were two benefits here:\n1.  If someone came to DevDecks from a link with the query parameter you could go right to that question in the deck. Here's a no-longer-working example:\n```html\nhttps://tinytechtuts.com/decks/52e4f834-a0a3-4c01-8ffb-c581d37de207/card?cardContent=How%20does%20a%20DOM/Client%20side%20XSS%20attack%20work?\n```\n2. I thought it might help with SEO. My thinking was that if the url content matched what a user was searching for that my content would get an edge over the same quality content without the query param. The problem is each question and answer is probably not enough content for Google to consider the page as quality content and Google identifies pages as unique if the URL is unique, including query params. I got rid of the query params for each card.\n\nAdding to the negative impacts, each flashcard had the same meta tags as the rest of the flashcards in a deck, so Google likely was viewing this as duplicate content which is negative points on the Google scale. The change's I made here were:\n\n1. Removed the query parameter entirely.\n2. Added more content to the page by showing all cards in the deck on each page and now use CSS to hide and show cards.\n\nThe content change has the negative affect of slowing down page loads to get the extra data, thus making the page less responsive, which is another SEO metric. However it will not be so slow as to deem the page unresponsive.\n\n<h3>4) Don't route to pages using query parameters</h3>\n\nI did this as a solution for static page routing in LiveView, which looked like this:\n`/pages?page=about`\n\nThis kept my code dry and I could keep all pages on my website in LiveView instead of using a mix of Websockets and REST.\n\nThe issue here was that these all had the same page title and meta tags. I could have written a proxy/conditional to update these values based on the parameter but ulimately I chose to move static pages back to MVC, the below are the controller actions with the dynamic SEO attributes for each view that will be rendered:\n\n```elixir\ndefmodule DevDecksWeb.PageController do\n  use DevDecksWeb, :controller\n\n  def svg_tool(conn, _params) do\n    meta_attrs = [\n      %{name: \"keywords\", content: \"svg tool, svg filter list, svg image filters\"},\n      %{name: \"description\", content: \"A tool for helping you change the color of SVG images.\"}\n    ]\n\n    render(conn, \"svg_tool.html\", meta_attrs: meta_attrs, page_title: \"DevDecks · SVG Color Changer\")\n  end\n\n  def about(conn, _params) do\n    meta_attrs = [\n      %{name: \"keywords\", content: \"About, DevDecks\"},\n      %{name: \"description\", content: \"The about page for the DevDecks website.\"}\n    ]\n\n    render(conn, \"about.html\", meta_attrs: meta_attrs, page_title: \"DevDecks · About\")\n  end\n\n  def attributions(conn, _params) do\n    meta_attrs = [\n      %{name: \"keywords\", content: \"attributions, DevDecks\"},\n      %{name: \"description\", content: \"The attributions page for the DevDecks website.\"}\n    ]\n\n    render(conn, \"attributions.html\", meta_attrs: meta_attrs, page_title: \"DevDecks · attributions\")\n  end\nend\n```\n\n<h3>5) Add a sitemap.xml file</h3>\n\nI also added a sitemap for Google to be able to craw my site more easily. I added a guide for that [here](https://tinytechtuts.com/2020-add-sitemap-to-phoenix-elixir-project/).\n\nAfter creating the sitemap I followed the steps outlined [here](https://hdwebpros.com/blog/how-often-does-google-update-its-search-results.html#:~:text=How%20Long%20Will%20It%20Take,four%20days%20and%20four%20weeks) and added Google Analytics, created a new account with Google's Search Console, and submitted [my sitemap](https://tinytechtuts.com/sitemap.xml) for reindexing by providing a link to my `sitemap.xml` page in the search console. I will do this periodically as my site's content grows.\n\nThat is all I have for now. I will be updating the post for any other changes I make to DevDecks on this topic.\n\n<br />\nResources I found useful when building this:\n- https://www.searchenginejournal.com/technical-seo/url-parameter-handling/#close\n- https://neilpatel.com/blog/the-on-page-seo-cheat-sheet/\n- https://hdwebpros.com/blog/how-often-does-google-update-its-search-results.html"},{"slug":"2020-seo-in-elixir","category":"blog","title":"On-page SEO meta-tags and page-title for Phoenix applications","description":"Learn how to make SEO more dynamic in a Phoenix App","tags":["elixir"],"body":"\n*This post assumes you are using server generated HTML templates in your Elixir application.\n\nTwo important elements of on-page SEO are the title and meta tags used on your each of your pages. This data describes what the content on your page pertains to and allows a search engine to more accurately index your website. This post shows you how to dynamically add these tags to your application.\n\nAdd this data to pages you want Google to be aware of. For DevDecks as of Dec 2020 those are Posts and Decks. In your layout view add `meta_tags` and `meta_tag` methods that will iterate over a list of meta_tags and will output the content for each tag.\n\n```elixir\nlayout_view.ex\n\ndefmodule DevDecksWeb.LayoutView do\n  use DevDecksWeb, :view\n\n  def meta_tags(attrs_list) do\n    Enum.map(attrs_list, &meta_tag/1)\n  end\n\n  def meta_tag(attrs) do\n    tag(:meta, Enum.into(attrs, []))\n  end\nend\n```\n\nIn the root layout file (`root.html.leex`) call the meta_tags function if meta_tags are provided to assigns. Call `assigns[:meta_attrs]` directly here instead of `@meta_attrs` so that if `@meta_attrs` is not provided the application does not error and stop execution. Also check for a page_title the same way right below or display a default title:\n```elixir\n<%= if assigns[:meta_attrs], do: meta_tags(assigns[:meta_attrs]) %>\n<%= live_title_tag assigns[:page_title] || \"DevDecks · Software Development Flashcards\" %>\n```\n\nAnd then if the template is generated from LiveView add page_title and meta_tags to assigns in mount like so:\n```elixir\ndef mount(_params, _session, socket) do\n  meta_attrs = [\n    %{name: \"keywords\", content: \"tech study flashcards, full list study cards\"},\n    %{name: \"description\", content: \"Software Development Study Flashcards\"}\n  ]\n\n  {:ok, assign(socket, meta_attrs: meta_attrs, page_title: \"DevDecks · Software Development Study Flashcards\")}\nend\n```\n\nAnd if you're using an MVC approach add it to your controller that is generating the template:\n```elixir\ndef index(conn, _params) do\n  meta_attrs = [\n    %{name: \"keywords\", content: \"tech blog, tech writing\"},\n    %{name: \"description\", content: \"A tech blog by DevDecks\"}\n  ]\n\n  render(conn, \"index.html\", meta_attrs: meta_attrs, page_title: \"DevDecks · The tech blog by DevDecks\")\nend\n```\n\nOne more thing to note is that when you are adding these tags you want to keep them in the `<head>` of the HTML doc because if they are in the body some technologies won't notice them, for example social media OpenGraph tags won't be read if they are not in the head of the document.\n\n<br />\nResources I found useful when building this:\n- https://elixirforum.com/t/how-to-create-dynamic-meta-tag-in-phoenix/15286\n- https://stackoverflow.com/questions/1447842/what-happens-if-the-meta-tags-are-present-in-the-document-body\n"},{"slug":"2021-301-vs-302-redirects-phoenix","category":"blog","title":"301 vs 302 redirects using Phoenix","description":"redirects using Phoenix","tags":["elixir","phoenix"],"body":"\nIf you need a temporary redirect aka `302` using the `redirect/2` function:\n```\ndef redirect_show(conn, %{\"id\" => id}) do\n  conn\n  |> redirect(to: Routes.blog_path(conn, :show, id))\nend\n```\n\nIf you are permanently moving a page and want to indicate that to mother Google and the rest of the web you need to first execute the `put_status/1` function and then pipe to `redirect/2`.\n\n```\ndef redirect_show(conn, %{\"id\" => id}) do\n  conn\n  |> put_status(:moved_permanently)\n  |> redirect(to: Routes.blog_path(conn, :show, id))\nend\n```\n\nCheck out other Phoenix posts:\n- [Route static paths across LiveView and App templates](https://tinytechtuts.com/2020-liveview-conn-vs-socket/)\n- [On-page SEO meta-tags and page-title for Phoenix applications](https://tinytechtuts.com/2020-seo-in-elixir/)"},{"slug":"2021-Guarav-Sen-API-Design-notes","category":"blog","title":"API Design Notes","description":"api design notes from Guarav Sen tutorial","tags":["apis"],"body":"\n*These notes are not intended to be a summary of the tutorial, for deeper understanding of what I've written watch the tutorial linked below.\n\n[Tutorial link](https://www.youtube.com/watch?v=_YlYuNMTCc8)\n\n<h2>Documentation</h2>\n- API documentation should show clients/consumers how to use your service, not how your code works.\n- Documentation list: Define function/endpoint, define parameters, define possible errors.\n\n<h2>Errors</h2>\n- Caution: sometimes API's return a generic error for anything that goes wrong when calling their system. This is not a good practice but is worth knowing about as an API consumer.\n- Caution: sometimes an API dev will build in too much error handling. This is also not recommended and can make an API overly complex for maintainers.\n- Idea: when handling errors ask yourself if the client/consumer should be able to decipher this without your system telling them explicitly. An example might be the client passes in an integer to your API instead of a string, a client could figure that out instead of you adding additional code.\n\n<h2>Side Effects</h2>\n- A function/endpoint shouldn't do more than the name suggests, ex `setAdmins` should only set admins. If it needs to do more than just set the admins, like create a group, then either name it properly to `setAdminsAndGroups`. Or see if they can be broken into separate calls where first you create a group and then set the group as admins.\n\n<h2>API Design Decision Scenario</h2>\n- If an a client asks for new functionality to check that a resource collection on the client side is the same as the resource collection on the server, there are a few options\n1) Accept a new parameter to an existing method that takes in the collection as a parameter that the client passes to your service.\n2) An a new method that get's the collection based on some identifier. The downside here is more HTTP/IO requests.\n3) Add a new method to that accepts the collection as a parameter. *This seems like the best option.\n\n<h2>Large Responses</h2>\n- Do not make an API response too large in hopes you will not need to make many changes to it later. It's confusing to the consumer deciphering your API and heavy on the network.\n- If an API is requesting all records of a particular resource, break down using either pagination or fragmentation.\n\n<h2>Data Consistency</h2>\n- Scenario: one user makes a query for a list of records while another user is posting to that list of records at the same time, you need to decide if that matters for your system or not. If it does matter than the various calls to your API will be less efficient.\n- If you cache resources you need to decide when/if that cache should expire based on new resources added. You may want to cache records if your DB load is heavy.\n\n\n<h2>Other Notes</h2>\n- Return an object instead of a list of objects as a response. This makes that API more extensible if additional data needs to be added later on. Instead of needing to update the list of objects, you can add a new key.\n- Web API URLs can take the format of: myapi.com/model/function/v1 and when the function needs to change, you can publish a v2.\n"},{"slug":"2021-adding-view-helpers-to-rails","category":"blog","title":"Add view helpers to a Rails application, globally and locally","description":"rails view helpers local global","tags":["rails"],"body":"\nBy the end of this post you will have a better idea of how to handle application data processing in Rails views.\n\nFor the first example, lets say you wanted to translate text in your footer like so:\n\n```\n<!-- _footer.html.erb -->\n\n<footer>\n  <div><%= translate(\"copyright\") %></div>\n  <div><%= translate(\"privacy-policy\") %></div>\n  <div><%= translate(\"faq\") %></div>\n</footer>\n```\n\nSince your footer will likely be a partial used across most if not all templates rendered by a controller you can add the `translate` view helper method used above to `application_controller.rb`. This will make the method accessible from any other controller and also if you invoke `helper_method` it will also be available across all view templates. This is what that would look like:\n\n```ruby\n# application_controller.rb\n\nhelper_method :translate\ndef translate(text)\n  # handle translation behavior\nend\n```\n\nIf you only wanted the method available in a specific template, you can add the method to the controller that renders that template:\n\n```ruby\n# users_controller.rb\n\nhelper_method :translate_user_details\ndef translate_user_details(text)\n  # handle translation behavior\nend\n```\n\nAfter creating these functions and their helper methods they can be invoked in their respective views as shown in the `_footer.html.erb` example above."},{"slug":"2021-apply-css-to-all-but-last-child","category":"blog","title":"Apply CSS styling to all but last selected element","description":"styling all but last element using css","tags":["css"],"body":"\nTo accomplish this first apply the styles to all of the elements in the selection. Laster we will remove the styles from the last element. In my example I am adding text after all links:\n```\na::after {\n  content: \" | \";\n}\n```\n\nFrom there we can get the last element in the selection using the `last-of-type` selector to update the previously applied styles like so:\n```\na:last-of-type::after {\n  content: \"\";\n}\n```\n\nThe markup looks like this in the browser:\n`Link One | Link Two | Link Three | Link Four`\n\nAnd you can see the last element did not get the `content: \" | \"` applied to it.\n"},{"slug":"2021-apply-css-to-only-first-two-elements","category":"blog","title":"Apply CSS styling to only first two elements","description":"styling first two elements using css","tags":["css"],"body":"\nThis requires the use of the `:nth-child` selector, which needs to be passed an argument of `-n+2`:\n```\na:nth-child(-n+2)::after {\n  content: \" | \";\n}\n```\n\nIn my example I am applying text after the first two links in the selector, which looks like this when rendered:\n`Link One | Link Two | Link Three`\n\nThe problem is when you add a fourth link there exists a style bug because the | is only applied to the first two elements:\n`Link One | Link Two | Link Three Link Four`\n\nI added my solution for this [here](https://tinytechtuts.com/2021-apply-css-to-all-but-last-child/).\n"},{"slug":"2021-beam-elixir-process-summary","category":"blog","title":"An series of introductions to Elixir Processes","description":"elixir processes introductions","tags":["elixir"],"body":"\nRecently I took some time to try and get a better grasp on processes in Elixir. I attempted to distill that knowledge into 5 blog posts that you and I can revisit anytime to refresh our memory.\n\n1) [BEAM/Elixir processes for web programmers](https://tinytechtuts.com/2021-beam-elixir-processes-explained/)\n\nIn this post I attempt to explain processes by defining prerequisite technical concepts needed to understand processes. From there I walk through `Process` concepts themselves, using examples where possible.\n\n2) [BEAM/Elixir 'let it crash': what it does and does not mean](https://tinytechtuts.com/2021-let-it-crash-explained/)\n\nRegularly I would come across the Elixir axiom \"let it crash\" and be uncertain of what was meant by it. Here I try to unpack that using examples of what it does and does not mean.\n\n3) [Do BEAM/Elixir processes provide concurrency or enable parallelism?](https://tinytechtuts.com/2021-elixir-processes-concurrency-and-parallelism/)\n\nThe terms concurrency and parallelism are often confused for one other in discussion and I wanted to make sure I had a general understanding of the two so I wrote a brief post of what each means in relation to the BEAM ecosystem.\n\n4) [An introduction to BEAM/Elixir processes in Phoenix](https://tinytechtuts.com/2021-introduction-to-elixir-processes-in-phoenix/)\n\nI mostly program for the web and Phoenix is the web application framework for Elixir, therefore I wanted to have a general understanding of how processes worked within Phoenix. This post breaks down what I learned through an example web request.\n\n5) [Elixir process module cheatsheet](https://tinytechtuts.com/2021-elixir-process-module-cheatsheet/)\n\nThis is a brief overview of some of the `Process` module functions and `Kernel` functions for working with processes.\n"},{"slug":"2021-beam-elixir-processes-explained","category":"blog","title":"BEAM/Elixir processes for web programmers","description":"overview of beam processes elixir","tags":["elixir"],"body":"\nTo start I think it's useful to define a few concepts:\n\nElixir ecosystem concepts:\n1) BEAM is a virtual machine that powers concurrent functional languages like Erlang and Elixir.\n2) Erlang is a programming language that is supported by the BEAM VM.\n3) Elixir is a programming language built on top of Erlang designed for developer efficiency.\n\nComputer processing concepts:\n4) CPU core is a smaller CPU/processor built into a larger CPU/processor. They were created to more efficiently handle processes and provide parallel execution (executing multiple functions at the same time).\n5) An OS process is a running application/program, like the BEAM VM or a web browser running on your computer. OS processes are created when you start these applications.\n6) An OS thread(s) can be used by an OS process to help it complete different tasks, it is lighter than an OS process in terms of resources and startup and cleanup. They are employed from OS processes.\n7) BEAM processes are like OS threads in their purpose but are even lighter and more efficient. They are employed from OS threads.\n\nThe BEAM VM achieves concurrency by running many small BEAM processes to handle different system functions, many being in the millions. These processes are independent of each other in terms of memory, execution context, and garbage collection.\n\nThe BEAM VM is a running OS process and within the VM is a queue of BEAM processes waiting to be executed. BEAM defers the handling of the processes to schedulers, by default there is one scheduler employed for each core on the server. These schedulers pull processes from the queue and execute it for a short period of time and then puts the process back in the queue, pulls in a new process for execution and does this over and over again.\n\nEach process gets executed for less than a millisecond before it is put back into the queue. The reason for this is so CPU intensive functions do not block the execution of other processes. The example given by [Sasa Juric](https://www.youtube.com/watch?v=-bCkha6U70o) is a function that calculates the sum of a large range of numbers like 1..1000000000000. This calculation would take a noticeable amount of time to return and we don't want it to block other processes from execution, hence the reason for constant context switching.\n\nIn a web based Elixir system different processes are used to handle various tasks like:\n1) HTTP connections\n2) Database connections\n3) PubSub transactions\n\nFor each new HTTP connection a new process is issued and if that process fails due to a runtime execution error, or if a third party API is down, the rest of the processes will continue to function normally.\n\nThis provides fault tolerance and high availability to your application, because a single error will not propagate to other users of your system. With some VM's other than BEAM you need to handle more issues through written code because multiple requests are handled by the same execution context to achieve concurrency and if one of those requests error then all of the requests in that execution context will fail along with it.\n\nMore Elixir process posts:\n[Let it crash explained](https://tinytechtuts.com/2021-let-it-crash-explained/),\n[Process module cheatsheet](https://tinytechtuts.com/2021-elixir-process-module-cheatsheet/),\n[Processes in phoenix](https://tinytechtuts.com/2021-introduction-to-elixir-processes-in-phoenix/),\n[Processes and concurrency](https://tinytechtuts.com/2021-elixir-processes-concurrency-and-parallelism/)\n\nOther useful resources:\n- https://elixirforum.com/t/understanding-the-advantages-of-let-it-crash-term/9748\n- https://www.youtube.com/watch?v=-bCkha6U70o"},{"slug":"2021-change-ecto-timestamps-from-inserted-at","category":"blog","title":"Change Ecto timestamps from inserted_at to created_at","description":"learn how to update Ecto timestamps","tags":["ecto","elixir"],"body":"\nWhen you generate a schema or migration that will create database tables your Elixir app will utilize there will usually be a call to `timestamps/0` in the newly generated file, if not you can add it manually. \n\nThe `timestamps` function will add timestamp columns to your table to track when records are created and updated. By default this will create columns `intserted_at` and `updated_at`, but you can override these column names to suit your needs by passing a keyword list argument containing the column you want to override and the column that should take its place. Example:\n\n```\n  def up do\n    create table(\"weather\") do\n      add :city,    :string\n      add :temp_lo, :integer\n      add :temp_hi, :integer\n      add :prcp,    :float\n\n      timestamps(inserted_at: :created_at, updated_at: :updated_time)\n    end\n  end\n```\n"},{"slug":"2021-check-if-http-status-falls-within-range-ruby","category":"blog","title":"Check if an HTTP status falls within a range using Ruby","description":"http status condition handling","tags":["rails","http"],"body":"\nSometimes you want to handle a group of HTTP responses with the same response, but only in the status falls within a certain range.\n\nThe situation where I needed this was to handle the case that the status code was in the range of 200-204, so I could handle different success status' the same way.\n\nIf you want to check if an HTTP status returned to your application falls within a range you can do so with the following snippet.\n\n```Ruby\n(200..204).member?(response.status)\n```\n\nIn the above code the range is defined using `(200...204)` and there is a member method on the range object that returns `true` or `false` depending on if the value exists in that range, in this case `response.status`."},{"slug":"2021-chrome-developer-manifest-v3-permissions","category":"blog","title":"Chrome developer Manifest v3 permissions","description":"chrome extension development manifest v3","tags":["chrome-extensions"],"body":"\nIf you're using Chrome Manifest v3 there are now three types of permissions available as config values in your manifest file:\n1. Permissions\n2. Optional permissions\n3. Host permissions\n\n1) Permissions\n\nThese are permissions required for the chrome extension to function and a user must agree to grant those permissions if they are to use your extension. They are defined as an array:\n```\n{\n  \"manifest_version\": 3,\n  ...\n  \"permissions\": [\"webRequest\", \"tabs\"]\n}\n```\n\n2) Optional permissions\n\nThese are permissions that a user can opt into if they want to utilize the functionality required by that permission. The user should still be able to use other parts of the chrome extension without the optional permission enabled.\n\nIf a permission is already defined in the permissions setting, it should not be included in your optional permissions.\n```\n{\n  \"manifest_version\": 3,\n  ...\n  \"permissions\": [\"webRequestBlocking\"]\n}\n```\n\n3) Host permissions\n\nThese are permissions to define what websites (hosts) your chrome extension can run on. If you want it to run on all websites:\n```\n<!-- manifest.json -->\n\n{\n  \"manifest_version\": 3,\n  ...\n  \"host_permissions\": [\"<all_urls>\"],\n}\n```\n\nIf you want it to run on only certain websites:\n```\n{\n  \"manifest_version\": 3,\n  ...\n  \"host_permissions\": [\"https://*.youtube.com/*\"],\n}\n```\n\nChrome extensions created by DevDecks:\n- [Http Sheriff](https://chrome.google.com/webstore/detail/http-sheriff/lkahbbgcfdicehlpefblblfelahakjfp)\n- [YouTube Control Tower](https://chrome.google.com/webstore/detail/youtube-control-tower/njfjdiighaejclkgnjgmblefmdklmoed)"},{"slug":"2021-chrome-manifestv2-backgroundscripts-vs-manifestv3-serviceworkers","category":"blog","title":"Chrome Manifest v2 background script vs v3 service worker","description":"chrome extension development background scripts","tags":["chrome-extensions"],"body":"\nIn Chrome's Manifest V2 if you wanted to have a script that ran in the background of the Chrome browser you would register it in the `background` field with the `scripts` key in the `manifest.js` file:\n```\n{\n  \"manifest_version\": 2,\n  ...\n  \"background\": {\n    \"scripts\": [\"background.js\"]\n  }\n}\n```\n\nThis changed in the release of Manifest V3 where now background scripts are to be registered in the `background` field with the `service_worker` key in the `manifest.js` file:\n```\n{\n  \"manifest_version\": 3,\n  ...\n  \"background\": {\n    \"service_worker\": \"background.js\"\n  }\n}\n```\n\nIn both of implementations this script runs in a separate thread than the browser and can be used to make network requests, interact with data storage mechanisms, broadcast messages, etc. Service workers are non-blocking scripts, meaning they are completely asynchronous.\n\nChrome extensions created by DevDecks:\n- [Http Sheriff](https://chrome.google.com/webstore/detail/http-sheriff/lkahbbgcfdicehlpefblblfelahakjfp)\n- [YouTube Control Tower](https://chrome.google.com/webstore/detail/youtube-control-tower/njfjdiighaejclkgnjgmblefmdklmoed)\n"},{"slug":"2021-chrome-manifestv2-browseraction-vs-manifestv3-action","category":"blog","title":"Chrome Manifest v2 browser action vs v3 service worker","description":"chrome extension development popup.html pages","tags":["chrome-extensions"],"body":"\nIn Chrome's Manifest V2 if you wanted to have a `popup.html` that displayed when you clicked on your extension icon in the browser you would register that in your `manifest.js` file as an `browser_action` field using the `default_popup` key:\n```\n{\n  \"manifest_version\": 2,\n  ...\n  \"browser_action\": {\n   \"default_popup\": \"popup.html\"\n }\n}\n```\n\nThis changed in the release of Manifest V3 where now to have a `popup.html` page rendered you need to register that in your `manifest.js` file as an `action` field using the `default_popup` key:\n```\n{\n  \"manifest_version\": 3,\n  ...\n  \"action\": {\n   \"default_popup\": \"popup.html\"\n  },\n}\n```\n\nIn both of implementations this script runs in a separate thread than the browser and can be used to make network requests, interact with data storage mechanisms, broadcast messages, etc. Service workers are non-blocking scripts, meaning they are completely asynchronous.\n\nChrome extensions created by DevDecks:\n- [Http Sheriff](https://chrome.google.com/webstore/detail/http-sheriff/lkahbbgcfdicehlpefblblfelahakjfp)\n- [YouTube Control Tower](https://chrome.google.com/webstore/detail/youtube-control-tower/njfjdiighaejclkgnjgmblefmdklmoed)\n"},{"slug":"2021-connecting-pods-to-deployments-kubernetes","category":"blog","title":"Connecting Kubernetes Deployments to Pods","description":"How to connect Kubernetes deployments to pods","tags":["kubernetes"],"body":"\nWhen using Kubernetes pods need to be connected to deployments so the deployment knows which pods it is responsible for. This requires specific key/value pair mappings in your K8's deployment configuration. This mapping is known as matching labels with selectors where the declared label for the pod(s) needs to be selected by the deployment.\n\nFirst to declare the pods label add a value in the deployment configuration for the path `spec.template.metadata.labels.app`. Example:\n```\nspec:\n  template:\n    metadata:\n      labels:\n        app: reporting-db\n```\n\nThen to map the pod(s) to the deployment using a selector you would specify a value in the deployments configuration for `spec.selector.matchLabels.app`. Example:\n```\nspec:\n  selector:\n    matchLabels:\n      app: reporting-db\n```\n\n\nSimilar posts:\n- [How to use a secrets file for postgres credentials using Kubernetes](https://tinytechtuts.com/2021-how-to-use-a-secrets-file-for-postgres-credentials-kubernetes/)\n- [When to use which service type in Kubernetes](https://tinytechtuts.com/2021-when-to-use-kubernetes-service-types-configip-loadbalancer-nodeport/)\n- [Connecting Kubernetes Services to Deployments](https://tinytechtuts.com/2021-connecting-services-to-deployments-kubernetes/)\n- [How to view a Kubernetes pods IP address](https://tinytechtuts.com/2021-how-to-view-kubernetes-pod-ip-address/)\n- [How to view the status data in a Kubernetes Deployment](https://tinytechtuts.com/2021-how-to-view-the-status-data-of-a-kubernetes-deployment/)\n- [Create your first Rails app cluster with Kubernetes and Docker](https://tinytechtuts.com/2021-create-your-first-kubernetes-rails-app-pt1/)\n- [Kubernetes kubectl commands for newbies](https://tinytechtuts.com/2021-kubernetes-kubectl-commands-for-newbies/)\n"},{"slug":"2021-connecting-services-to-deployments-kubernetes","category":"blog","title":"Connecting Kubernetes Services to Deployments","description":"How to connect Kubernetes Services to Deployments","tags":["kubernetes"],"body":"\nWhen using Kubernetes services need to be connected to deployments so that all of the pods in the deployment can receive traffic to the services static IP and its port. This requires specific key/value pair matchings in each of these components (service and deployment) configurations. This mapping is known as matching labels with selectors where the declared label for the deployment needs to be selected by the service.\n\nFirst your deployment configuration you must declare a value for `metadata.labels.app`; this value will be used by the service as a way to select the deployment to connect to. Example:\n```\nmetadata:\n  name: reporting-db-deployment\n  labels:\n    app: reporting-db\n```\n\nThen to map this deployment to a service you would specify it in the services configuration through `spec.selector.app`. Example:\n```\nspec:\n  selector:\n    app: reporting-db\n```\n\nSimilar posts:\n- [How to use a secrets file for postgres credentials using Kubernetes](https://tinytechtuts.com/2021-how-to-use-a-secrets-file-for-postgres-credentials-kubernetes/)\n- [When to use which service type in Kubernetes](https://tinytechtuts.com/2021-when-to-use-kubernetes-service-types-configip-loadbalancer-nodeport/)\n- [Connecting Kubernetes Deployments to Pods](https://tinytechtuts.com/2021-connecting-pods-to-deployments-kubernetes/)\n- [How to view a Kubernetes pods IP address](https://tinytechtuts.com/2021-how-to-view-kubernetes-pod-ip-address/)\n- [How to view the status data in a Kubernetes Deployment](https://tinytechtuts.com/2021-how-to-view-the-status-data-of-a-kubernetes-deployment/)\n- [Create your first Rails app cluster with Kubernetes and Docker](https://tinytechtuts.com/2021-create-your-first-kubernetes-rails-app-pt1/)\n- [Kubernetes kubectl commands for newbies](https://tinytechtuts.com/2021-kubernetes-kubectl-commands-for-newbies/)\n"},{"slug":"2021-copy-collection-text-to-clipboard-js","category":"blog","title":"How to copy text from a collection of non input elements in JavaScript","description":"copy a non input elements in JavaScript","tags":["javascript"],"body":"\nThis was something I built for the [svg filter tool](https://tinytechtuts.com/tools/svg-color-changer/) on this site.\n\nThe steps to accomplish this:\n- get the elements into a collection.\n- add the desired event listener.\n- copy the text to the users clipboard.\n\nFirst, all of the elements need to share the same className so they can be queried for together. For this implementation I added the text that needed to be copied as a data attribute called `data-css-snippet`:\n```html\n<code class=\"filter-css-code\" data-tooltip-id=\"10\" data-css-snippet=\"filter: brightness(0.5) sepia(1) hue-rotate(-200deg) saturate(5);\">\n  filter: brightness(0.5) sepia(1) hue-rotate(-200deg) saturate(5);\n</code>\n```\n\nThen in JavaScript the elements can be accessed and transformed into an iterable collection using `Array.from`.\n```JavaScript\nlet filterSvgCodeSnippets = document.getElementsByClassName(\"filter-css-code\");\nfilterSvgCodeSnippets = Array.from(filterSvgCodeSnippets);\n```\n\nLastly add a click event to each element that copies the `data-css-snippet`. Start by iterating the collection using the `map` function, add the event using `addEventListener(\"click\", () => {})` and copies the text to the clipboard through `navigator.clipboard.writeText(e.target.getAttribute(\"data-css-snippet\"));`. Below is the full example:\n```\nfilterSvgCodeSnippets.map((snippet) => {\n  snippet.addEventListener(\"click\", (e) => {\n    navigator.clipboard.writeText(e.target.getAttribute(\"data-css-snippet\"));\n  });\n});\n```\n\nSimilar post\n- [Differences between window assign, open, replace, and href= in JS](https://tinytechtuts.com/2021-windowlocation-open-replace-assign-differences/)"},{"slug":"2021-create-a-custom-mix-task-by-example","category":"blog","title":"Create a custom Mix task by example","description":"Create a custom Mix task by example","tags":["elixir"],"body":"\nI am working on a task to migratie the DevDecks flashcard decks I created for this website to markdown files that will be rendering using NimblePublisher.\n\nThese were the sub tasks I outlined for completing this task given I have no prior experience writing a custom mix tasks:\n1. Determine where to place the file for the task within my application\n2. Figure out the syntax for the task, is there a module definition format? What function will the task voke? Are there other modules I need to import?\n3. How do I run the custom mix task from the command line?\n4. How do I create, write, and close a file in Elixir?\n5. How do I include Ecto modules that will be needed for querying the database for the flashcard decks?\n6. Put it all together\n\n<h3>1) Determine where to place the file for the task within my application</h3>\nI created a new directory and task file within devdecks/lib/dev_decks/tasks/migrate_db_posts_to_md.ex that would be used to define the task\n\n<h3>2) Figure out the syntax for the task, is there a module definition format? What function will the task voke? Are there other modules I need to import?</h3>\n\nThis is probably best illustrated with an annotated code example:\n```\n# define the module under mix.tasks namespace\ndefmodule Mix.Tasks.MigrateDbPostsToMd do\n @moduledoc “convert db posts to markdown posts\"\n # include the Mix.Task code\n use Mix.Task\n \n # define a run/1 function that will be invoked when your task is executed\n def run(_) do\n   IO.puts(\"RUNNING!\")\n end\nend\n```\n\n<h3>3) How do I run the custom mix task from the command line?</h3>\nThe command for the task is going to be the snake case version of the module you created for the task. So in this example from the root directory of the application I execute `mix migrate_db_posts_to_md`. \n\n<h3>4) How do I create and write to a file in Elixir?</h3>\nThrough the use of Elixir’s `File` module there is a `write!/3` function that will create a file if one doesn’t exist at the specified path and write the contents provided to it as the second argument, ex:\n```\nFile.write!(“/path/to/new_or_existing_file.md”, contents)\n```\n\n<h3>5) How do I include Ecto modules that will be needed for querying the database for the flashcard decks?</h3>\n\nYou just include them as you would inside any other Elixir module inside your Phoenix application, but now your task must start the application in order to have access to those modules through `Mix.Task.run(\"app.start\")`, the result of all the changes looked like this in my case:\n\n```\ndefmodule Mix.Tasks.MigrateDbPostsToMd do\n @moduledoc \"convert db posts to markdown posts\"\n use Mix.Task\n import Ecto.Query\n alias DevDecks.Repo\n alias DevDecks.Deck\n \n \n def run(_) do\n   # Need this to get repo\n   Mix.Task.run(\"app.start\")\n \n   IO.puts(\"BLURP\")\n end\nend\n\n```\n\n\n<h3>Put it all together</h3>\n```\ndefmodule Mix.Tasks.MigrateDbPostsToMd do\n @moduledoc \"convert db posts to markdown posts\"\n use Mix.Task\n import Ecto.Query\n alias DevDecks.Repo\n alias DevDecks.Deck\n \n def run(_) do\n   Mix.Task.run(\"app.start\")\n \n   Deck |> Ecto.Query.select([:title]) |> Repo.all |> Enum.with_index |> Enum.each(fn({deck, i}) ->\n       File.write(\"priv/posts/scheduled/post#{i}\", deck.title)\n   end)\n end\nend\n```\n\nAnd the newly built files:\n<image src=\"/images/blog/custom-mix-ouput.gpng\" alt=\"my_picture\" />"},{"slug":"2021-create-your-first-kubernetes-rails-app-pt1","category":"blog","title":"Create your first Rails app cluster with Kubernetes and Docker - Part 1","description":"create a rails cluster with Kubernetes","tags":["kubernetes"],"body":"\nThe goal of this post is to get a cluster of Rails application servers running on your local machine. Part one will not include connecting to a database.\n\nAssumptions in this post:\n* You have Docker installed and running on your local machine, if that is not the case follow the steps outlined [here](https://docs.docker.com/get-docker/) for your respective OS.\n* This will use Homebrew for package installation. If you don't have Homebrew or are unfamiliar with how to download packages on your local machine and are using a Mac you can [follow this guide](https://docs.brew.sh/Installation).\n* You understand K8s terminology such as pod, deployment, service, replica.\n\nSteps we will go through to stand up the cluster:\n1) Create a local Rails app Docker Image.\n2) Push the local Docker Image to Docker Hub.\n3) Install packages needed for local Kubernetes clustering.\n4) Create a Kubernetes config file to build the cluster from.\n5) Apply the config file and establish the external connection.\n\n<h3>Create a local Rails app Docker Image</h3>\n\nTo create the Docker image first create a new rails app `rails new k8s-test-app`.\n\nThen you need to create a Dockerfile at the root of the app directory:\n```\ncd /path/to/k8s-test-app && touch Dockerfile\n```\n\nPaste these directives into the Dockerfile. These are the commands that will be used to build your Docker image.\n```\nFROM ruby:2.5\nRUN apt-get update -qq && apt-get install -y nodejs\nWORKDIR /app\nCOPY Gemfile ./Gemfile\nCOPY Gemfile.lock ./Gemfile.lock\nRUN gem install bundler -v 2.0.1\nRUN bundle install\nCOPY . /app\nEXPOSE 3000:3000\nCMD [\"rails\", \"server\", \"-b\", \"0.0.0.0\"]\n```\n\nFrom the app root directory run the following command to build your image:\n```\ndocker build --tag=k8s-test-app .\n```\n\nFind your image locally through the command `docker image ls`.\n\n<h3>Push the local Docker Image to Docker Hub</h3>\n\nYou will need to push your image to a Docker Repository, for this tutorial that will be Docker Hub. I have outlined those steps in [this post](https://tinytechtuts.com/2021-pushing-docker-image-to-dockerhub-tutorial/).\n\n<h3>Install packages needed for local Kubernetes clustering</h3>\n\nTo begin using K8's locally you will need to have a few packages installed. See the commands below to install these packages and their annotations for what their purpose is:\n```\n<!-- install a virtual machine to run the cluster -->\nbrew install hyperkit\n\n<!-- link the vm -->\nbrew link hyperkit\n\n<!-- install a local K8s environment that gives you access to K8s functionality -->\nbrew install minikube\n```\n\nAlso note that Minikube will give you access to Kubectl which is the command line interface for working with K8s clusters.\n\n<h3>Create a Kubernetes config file to build the cluster from</h3>\n\nCreate a YAML file at the root of your rails application directory:\n```\ncd /path/to/k8s-test-app && touch deployment.yml\n```\n\nNext Paste of the below code snippet into the deployment.yml file. This is your configuration from which the cluster will be built. This file will create two instances of your container and link them to the service created in the second part of the file. A few things to note about this spec:\n1. Use the image you created in Docker Hub to build your containers replace `spec.template.spec.containers.image` with your image.\n2. The port under `spec.template.spec.containers.ports.containerPort` must match what we declared in our Dockerfile so the container can be reached. In our case port 3000.\n3. The service is connected to the deployments pods through the label in the deployment (`metadata.labels.app`) and the selector in the service (`spec.selector.app`)\n4. We denote we want two container instances created through `spec.replicas` in the deployment.\n\n```\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: k8s-test-app-deployment\n  labels:\n    app: k8s-test-app\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: k8s-test-app\n  template:\n    metadata:\n      labels:\n        app: k8s-test-app\n    spec:\n      containers:\n      - name: k8s-test-app\n        image: joe-britton/first-repo:v.0.0.1\n        ports:\n        - containerPort: 3000\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: k8s-test-app-service\nspec:\n  selector:\n    app: k8s-test-app\n  type: LoadBalancer\n  ports:\n    - protocol: TCP\n      port: 80\n      targetPort: 3000\n      nodePort: 30000\n```\n\n<h3>Apply the config file and establish the external connection.</h3>\n\nFirst start the Minikube application using the Hyperkit VM.\n```\nminikube start --vm-driver=hyperkit\n```\n\nNow run the deployment to stand up the K8s cluster. This command will create the nodes and pods to run the Docker container, it will also create the service that will be used to communicate with the pods.\n```\nkubectl apply -f deployment.yml\n```\n\nTo connect to the container through the browser locally an additional step is required:\n```\nminikube service k8s-test-app-service\n```\nThis command will link the service you created to an IP address reachable from your browser. In most production deployments this step will not be required.\n\nAfter running this command minikube will open the app for you automatically and you should see  the default rails page rendered. If that is the case then you have successfully deployed your first K8s cluster 🎉🎉.\n\nSimilar post:\n- [How to view the status data in a Kubernetes Deployment](https://tinytechtuts.com/2021-how-to-view-the-status-data-of-a-kubernetes-deployment/)"},{"slug":"2021-created-scheduled-posts-using-nimblepublisher","category":"blog","title":"Create scheduled posts using NimblePublisher","description":"learn how to create scheduled posts using NimblePublisher","tags":["elixir","cms"],"body":"\nTo accomplish this I first tried creating a scheduled_posts folder in my app and then could use the Quantum library to move posts from the scheduled_posts folder to the posts folder, which contains the published posts, on a nightly.\n\nThe issue I ran into there was that the storage there was ephemeral and was overwritten on each deploy/new instance so my scheduled posts would be overwritten quickly.\n\nI was eventually able to get this working by adding a published key to the Post struct:\n```\ndefstruct [:id, :title, :body, :description, :tags, :date, :published]\n```\n\nAnd then when the posts are queried for in the Blog I filter them based on their date, if the date of the post is later than today's date then that post will not be published, otherwise it will be. The code for that, which exists in my `blog.ex` file as:\n\n```\n@posts Enum.map(@posts, fn (p)->\n  cond do\n    Date.compare(p.date, Date.utc_today) == :lt -> %{p | published: true}\n    true -> p\n  end\nend)\n@published_posts Enum.filter(@posts, fn (p)-> p.published end)\n```\n\n"},{"slug":"2021-creating-a-table-with-different-primary-key-rails","category":"blog","title":"Creating a table with non id primary key in Rails","description":"rails database with primary key other than id","tags":["rails"],"body":"\nIn order two change a database tables primary key from `id` to another desired attribute when on create you must first pass an option of `id: false` as a second argument to the `create_table` method. Then when declaring columns for your table, indicate which should become the primary key by passing it an option of `primary_key: true`.\n\n```ruby\n  def change\n    create_table :applications, id: false do |t|\n      t.string  :uid,     null: false, primary_key: true\n    end\n  end\n```\n\nThen within your applications ActiveRecord model you will need to add a delcaration at the top of the model indicating the new primary key. This helps keep things clear for others working on your application. \n\n```ruby\nclass Application\n  self.primary_key = \"uid\"\nend\n```\n\nSimilar posts:\n- [Same Database table parent/child relationship using Rails](https://tinytechtuts.com/2021-same-db-table-parent-child-relationship-rails/)\n - [Rails nested resources completed example](https://tinytechtuts.com/2021-rails-nested-resources-mvc-complete-example/)\n\n"},{"slug":"2021-creating-links-using-non-interactive-elements-in-react","category":"blog","title":"Creating links using non-interactive elements in React","description":"building noninteractive element links in react","tags":["react"],"body":"\nWhen building a React view I came across the scenario where I wanted a JSX element to be a link when a user was viewing from a laptop or other larger screen and a `div` when they were viewing on mobile. \n\nThe reason for this difference is on mobile there is no concept of a hover state. When you hover the link in mention on a large screen it will show a dropdown nav and when you click the link it will take you to a profile page. On mobile when you click the `div` it should show the dropdown and include a link to that profile page.\n\n```react\n<a id=\"lg-dropdown\" href=\"/profile\">\n  <ul>\n    <li><a href=\"/darkmode\">Darkmode</a></li>\n    <li><a href=\"/settings\">Settings</a></li>\n    <li><a href=\"/logout\">Logout</a></li>\n  </ul>\n</a>\n\n<div id=\"sm-dropdown\" role=\"button\" tabIndex=\"0\" onClick={() => setShow(!show)}onKeyUp={(e) => e.key == \"Enter\" && setShow(!show)} >\n  <ul>\n    <li><a href=\"/profile\">Profile</a></li>\n    <li><a href=\"/darkmode\">Darkmode</a></li>\n    <li><a href=\"/settings\">Settings</a></li>\n    <li><a href=\"/logout\">Logout</a></li>\n  </ul>\n</div>\n```\n\n```scss\n#sm-dropdown {\n  display: none;\n}\n\n@media (max-width: 480px) {\n  #sm-dropdown {\n    display: block;\n  }\n\n  #lg-dropdown {\n    display: none;\n  }\n}  \n```\n\nThe `div` contains a few attributes worth noting:\n- `role` - the role attribute tells the browser that this element will trigger a response when activated by the user. In this case we are setting the attribute to \"button\" which identifies the element as a clickable button to the browser.\n- `tabIndex` - this attribute is required to make the element focusable by users and screen readers, it also makes the element a part of the page's tab order when using tab navigation.\n- `onClick`, `onKeyUp` - I originally only had an `onClick` handler for this element but if you are going to have a click handler it is a best practice to have a keyboard event that can accomodate the interaction as well for accessibility purposes, so I also included the `onKeyUp` event.\n\nMore React posts for you enjoyment:\n- [Jest Testing Cheatsheet](https://tinytechtuts.com/2021-jest-testing-cheatsheet/)\n - [Mock React Custom Hooks](https://tinytechtuts.com/2021-mock-custom-react-hooks-with-jest/)"},{"slug":"2021-cross-site-request-forgery-explained","category":"blog","title":"Cross Site Request Forgery explained through q&a","description":"cross site request forgery explained","tags":["web-security"],"body":"\nThis and the other \"Deck\" posts are a repurposing of flashcard study decks to Q&A blog posts. Google was not showing love to this content as a set of flashcards and I didn't want to delete them entirely, I hope you find it useful.\n\n<h3>What is someone attempting a CSRF attack trying to do?</h3>\nIn the most straightforward case they are attempting to get you to make requests you didn't intend to, often by clicking on a link or image. These requests might be trying to alter a user password so the attacker can continue to act as the victim now knowing their password or transfer money from the victims online bank account into the attackers.\n\n<h3>What is an example of a CSRF attack?</h3>\nAn attacker trying to transfer money out of user accounts of bank.com. This attacker could setup an email account similar to that of bank.com's support email. Let's say bank.com's email address is support@bank.com and the attacker creates the email support@banks.com and then sends an email posing as the bank with links included in the email body like:\n```\n&lt;a href=\"bank.com/transfer?to=theattacker@gmail.com&amount=2000 />\n```\nClicking this URL would transfer $2000 from the victims account to the attackers, using the cookies stored in the victims browser as a means of authorization.\n\n<h3>How are XSS and CSRF attacks different?</h3>\nIn an XSS attack the end goal is often to steal user credentials to gain access to their systems account.\n\nIn the case of a CSRF attack the object is to execute an unwanted action on behalf already logged in user, like a transfer money from victims account into the attackers account in a banking system.\n\n<h3>Is the following an example of a CSRF attack?</h3>\nScenario: An attacker executes a script on behalf of a user that hijacks the credentials of the current browser window they are logged into and writes those credentials to a database so they can act on behalf of that user in the future?\n\nIt is not an example of a CSRF attack, this is a Persisted XSS attack. It would have been a CSRF attack if it was attempting to execute an action (example a bank transfer) without stealing the credentials for future use.\n\n\n<h3>How is an attacker able to authenticate requests using the victims credentials?</h3>\nThrough the use of browser cookies.\n\nEncrypted session cookies are often used as a means of authorizing a user to server resources and they are sent on every request to the server that issued them. An attacker could send you a link to bank.com and if your session cookie for bank.com isn't expired, your credentials will be sent along with that request and the attacker will be authorized as you, if you click the link.\n\n<h3>What measures should a developer take to ensure they are protected from CSRF?</h3>\nTo protect against malicious form POST requests websites can use a hidden input field generated by the websites application server, the value of which is an authenticity token that gets sent to the server along with the rest of the form values onsubmit. This token is then checked for validity before continuing with the intended POST action. An attacker could not create their own fake authenticity tokens because they would not have been generated by the server that created the form. Most modern web frameworks handle this in forms by default.\n\nMore Web Attack/Security Decks:\n1. [Cross Site Scripting](https://tinytechtuts.com/2021-cross-site-scripting-explained/)\n2. [Man In The Middle Attack](https://tinytechtuts.com/2021-man-in-the-middle-attack-explained/)"},{"slug":"2021-cross-site-scripting-explained","category":"blog","title":"Cross Site Scripting explained through q&a","description":"cross site scripting explained","tags":["web-security"],"body":"\nThis and the other \"Deck\" posts are a repurposing of flashcard study decks to Q&A blog posts. Google was not showing love to this content as a set of flashcards and I didn't want to delete them entirely, I hope you find it useful.\n\n<h3>What is an XSS attack?</h3>\nIt is a type of application attack in which html, often a script, is inserted into the document of your application by a malicious user and when other users interact with this they could be giving away their credentials to the attacker and then the attacker can act on the unsuspecting users behalf.\n\n<h3>What does the acronym XSS stand for?</h3>\nCross Site Scripting.\n\n<h3>What is the difference between an XSS and CSRF attack?</h3>\nWith XSS the attackers end goal is often to steal user credentials.\n\nWith a CSRF attack the goal is to execute an unwanted action on behalf already logged in user, like a transfer money from victims account into the attackers account in a banking system.\n\n<h3>Are there different types of XSS attacks?</h3>\nYes, there are three.\n1. Reflected\n2. Stored/Persisted\n3. DOM/Client Side.\n\n<h3>What is a stored XSS attack?</h3>\nThis attack is similar to a reflected attack in that it sends a request to the server, but with the intent of storing malicious data in a database that will be returned any time requests are made for this content.  \n\nAn often cited example is in the comments section of a website where an attacker leaves a comment that gets stored and then if that comment is interacted with by other users they will fall victim to the stored XSS attack.\n\n<h3>How does a DOM/Client side XSS attack work?</h3>\nThis occurs when malicious data, often search parameters or form inputs, are taken directly from the client HTML page and inserted right back into that page without proper data sanitization. The attacker will inject malicious code into the vulnerable website and then it is immediately accessible for any user to interact with who browsing the same page.\n\n An example of a vulnerable site is one with a search field that shows all searches made from all users. If the website is not properly checking that data for malicious code all users interacting with that page would be susceptible to an attack.\n\n<h3>What is the difference between a reflect and client-side XSS attack?</h3>\nIn reflected attacks the data submitted by the attacker makes its way back the app server before becoming accessible to other users. In client-side attacks data submitted by an attacker does not travel back to the server, instead the data (often a malicious script) is immediately accessible to other users.\n\n<h3>How can I make my website less susceptible to an XSS attack?</h3>\nDetect the attack by checking the URL string and HTML input fields for malicious values like `&lt;script&gt;` tags either on the client or server and whenever possible properly encode that data before presenting it to users.\n\nMany web frameworks handle these XSS mitigation techniques out of the box.\n\n<h3>How does a Session Hijacking relate to XSS?</h3>\nWhen an attacker uses a valid session of another user to make requests on their behalf this can be described as session hijacking. So if the XSS attack being executed is one where the attacker tries to steal the session token of another user, that is an example of both Session Hijacking and XSS where an XSS attack is being used to hijack the session.\n\n<h3>If an attacker is listening for HTTP network traffic to inject malicious headers into the request, is this an example of an XSS attack?</h3>\nNo this would be a man in the middle attack (MITM).\n\n<h3>Do most modern web frameworks help in mitigating XSS by escaping or encoding inputs and search parameters?</h3>\nYes they do. Thanks be to internet 2.0.\n\n<h3>How does Phishing relate to XSS?</h3>\nPhishing can be an XSS attack. Phishing occurs when a user is tricked into handing over sensitive data like credit card information, SSN, user name and password, etc. to an attacker. Example:  \n\nIf you click on a random link in the comment section of a website that claims to be giving you a gift for $20,000 as a reward for being the millionth viewer of the content and then you click on it and the attacker is able to steal your username and password of the website you came from it could correctly be said that you were a victim of a Phishing attack but it is also correct to say you were the victim of an XSS attack because the attacker had to use XSS to place the comment there to begin with.\n\nMore Web Attack/Security Decks:\n1. [Cross Site Request Forgery](https://tinytechtuts.com/2021-cross-site-request-forgery-explained/)\n2. [Man In The Middle Attack](https://tinytechtuts.com/2021-man-in-the-middle-attack-explained/)"},{"slug":"2021-delete-sidekiq-cache-key","category":"blog","title":"Delete a cache key from Sidekiq using Rails","description":"Delete a cache key from Sidekiq using Rails","tags":["rails","caching","sidekiq"],"body":"\nTo handle a situation where a cache key needs to be deleted and you don't have admin access to the system itself, you can handle the remove through the application by defining a new Rails controller method that calls a Sidekiq job to delete the cache key.\n\nThe steps are:\n1) Define the new route and controller action\n2) Create the new Sidekiq job to delete the key\n3) Invoke the controller action in whichever environment the key needs to be cleared from\n\nRoute and Controller\n```\nget \"/sidekiq/delete_key/:key\", to: \"sidekiq#delete_key\"\n```\n\n```\nclass SidekiqController < ApplicationController\n  def delete_key\n    DeleteSidekiqKeyJob.perform_later(params[:key])\n  end\nend\n```\n\nJob\n```\nclass DeleteSidekiqKeyJob < ApplicationJob\n  def perform(key)\n    Rails.cache.delete(key)\n  end\nend\n```\n\nNow you can hit the route you defined and pass in the key as a path parameter to delete the cached record.\n\n"},{"slug":"2021-determine-object-heaviness-ruby","category":"blog","title":"How to determine the rough size (heaviness) of an object in Ruby","description":"determine size of an object in Ruby","tags":["ruby"],"body":"\n\nLet's say you are trying to find ways to reduce application memory and want to do a rough audit of object sizes in your application to see if there are any bloated objects that can be divided into smaller objects for a more performant application. How do you go about this?\n\nThe means I've found is through the use of the `objspace` library. An example use of this library:\n\n```\nrequire 'objspace'\n\nObjectSpace::trace_object_allocations{ \n  org = Organization.last\n  puts ObjectSpace::memsize_of(org) \n}\n```\n\nThe example above first requires the library and then prints the size of the Ruby object in bytes.\n\nNote that this is an approximation and the ObjectSpace documentation recommends you be familiar with your MRI implementation before using this library.\n"},{"slug":"2021-early-code-optimization-okay","category":"blog","title":"When early code optimization is okay, an example","description":"code optimization","tags":["rails","oauth"],"body":"\nAn often mentioned issue within software development is premature code optimization, which happens when a developer makes too many assumptions about the future context of what they are currently developing. It can make a codebase confusing when someone else is trying to interpret functionality later on.\n\nI had a situation where I opted to optimize Rails controller code before I had to, but I think it was the correct decision, but first the code snippets:\n\nCode before the optimization:\n```ruby\ndef accept_client_credentials_grant\n  org_options = OrganizationOptions.find_by!(uuid: params[:uuid])\n\n  response = OauthAccessGrant.create_and_update_client_credentials(org_options, grant_params)\n\n  render json: response\nend\n```\n\nCode after the optimization:\n```ruby\ndef accept_grant\n  org_options = OrganizationOptions.find_by!(uuid: params[:uuid])\n\n  case params[:grant][:grant_type]\n  when \"client_credentials\"\n    response = OauthAccessGrant.create_and_update_client_credentials(org_options, grant_params)\n  else\n    StandardError.new(\"OAuth Grant Type Not Supported\")\n  end\n\n  render json: response\nend\n```\n\nIn the code examples above I ended up switching the `accept_client_credentials_grant` controller method to `accept_grant` and then used a case statement as a proxy to determine what the app should do based on the `grant_type` that was sent to the app through `params`.\n\nThis controller was an OAuth controller, which has established workflows. I was only building this OAuth server to handle one workflow, but given that the app I built on has many different customers, many of which have unique auth needs, I felt it made sense to add this proxy now.\n\nThis early optimization prevents the situation of a different developer needing to update this method later on and not knowing what the value for `grant_type` would exactly look like. For all they know the param value could be \"Client Credentials\", \"CLIENT_CREDENTIALS\" or any number of other options. Given that I knew of future potential workflows in advance and could see a future issue for other developers, I chose to optimize this code early, but in my opinion not prematurely.\n"},{"slug":"2021-elixir-atoms-and-integers-explained","category":"blog","title":"Elixir Atoms and Integers explained through q&a","description":"elixir atoms and integers explained","tags":["elixir"],"body":"\nThis post works best when paired with the [Elixir docs](https://elixir-lang.org/getting-started/basic-types.html) for a general overview of Atoms and Integers.\n\n<h3>What is an Elixir Atom?</h3>\nIt is an Elixir data type thats value is its own name.\n\n<h3>What is an Elixir Atom used for?</h3>\nThey are often used to indicate the result of an operation either as the first value of a tuple or as a standalone response. `:ok` is often used to indicate a successful operation and `:error` is used if something goes wrong.\n```\n{:ok, result} = some_function()\n\n:ok = some_other_function()\n```\n\n<h3>What is special about the values true, false and nil as they relate to atoms?</h3>\nEach of those data types are atoms. Elixir allows you to skip typing the colon (:) for these atoms. Ex:\n```\ntrue == :true\n=> true\n\nnil == :nil\n=> true\n\nfalse == :false\n=> true\n```\n\n<h3>Which data type represents whole numbers in Elixir Integer or Float?</h3>\n`Integer`. `Float` is used for fractional numbers.\n\n<h3>The Kernel and Integer module each define integer functions. What integer functions does the Kernel define?</h3>\n`abs/1`, `div/2`, `min/2`, `max/2`, `rem/2`. These are all arithmetic based functions.\n\n<h3>What functions does the Integer module define?</h3>\n`is_env` and `is_odd`. These are most often used as Guards in Elixir.\n```\nInteger.is_even(12)\n=> true\n\nInteger.is_odd(12)\n=> false\n```\n\nMore Elixir Decks:\n1. [Tuples](https://tinytechtuts.com/2021-elixir-tuples-explained/)\n2. [List](https://tinytechtuts.com/2021-elixir-lists-explained/)\n"},{"slug":"2021-elixir-comprensions-explained","category":"blog","title":"Learn Elixir Comprehensions through q&a","description":"elixir comprehensions","tags":["elixir"],"body":"\n<h3>What is an Elixir Comprehension?</h3>\nIt is another way to loop over an Enumerable, just like the Enum module, only with a cleaner syntax.\n\n<h3>What Elixir data types are Enumerable?</h3>\nList, Map, Range, MapSet\n\n<h3>How does an Elixir Comprehension differ from an Enum?</h3>\nThere is no difference in terms of performance and what you can accomplish functionally. The difference is in developer preference.\n\n<h3>What is a the generator in a Comprehension?</h3>\nIt is the Enumerable being passed into the comprehension. In the below example `<- [1, 3, 5]` is the generator being passed into the comprehension.\n```\nfor n <- [1, 3, 5], do: n * 2\n```\n\n<h3>Can multiple generator's be used within a Comprehension?</h3>\nYes. If you need to perform a set of operations on an Enumerable, you can use multiple generators.\n\n<h3>Can you use pattern matching with Comprehensions?</h3>\nYes. The below example pattern matches a keyword list of http responses for user requests and returns only the successes.\n```\nresponses = [ok: %{name: \"Joe\", email: \"joe@friendo.com\"}, error: \"invalid request\", error: \"invalid request\", ok: %{name: \"Jen\", email: \"jen@friendo.com\"}]\nfor {:ok, msg} <- responses, do: msg\n=> [\n  %{email: \"joe@friendo.com\", name: \"Joe\"},\n  %{email: \"jen@friendo.com\", name: \"Jen\"}\n]\n```\n\n<h3>Write the equivalent Comprehension and Enum code for accepting a List and multiplying it by two.</h3>\n```\nfor n <- [1, 3, 5], do: n * 2\n```\n\n```\nEnum.map([1,3,5], &(&1 * 2))\n```\n"},{"slug":"2021-elixir-earmark-code-parsing","category":"blog","title":"Migrating to Elixir's Earmark for markdown processing","description":"Migrating to Elixir's Earmark for markdown processing","tags":["elixir"],"body":"\nPrior to migrating to Earmark any html needed for the DevDeck cards had been hard coded. Switching to Earmark for markdown processing now saves me a lot of time in card creation. Previously I would have to save a card question or answer with a code block resembling this:\n```\n\"\"\"Multi-line string of text\n  <br />\n  <pre><code>IO.inspect \"some code\"</code></pre>\n\"\"\"\n```\n\nNow I can accomplish the same thing with:\n```\n\"\"\"Multi-line string of text\n  \\n\n  ```IO.inspect \"some code\"</code></pre>```\n\"\"\"\n```\n\nIt might not look like a big deal but the minutia required to get HTML formatted correctly for each of the of questions and answers requires extra attention to detail and is prone to mistakes.\n\nIf you're unfamiliar with markdown processors, they essentially take a set of rules and convert those rules to HTML nodes. For example the open and closed backticks above (```repetitions sake example```) get converted the `<pre><code></code></pre>` html nodes for displaying code snippets in a web browser.\n\nThe migration to Earmark included three steps:\n1) Add Earmark as a project dependency\n2) Use the Earmark client to process markdown\n3) Write and execute a migration to convert hard coded HTML to markdown.\n\n<h2>Step one: adding Earmark as a project dependency</h2>\n\nInclude Earmark as a project dependency in your `mix.exs` file:\n\n```\ndefp deps do\n  [\n    ...\n    {:earmark, \">= 1.4.15\"}\n  ]\nend\n```\n\nAnd update dependencies with the command `mix deps.get`.\n\n\n<h2>Step two: use the Earmark client to process markdown</h2>\n\nI have to use the Earmark client when my server calls for the cards. For this application I am using LiveView for websocket based client/server data transactions so I added the Earmark functionality to my `card_live.ex` file which will include the card data in the rendering of the `card.html.leex` template. I use the `as_html` function on the `Earmark` module to accomplish this. That update looked like:\n\n```\ndef mount(%{\"uuid\" => uuid} = params, _session, socket) do\n  cards = Card.from_uuid(uuid)\n  cards = Enum.map(cards, fn (card) ->\n    {:ok, answer, _opt} = Earmark.as_html(card.answer)\n    {:ok, question, __opt} = Earmark.as_html(card.question)\n    %{card | answer: answer, question: question}\n  end)\n\n  {:ok, assign(socket, cards: cards)}\nend\n```\nAbove I am mapping over a list of cards and processing the question and answer markdown before assigning the cards to the socket.\n\nThe rendering didn't change but this is what the template code looks like in my `card.html.leex` file:\n```\n<%= @cards |> Enum.with_index |> Enum.map(fn({card, index}) ->  %>\n  <div id=\"card\">\n    <span><%= raw card.question %></span>\n    <span><%= raw card.answer %></span>\n  </div>\n<% end) %>\n```\n\n<h2>Step 3: Write and execute a migration against existing cards to convert hard coded HTML to markdown.</h2>\n\nFirst generate a new migration file on the command line through:\n```\nmix ecto.gen.migration earmark_cards\n```\n\nAnd then in the migration file I convert all of the question and answer strings using `String.replace` and replace the html code matched with its markdown equivalent, I annotate some of the script where I think it could be helpful.\n\n```elixir\ndefmodule DevDecks.Repo.Migrations.EarmarkCards do\n  use Ecto.Migration\n\n  def up do\n    # Get all decks and then all the cards from those decks (this could be simplified)\n    DevDecks.Deck.query_uuids |> Enum.map(fn(uuid) -> DevDecks.Card.from_uuid(uuid) end)\n    |> Enum.map(fn(card_set) ->\n      Enum.map(card_set, fn(card) ->\n        # some test cards don't have answers so add a default blank string\n        answer = card.answer || \"\"\n        # pipe the answer string through all of the regex string replacement\n        updated_answer = answer\n        |> String.replace(~r/<pre><code>/, \"```\")\n        |> String.replace(~r/<\\/code><\\/pre>/, \"```\")\n        |> String.replace(~r/<code>/, \"`\")\n        |> String.replace(~r/<\\/code>/, \"`\")\n        |> String.replace(~r/<br \\/>/, \"\\n\")\n        |> String.replace(~r/<br\\/>/, \"\\n\")\n        |> String.replace(~r/<br>/, \"\\n\")\n\n        # repeat steps for question (this could have been extracted to a function)\n        question = card.question || \"\"\n        updated_question = question\n        |> String.replace(~r/<pre><code>/, \"```\")\n        |> String.replace(~r/<\\/code><\\/pre>/, \"```\")\n        |> String.replace(~r/<code>/, \"`\")\n        |> String.replace(~r/<\\/code>/, \"`\")\n        |> String.replace(~r/<br \\/>/, \"\\n\")\n        |> String.replace(~r/<br\\/>/, \"\\n\")\n        |> String.replace(~r/<br>/, \"\\n\")\n\n        # call the update function on the card context with the card uuid to find the card and the updated answer and question.\n        DevDecks.Card.update(%{\"uuid\" => card.uuid, \"answer\" => updated_answer, \"question\" => updated_question})\n      end)\n    end)\n  end\n\n  # add a down method for rollbacks if needed.\n  def down\n    nil\n  do\nend\n```\n\nAfter testing this locally I deployed it using Gigalixir and ran the migration in production from the command line through `gigalixir run mix ecto.migrate` and could watch the migration through the logs using `gigalixir logs`.\n\nFollowing the successful migration the transition was complete.\n\nIf you found this useful I also wrote a post about a migrating to add timestamps to the DevDecks database retroactively [here](https://tinytechtuts.com/2021-retroactively-add-timestamps-in-phoenix-ecto/):\n\n"},{"slug":"2021-elixir-file-extensions-for-new-developers","category":"blog","title":"Elixir file extensions for new developers","description":"Elixir file extensions for new developers","tags":["elixir"],"body":"\nThis and the other \"Deck\" posts are a repurposing of flashcard study decks to Q&A blog posts. \n\n<h3>When would you use the .ex extension for an Elixir file vs `.exs`?</h3>\n\nYou use `.ex` when you want to compile your code and `.ex` when writing a script.\n\n\n<h3>How would you execute a .exs file script from the command line?</h3>\n\n```\nelixir my_exs_file.exs\n``` \nRunning the script above will execute the file without writing a compiled BEAM file to disk.\n\n\n<h3>How would you execute a .ex file on the command line?</h3>\n\n```\nelixirc my_exs_file.ex\n``` \nThe above will write a compiled BEAM file to disk and you will be able to use the modules/functions you create in your Elixir environment.\n"},{"slug":"2021-elixir-list-to-comma-separated-string","category":"blog","title":"Convert an Elixir List into a comma separated String","description":"Convert an elixir list into a comma separated string","tags":["elixir"],"body":"\nSometimes when working with an Elixir List you may need to utilize that list in a different format, such as a comma separated string. In this event you can reach for the `Enum` module and its `join/2` function, for example:\n\n```\n=> list = [\"snow shoes\", \"biscuits\", \"turtles\"]\n=> string = Enum.join(list, \", \")\n\"snow shoes, biscuits, turtles\"\n```\n"},{"slug":"2021-elixir-lists-explained","category":"blog","title":"Elixir Lists explained through q&a","description":"elixir lists explained","tags":["elixir"],"body":"\nThis post works best when paired with the [Elixir docs](https://hexdocs.pm/elixir/1.12/List.html) for a general overview of Lists.\n\n<h3>What is an Elixir List?</h3>\nA data type for storing a collection of values.\n\n<h3>Are Lists in Elixir considered Linked Lists? What does that imply?</h3>\nYes. This means that when performing operations Elixir always begins with the first element in a List and ends with the last, another way of saying this is operations will run in linear time.\n\n<h3>Is it faster to prepend or append a value to an Elixir List?</h3>\nPrepend.\n\n<h3>How do you add a value(s) to a List?</h3>\nOne way is by using the `|` operator to create a new List where the left hand side are the new values and the right hand side is the previous List.\n```\n=> wise_words = [\"battlestar galactical\"]\n=> [\"bears\", \"beets\" | wise_words]\n[\"bears\", \"beets\", \"battlestar galactical\"]\n```\n\n<h3>How do you merge one or more Lists into a single List?</h3>\nUsing the `++` operator.\n```\n=> [\"bears\", \"beets\"] ++ [\"battlestar galactical\"]\n[\"bears\", \"beets\", \"battlestar galactical\"]\n=> [\"bears\", \"beets\"] ++ [\"battlestar galactical\"] ++ [\"boiled biscuits\"]\n[\"bears\", \"beets\", \"battlestar galactical\", \"boiled biscuits\"]\n```\n\n<h3>How do you remove the first occurrence of a value from a List?</h3>\nUsing the `--` operator. See the example below:\n```\n=> wise_words = [\"bears\", \"beets\", \"beets\", \"battlestar galactical\", \"bears\"]\n=> wise_words -- [\"beets\", \"bears\"]\n[\"beets\", \"battlestar galactical\", \"bears\"]\n```\n\n<h3>How do you remove an element using its index?</h3>\nUsing the `List` modules `delete_at` method and providing an index as the second argument. The below removes the second element of the List:\n```\n=> wise_words = [\"bears\", \"beets\", \"battlestar galactical\"]\n=> List.delete_at(wise_words, 1)\n[\"bears\", \"battlestar galactical\"]\n```\n\n<h3>How do you remove the last Item from a List?</h3>\nThe below example uses the `Kernel` length function to get the index of the last element and then deletes that element using the `List.delete_at/2` function.\n```\n=> wise_words = [\"bears\", \"beets\", \"battlestar galactical\"]\n=> last_element_index = length(wise_words) - 1\n=> List.delete_at(wise_words, last_element_index)\n[\"bears\", \"beets\"]\n```\n\n<h3>What is the head of a List, what is the tail?</h3>\nThe head is the first element of a List and the tail is the rest of the Lists elements that follow.\n\n<h3>How do you remove all elements with the same value from a List?</h3>\nYou can use the `Enum` module and the `filter` or `reject` functions. The following example removes all occurrences of \"bears\" and \"beets\" from the wise_words List.\n```\nwise_words = [\"bears\", \"beets\", \"beets\", \"battlestar galactical\", \"bears\"]\nEnum.filter(wise_words, fn (word) -> (word !== \"bears\") && (word !== \"beets\") end)\n```\n\n<h3>How do you retrieve the value of the head of a List? How do you retrieve the tail?</h3>\n1. Using the `Kernel` modules `hd` and `tl` functions respectively:\n```\n=> hd [\"bears\", \"beets\", \"battlestar galactical\"]\n\"bears\"\n=> tl [\"bears\", \"beets\", \"battlestar galactical\"]\n[\"beets\", \"battlestar galactical\"]\n```\n2. Using pattern matching:\n```\n=> [head | tail] = [\"bears\", \"beets\", \"battlestar galactical\"]\n=> head\n\"bears\"\n=> tail\n[\"beets\", \"battlestar galactical\"]\n```\n\nMore Elixir Decks:\n1. [Atoms and Integers](https://tinytechtuts.com/2021-elixir-atoms-and-integers-explained/)\n2. [Tuples](https://tinytechtuts.com/2021-elixir-tuples-explained/)\n"},{"slug":"2021-elixir-modules-for-new-developers","category":"blog","title":"Elixir Modules for new developers","description":"Elixir Modules for new developers","tags":["elixir"],"body":"\nThis and the other \"Deck\" posts are a repurposing of flashcard study decks to Q&A blog posts. \n\n<h3>What do Elixir developers use Modules for?</h3>\n\nGrouping functions with like behavior under a namespace.\n\n\n<h3>How can Modules be nested?</h3>\n\nThrough a `.` in the Module definition. In the below example `Profile` is nested under `User`: \n```\ndefmodule User.Profile do \n  def get_details \n  end \nend\n```\n\n\n<h3>What are Module attributes?</h3>\n\nThey are most often used as constants within a Module but can also be used for documentation of the Module and its functions. In advanced use cases they can used as temporary storage to be referenced in compilation. Below is an example of the constants use case: \n```\ndefmodule Server do \n  @initial_state %{host: localhost, port: 3000} \nend\n```\n\n\n<h3>Does Elixir have any reserved Module attributes?</h3>\n\nYes. Some of the more common ones are `@moduledoc`, `@doc`, `@behaviour`. More detailed information on these and other attributes can be found [here](https://hexdocs.pm/elixir/Module.html#module-module-attributes).\n\n\n<h3>In functional programming languages like Elixir how are we able to reuse code? How do modules help with this?</h3>\n\nThrough a technique called composition. Composition allows us to reuse behavior between Modules. The next few questions will walk through ways Elixir accomplishes this.\n\n\n<h3>If you want to use and reference a module inside another module, what Elixir directive would you use?</h3>\n\nThe `alias` directive. \n```\ndefmodule ProfileHelpers do \n  def from_rds \n  end \nend\n``` \n```\ndefmodule User.Profile do \n  alias ProfileHelpers \n\n  def get_details ProfileHelpers.from_rds\n  end \nend\n```\n\n\n<h3>If you want to use functions defined in one module inside another module without referencing the module directly, what Elixir directive would you use?</h3>\n\nThe `import` directive. \n```\ndefmodule ProfileHelpers do \n  def from_rds \n  end \nend\n```\n```\ndefmodule User.Profile do\n  import ProfileHelpers\n   \n  def get_details_from_rds \n  end \nend\n```\n\n\n<h3>Is it possible to change the name of a module being aliased?</h3>\n\nYes, by using the `as:` option when issuing the `alias` \n```\ndefmodule ProfileHelpers do\n  def from_rds \n  end \nend\n``` \n```\ndefmodule User.Profile do \n  alias ProfileHelpers, as: Helpers \n\n  def get_details Helpers.from_rds \n  end \nend\n```"},{"slug":"2021-elixir-process-module-cheatsheet","category":"blog","title":"Elixir process module cheatsheet","description":"process module cheatsheet","tags":["elixir"],"body":"\nThe Process module defines functions for working with processes to handle things like introspection, starting/stopping, linking, etc.. These are a few that I find to be particularly useful:\n\n- `Process.list/0` - gets a list of all running processes on the BEAM VM.\n- `Process.info/1` - accepts a pid as an argument a returns metadata about the process.\n- `Process.alive?/1` - accepts a pid as an argument and returns a boolean based on if the process is alive or dead.\n- `Process.exit/2` - accepts a pid and an instruction atom (often :kill) and terminates the process\n\nFor other process behavior like creating new processes, linking processes and sending messages I find it more useful to use the `Kernel` functions `spawn`, `spawn_link` and `send`.\n\nMore Elixir process posts:\n[Processes for web programmers](https://tinytechtuts.com/2021-beam-elixir-processes-explained/),\n[Let it crash explained](https://tinytechtuts.com/2021-let-it-crash-explained/),\n[Processes in phoenix](https://tinytechtuts.com/2021-introduction-to-elixir-processes-in-phoenix/),\n[Processes and concurrency](https://tinytechtuts.com/2021-elixir-processes-concurrency-and-parallelism/)\n"},{"slug":"2021-elixir-processes-concurrency-and-parallelism","category":"blog","title":"Do BEAM/Elixir processes provide concurrency or enable parallelism?","description":"elixir parallelism and concurrency","tags":["elixir"],"body":"\nFor a refresher on [Elixir processes](https://tinytechtuts.com/2021-beam-elixir-processes-explained/)\n\nIf you have a concurrent application that means it has the ability to make progress on more than one task at the same time.\n\nIf an application provides parallelism that means it can execute/process multiple things at the same time.\n\nBefore multi-core processes were created the BEAM VM enabled concurrency but not parallelism. The reason here is because you could not employ multiple schedulers to process tasks in the queue at the same time, but the single scheduler was able to make progress on more than one task at a time due to its concurrent nature. The scheduler takes one process from the queue, works on it for less than a millisecond, and then puts that process back in the queue and works on another process. This queue mechanism enables concurrency.\n\nOnce multi-core processors were created you could deploy multiple schedulers, one per core. Now each scheduler can operator on different processes at the same time, thus enabling parallelism.\n\nMore Elixir process posts:\n[Processes for web programmers](https://tinytechtuts.com/2021-beam-elixir-processes-explained/),\n[Let it crash explained](https://tinytechtuts.com/2021-let-it-crash-explained/),\n[Processes in phoenix](https://tinytechtuts.com/2021-introduction-to-elixir-processes-in-phoenix/),\n[Process module cheatsheet](https://tinytechtuts.com/2021-elixir-process-module-cheatsheet/)\n\nOther useful resources:\n- https://medium.com/@itIsMadhavan/concurrency-vs-parallelism-a-brief-review-b337c8dac350"},{"slug":"2021-elixir-protocols-for-new-developers","category":"blog","title":"Elixir Protocols for new developers","description":"Elixir Protocols for new developers","tags":["elixir"],"body":"\nThis and the other \"Deck\" posts are a repurposing of flashcard study decks to Q&A blog posts. \n\n<h3>Protocols enable polymorphism in Elixir, what is polymorphism?</h3>\nIt is the ability to implement the same function with different behavior based on the data-type provided to the method.\n\n<h3>How do Protocols enable polymorphism?</h3>\nBy providing an interface to group implementations of the same method on different data types.\n\n<h3>How are protocols defined?</h3>\nFirst you need to define the protocol with `defprotcol`: \n\n```\ndefprotocol First do \n def first(data) \nend\n``` \n\nAnd then individual implementations for each type. The below implementations are for `Tuple` and `Map`: \n\n```\ndefimpl First, for: Tuple do \n def first(tuple), do: elem(tuple, 0) \nend \n\ndefimpl First, for: Map do \n  def first_key_and_value(map) do \n   keys = Map.keys(map) \n   key = List.first(keys) \n   value = map[key] \n   \"#{key}: #{value}\" \n  end \n  \n  def first(map), do: first_key_and_value(map)\nend\n```\n\n\n<h3>How do you invoke a Protocol after it is defined and implemented?</h3>\nFor the previous example we would reference the protocol and invoke the method using dot notation and pass a data type to the method that has an implementation for the protocol: \n```\nFirst.first({4, 6, 12}) \n=> 4\n``` \n\n```\nFirst.first(%{name: \"bob\", email: \"bobo@email.com\"}) \n=> \"name: bob\"\n```\n\n\n<h3>Where are protocols used in the Elixir ecosystem?</h3>\nOne example is the `Enum` module. The `Enum` modules functions can operate successfully on a `List`, `Map`, or `Range`.\n\n\n<h3>Which data types can implement a Protocol?</h3>\n`Atom`, `BitString`, `Float`, `Function`, `Integer`, `List`, `Map`, `PID`, `Port`, `Reference`, `Struct`, `Tuple`.\n\n\n<h3>How do protocols allow for cleaner code?</h3>\nThey provide another means of code organization. Any time you need the same method with different behavior, you have the option to either look for an existing protocol to add a new implementation for or to create a new protocol and extract any existing behavior into the implementations.\n\n\n<h3>Do Structs require their own Protocol implementation?</h3>\nYes. Structs share a lot of behavior with maps, but each struct requires its own protocol implementation.\n\n\n<h3>When implementing a protocol inside a struct, do you need to pass the for: option?</h3>\nNo. See the example below: \n```\ndefmodule User do \n defstruct [:email, :name] \n\n defimpl Size do \n  def size(%User{}), do: 2 \n end \nend\n```\n\n\n<h3>How do you fallback to a default implementation if a protocol is invoked that doesn't have an implementation for that type?</h3>\nUse the `@fallback_to_any` attribute, ex: \n```\ndefprotocol First do \n  @doc \"GET the first value from collections\" \n  @fallback_to_any true \n  def first(data) \nend\n``` \n  \nAnd then implement `first` for `Any` \n```\ndefimpl First, for: Any do \n  def first(_), do: nil \nend\n```\n"},{"slug":"2021-elixir-structs-for-new-developers","category":"blog","title":"Learn Elixir through Q&A: Structs","description":"learn Elixir Structs","tags":["elixir"],"body":"\nThis and the other \"Deck\" posts are a repurposing of flashcard study decks to Q&A blog posts. \n\n<h3>What are Structs?</h3>\nAn Elixir key/value data structure. They are also extensions of the Map module and thus share similar functionality.\n\n<h3>What are some differences between Structs and Maps?</h3>\n<ul>\n<li>Structs do not have access to Enum functions like Maps do</li> \n<li>The keys for a Struct must be included in its definition.</li> \n<li>If a key is provided to a Struct that the Struct is unaware of an error will be raised.</li> \n<li>Only atoms can be used as keys in a Struct.</li> \n</ul>\n\n<h3>How is a Struct defined?</h3>\nFrom inside a module using the defstruct macro. Ex: \n```\ndefmodule User do \n  defstruct email: \"lisa@gmail.com\", age: 29, name: \"Lisa\" \nend\n```\n\n\n<h3>How would you instantiate a new Struct using the previous cards User struct definition?</h3>\nThe examples below are two separate structs created from the User struct. \n```\nlisa = %User{} => %User{age: 29, email: \"lisa@gmail.com\", name: \"Lisa\"} \njim = %User{name: \"Jim\", email: \"jim@gmail.com\"} \n=> %User{age: 29, email: \"jim@gmail.com\", name: \"Jim\"}\n```\n\n\n<h3>How do you update a Struct?</h3>\nThe same way you would update a `Map`. Using the `|` operator: \n```\njim = %User{name: \"Jim\", email: \"jim@gmail.com\", age: 24} \njim = %{jim | age: 30} \n=> %User{age: 30, email: \"jim@gmail.com\", name: \"Jim\"}\n```\n\n\n<h3>How do you access a value in a Struct?</h3>\nThe same way you would access a value in a Map: \n```\njim = %User{name: \"Jim\", email: \"jim@gmail.com\", age: 24} \njim.email \n=> \"jim@gmail.com\"\n```\n\n\n<h3>How do you delete a key/value from a Struct?</h3>\nYou don't. `Struct` definitions are constant. If you need a more dynamic key/value store, a `Map` should be used.\n\n\n<h3>Can you set a Struct key without a default value?</h3>\nYes, but it must come at the end of the beginning of the definition. Ex: \n```\ndefmodule User do \n  defstruct [:email, age: 29, name: \"Lisa\"]\nend\n```\n"},{"slug":"2021-elixir-tuples-explained","category":"blog","title":"Elixir Tuples explained through q&a","description":"elixir tuples explained","tags":["elixir"],"body":"\nThis post works best when paired with the [Elixir docs](https://hexdocs.pm/elixir/1.12/Tuple.html) for a general overview of Tuples.\n\n<h3>What is an Elixir Tuple?</h3>\nIt is a collection data type in Elixir defined using curly brackets `{}`\n\n<h3>When should you use a Tuple?</h3>\nAs response objects. The most often take the form of `{:ok, response_data_1, response_data_2}` or `{:error, message}`.\n\n<h3>Should you use a Tuple to store a collection of application data you want to iterate over?</h3>\nNo you should use a `List`. Writing and performing operations on a collection in Elixir was designed to be handled using lists.\n\n<h3>How do you add an element to an existing Tuple?</h3>\nOne way is to use the `Kernel` `put_elem/3` function. The example below takes a `Tuple`, an index in that `Tuple`, and a new value for that index and creates a new `Tuple`.\n```\n=> put_elem({:ok, \"fish\", \"penguin\"}, 1, \"lobster\")\n{:ok, \"lobster\", \"penguin\"}\n```\n\n<h3>What happens when you try to use put_elem/3 with a non-existing index?</h3>\nAn `ArgumentError` is raised.\n```\n=> put_elem({:ok, \"fish\", \"penguin\"}, 3, \"lobster\")\n** (ArgumentError) argument error\n```\n\n<h3>How do you retrieve an element from a Tuple without pattern matching?</h3>\nUsing the `Kernel` `elem/2` function and passing it the tuple and the index of the value you want to get.\n```\n=> aqua_friends = {:ok, \"fish\", \"penguin\"}\n=> elem(aqua_friends, 1)\n\"fish\"\n```\n\n<h3>How do you retrieve an element from a Tuple through pattern matching?</h3>\nBy using Elixirs match operator `=` to destructure the tuple. See the example below:\n```\n=> {:ok, diet, animal} = {:ok, \"fish\", \"penguin\"}\n=> diet\n\"fish\"\n=> animal\n\"penguin\"\n```\n\n<h3>How do you remove an element from a Tuple?</h3>\nUsing the `Tuple` `delete_at/2` function and passing it the tuple and the index of the value you want to remove.\n```\n=> Tuple.delete_at({:ok, \"lobster\", \"penguin\"}, 2)\n{:ok, \"lobster\"}\n```\n\nMore Elixir Decks:\n1. [Atoms and Integers](https://tinytechtuts.com/2021-elixir-atoms-and-integers-explained/)\n2. [List](https://tinytechtuts.com/2021-elixir-lists-explained/)\n"},{"slug":"2021-everything-to-know-dates-and-times-ruby-and-rails","category":"blog","title":"Everything you may have wanted to know about Dates and Times in Ruby and Rails","description":"Everything you may have wanted to know about Dates and Times in Ruby and Rails","tags":["ruby","rails"],"body":"\n\nI wrote this post as a reference to myself for when I need to work with Dates/Times on different projects. I hope you find it helpful.\n\n...\n\n<h3>How do you change the an applications time zone using Rails?</h3>\nUpdate the `config/application.rb` value for `config.time_zone = \"American Samoa\"`\n\n<h3>If you update an applications time zone, what conflicts might arise between the system time and the application time?</h3>\nUnless you have your application deployed in the same region that you set the time zone for, they will be on different time zones. On the `DateTime` object there is a `#now` method that will return the date and time using the systems timezone and this can be easily thought to be the applications timezone. In this scenario you will want to use `DateTime.current` which reflects the applications timezone. If you do not update the timezone for your application this does not apply.\n\n<h3>Let's say you have a resource in your application which you would like to share with users, a report in this case. On the report you want to show the time the report was created in your users local time, how do you handle that?</h3>\nThere is no built in methodology to help with this. In your system you will have to capture the users time zone on the client and pass it to the server to be stored for future reference. [Thoughtbot](https://thoughtbot.com/blog/its-about-time-zones){:taget=\"_blank\"} wrote a good blog that illustrates a clean way of handling this.\nThis post from [Viget](https://www.viget.com/articles/using-time-zones-with-rails/) also illustrates a few options for this.\n\n<h3>What format should be used when sending dates and times to API's?</h3>\n`ISO8601`. This is the most widely supported standard in systems today. To convert a date/time object to this standard in Ruby:\n```\nreport.created_at.to_s(:iso8601)\n```\n\n<h3>How do time offsets work in regards to UTC and timezones?</h3>\nCoordinated Universal Time aka UTC is the default \"timezone\" in Rails but it is not a timezone, rather it is a universal standard for keeping time based on atomic time. UTC offsets then are an amount of time subtracted from or added to UTC time to specify the local time.\n\n<h3>In your Ruby codebase do you need to convert times/dates to a standard format to compare if two dates are the same?</h3>\nNo, that is handled for you:\n\n```\nt1 = Time.parse('2017-07-13T17:13:12-04:00')\n#=> 2017-07-13 17:13:12 -0400\n\nt2 = Time.parse('2017-07-13 21:13:12 UTC')\n#=> 2017-07-13 21:13:12 UTC\n\nt1 == t2\n#=> true\n```\n[Source](https://stackoverflow.com/questions/45091068/how-to-compare-times-in-different-time-zones-in-ruby){:taget=\"_blank\"}\n\n\n<h3>How do you query for the current time in UTC when using Rails vs non Rails</h3>\nRails: `DateTime.current.utc`\nNon Rails Project: `Time.current.utc`\n\n\n<h3>How to get the current timezone:</h3>\n```\n=> Time.zone.name\n\"Perth\"\n```\n\n<h3>When using Rails you can get all available time zones using the rake task:</h3>\n```\nrake time:zones:all\n```\n\n<h3>Rails records by default are saved in the UTC timezone.</h3>\n1. Getting retrieving an ActiveRecord record from your DB and retrieving its timestamp:\n```\nUser.first.created_at\n=> Thu, 24 Jun 2021 18:39:01 UTC +00:00\n```\n\nNote here the zone is indicated by `UTC +00:00`\n\n2. Check that against the output of `rake time:zones:all` and check that output for the previously mentioned `UTC +00:00`. You will find UTC in that timezone list.\n\n```\n* UTC +00:00 *\nCasablanca\nDublin\nEdinburgh\nLisbon\nLondon\nMonrovia\nUTC\n```\n\n<h3>How to check if an object is an instance of date or Timeor DateTime in Ruby?</h3> [Source](https://stackoverflow.com/questions/37976719/how-to-check-if-variable-is-date-or-time-or-datetime-in-ruby)\n```\nif d.respond_to?(:strftime)\n  # d is a Date or DateTime object\nend\n```\n\n\n"},{"slug":"2021-example-of-when-to-expire-cache-key","category":"blog","title":"An example of when to expire a cache key","description":"when to expire a cache key","tags":["rails","caching"],"body":"\nIf you are using a cache key to keep track of queue processing status, said another way, to check if the queue is busy, then it will likely be a good idea to expire those keys. If the queue processing were to error and as a result that key never was deleted, the queue would never be free for additional processing. The only consideration is the maximum amount of processing time that would occur and then add buffer time to it to make sure the cache does not expire prematurely.\n\nTo add an expiration to a cache key in Rails use the `expires_in` option when writing to the cache:\n\n```\nRails.cache.write(\"queue_status_key_id\", true, expires_in: 10.minutes)\n```\n\nYou could also handle this by catching any error thrown during processing and deleting the key, whichever way is more reusable in your specific circumstance.\n"},{"slug":"2021-fix-ruby-no-preset-version-installed-asdf","category":"blog","title":"Ruby no preset version installed asdf","description":"fix ruby error no preset version installed","tags":["ruby"],"body":"\nThe issue I faced here was:\n1. I installed a new version of ruby\n2. I added that version to my .tool-versions file\n3. I tried to run the application and was faced with the error `No preset version installed for ...`\n\nI imagine others will face this issue with different plugins, but the answer for me was to reshim so that the exectuables were created for the Ruby version I wanted to use:\n\n```\nasdf reshim ruby 2.5.6\n```\n\nAfter that I was able to run ruby executables for Rbuy 2.5.6.\n"},{"slug":"2021-get-text-from-url-string-ruby","category":"blog","title":"How to get text from a URL string in Ruby","description":"url text from string ruby","tags":["ruby"],"body":"\nI ran into the scenario where an api was sending over a url string as a configuration item to use later in a workflow. That string also contained a resource UUID I needed for the current part of the workflow so I needed to parse that string for the UUID.\n\nI first thought to use a regular expression to match and capture the text I needed but then I had an idea to split the string into an array based on forward slashes in the URL.\n\nThe final result looked like this:\n\n```\n=> url = \"https://bluecanoes.com/spring-2020/orders/23445erwtwer323\"\n=> url.split(\"/\")[5]\n=> 23445erwtwer323\n```\n\nIn the above example the URL is parsed into an array containing the captured values using the `split` method:\n\n```\n=> url = \"https://bluecanoes.com/spring-2020/orders/23445erwtwer323\"\n=> url.split(\"/\")\n=> [\"https:\", \"\", \"bluecanoes.com\", \"spring-2020\", \"orders\", \"23445erwtwer323\"]\n```\n\nFrom there you can access the value you need, in my case 23445erwtwer323.\n\nThe downside to this solution is if the number of forward slashes in the URL ever changes, this needs to be updated. Make sure there is a test that would fail if the number of forward slashes ever changed.\n\n"},{"slug":"2021-get-username-for-git-npm","category":"blog","title":"How to get your username in Git and NPM","description":"get usernames in git and npm","tags":["git","npm"],"body":"\nThis is a cheatsheet/reference guide for accessing your username for the titled technologies:\n\nGet git username:\n```\ngit config --list\n```\nThe above command will provide your current git username and email. If you run it from a directory with git tracking it will provide additional git repo information such as the git url.\n\nGet NPM username:\n```\nnpm whoami\n```\nThe above command will provide your username with no additional information.\n\n"},{"slug":"2021-graphql-required-arguments","category":"blog","title":"How to tell if an argument is required in Graphql?","description":"required arguments in graphql","tags":["graphql"],"body":"\nOne of the powerful features of Graphql is its dynamic nature. In this case referring to the ability to pass different data to the same queries and mutations, but what if you need to ensure one of those data fields is required?\n\n<h3>Reading an existing schema</h3>\nIf you are looking at an existing schema in Graphiql you can tell if a data type is required based on whether the type declaration ends in a bang `!`. In the below example the only required data elements for the information node are `name` and `search`:\n\n```\ninformation(\nsearch: String!\norder: String\nname: String!\nvalue: String\nbefore: String\nafter: String\nfirst: Int\nlast: Int): InformationConnection\n```\n\n<h3>Marking a type as required in a schema</h3>\nTo mark a type as required go to the file which defines the schema object type and add the bang `!` to set it to required.\n\n```\ntype InformationConnection {\n  search: ID!\n  name: String!\n  ...\n}\n```\n\nFor your continued enjoyment:\n- [How to set default values in Graphql Schemas](https://tinytechtuts.com/2021-graphql-schema-default-values/)"},{"slug":"2021-graphql-schema-default-values","category":"blog","title":"How to set default values in Graphql Schemas","description":"default values in graphql","tags":["graphql"],"body":"\nI think setting default GQL values is best illustrated through two annotated examples:\n\n<h3>1) Setting a default for a non-nested type:</h3>\n\nIn the below example the CoffeeOrder type has a field of size which sets a default value for the CupSize type of SMALL.\n\n```\ntype CoffeeOrder {\n  name: String!\n  size: CupSize = SMALL\n}\n```\n\nAnnotated spec:\n```\nfield: FieldType = defaultValue\n```\n\n\n<h3>2) Setting a default for a nested type:</h3>\n\nThe below example is a different implementation of the CoffeeOrder type. This time there is a field cup that contains a field size, which has a default value of SMALL:\n\n```\ntype CoffeeOrder {\n  name: String!\n  cup(size: CupSize = SMALL): Cup\n}\n```\n\nAnnotated spec:\n```\nfield(subfield: SubFieldType = defaultValue: FieldType\n```\n\nFor your continued enjoyment:\n- [How to tell if an argument is required in Graphql?](https://tinytechtuts.com/2021-graphql-required-arguments/)\n"},{"slug":"2021-how-to-base64-encode-string-from-command-line","category":"blog","title":"How to base64 encode a string using the command line on macOS","description":"base64 encode a string using Mac","tags":["macos"],"body":"\n```\necho -n 'blueballoons' | base64\n=> Ymx1ZWJhbGxvb25z\n```\n\nThe `echo` commands job is to output the string that is passed to it as an argument. By passing the `-n` flag we do not get the trailing newline in our output. Then we use the `|` to pipe the output to `base64` which base64 encode the string, in this case \"blueballoons\".\n\nSimilar post:\n- [How to get and filter a list of previously executed commands on macOS](https://tinytechtuts.com/2021-how-to-get-and-filter-previously-executed-commands-macos/)"},{"slug":"2021-how-to-get-and-filter-previously-executed-commands-macos","category":"blog","title":"How to get and filter a list of previously executed commands on macOS","description":"base64 encode a string using Mac","tags":["macos"],"body":"\n```\nhistory\n=> output the the last 10000 or so commands executed.\n```\n\nThe `history` command on macOS will output your previously executed commands in the order they were executed.\n\nYou can filter the output by piping it to the `grep` command like so:\n\n```\nhistory | grep docker\n```\n\nThe above command will output only Docker commands from your history.\n\nThe output will also provide you the uid of the command executed and you can use that to rerun the command you were looking for. For example if your history's output was the below list and you wanted to rerun `docker image ls`...\n\n```\n10080  cd docker\n10088  docker image ls\n10089  history | grep docker\n10090  docker build --tag=reporting-app .\n10095  docker build --tag=reporting-app .\n```\n\nYou could do so by executing this on your terminal:\n\n```\n!10088\n```\n\nSimilar post:\n- [How to base64 encode a string using the command line on macOS](https://tinytechtuts.com/2021-how-to-base64-encode-string-from-command-line/)"},{"slug":"2021-how-to-read-gemfile-versions-in-ruby","category":"blog","title":"How to read Ruby Gemfile package versions","description":"How to read Ruby Gemfile versions","tags":["ruby"],"body":"\nWhen I was looking into how to read RubyGem versions in Gemfile's I was hoping to find some examples to reference but didn't find quite what I was looking for. I hope these annotated examples are helpful:\n\n```\ngem 'rails', '~> 6.1.4'\n```\n\nThe above `gem` method says to install Rails at a version greater than or equal to 6.1.4 (>= 6.1.4) and less than 6.2 (< 6.2).\n\n```\ngem 'wisper', '~> 2.0', '>= 2.0.1'\n```\n\nThe above `gem` method has two arguments. The first says to install the Wisper gem at a version greater than or equal to 2.0 (>= 2.0) and less than 3.0 (< 3.0). The second argument makes it more specific and requires that the version be greater than or equal to 2.0.1.\n\nSimilar post:\n- [The missing guide to troubleshooting RubyGem issues](https://tinytechtuts.com/2021-the-missing-guide-to-troubleshooting-rubygem-issues/)\n"},{"slug":"2021-how-to-set-state-from-url-in-react","category":"blog","title":"How to set state from a URL using React","description":"react state from url","tags":["react"],"body":"\nDuring the development of a view for an OAuth application I wanted to reuse an already existing login screen that had session create functionality I needed. I wanted to add some new logic based on if the login screen was for the OAuth workflow or original user login screen the functionality had previously been built for.\n\nTo accomplish this I chose to set state based on the url because the OAuth url contained the path `/oauth` and then I could base other checks around that state.\n\nI needed to set this state before render so I added it to the constructor of a class based component. The result looked like this:\n```\nconstructor(props) {\n  super(props);\n\n  this.state = {oauthApp: null, oauthProviderFlow: window.location.pathname.includes(\"oauth\")};  \n}\n```\n\nAbove I check that the url path contains the substring \"oauth\" and update the state to true if that is the case. From there I will have that state available for the first render.\n"},{"slug":"2021-how-to-use-a-configmap-file-for-postgres-url-kubernetes","category":"blog","title":"How to use a ConfigMap file for postgres environment variables in Kubernetes","description":"How to use a ConfigMap file for postgres environment variables in Kubernetes","tags":["kubernetes"],"body":"\nIn order to keep environment variables independent of the application itself in a Kubernetes environment there is a specific component called a ConfigMap. After a ConfigMap configuration is applied in a Kubernetes environment its values will be available for configuring pods to connect to services such as a postgres db.\n\nMaking the ConfigMap available in a K8's environment requires 2 steps:\n1) Defining the ConfigMap component in a configuration file\n2) Applying the ConfigMap file to the Kubernetes environment\n\n<h3>Defining the ConfigMap component in a configuration file</h3>\n\nNOTE: all of the ConfigMap values that you want to reference reside under the `data` key. In this example `data.database_url`.\n\n```\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: reporting-app-configmap\ndata:\n  database_url: reporting-db-service\n```\n\n<h3>Applying the ConfigMap file to the Kubernetes environment</h3>\n\nTo make the ConfigMap available in your environment run the `kubectl apply` command with a `-f` flag and pass in the filename.\n```\nkubectl apply -f /fullpath/to/reporting-app-configmap.yaml\n```\n\nAfter the ConfigMap is deployed to your environment you can reference them in deployments and services. They can be referenced in the `env` section of on of those files. Take this deployment file as an example\n\n```\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: reporting-app-deployment\n  labels:\n    app: reporting-app\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: reporting-app\n  template:\n    metadata:\n      labels:\n        app: reporting-app\n    spec:\n      containers:\n      - name: reporting-app\n        image: jtburum/project1:v.0.0.4\n        ports:\n        - containerPort: 3000\n        env:\n        - name: POSTGRES_USER\n          valueFrom:\n            secretKeyRef:\n              name: reporting-app-secrets\n              key: postgres-db-username\n        - name: POSTGRES_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: reporting-app-secrets\n              key: postgres-db-username\n        - name: POSTGRES_URL\n          valueFrom:\n            configMapKeyRef:\n              name: reporting-app-configmap\n              key: database_url\n```\n\nThere is extra data in the snippet above unrelated to the secrets accessors, but I figured it would be more relevant to post the entire file. The secrets as you can see are accessed under `spec.template.spec.containers.env-name.valueFrom.configMapKeyRef.key`. You mostly need to remember to pull secrets using `valueFrom.configMapKeyRef.key`.\n\nSimilar posts:\n- [When to use which service type in Kubernetes](https://tinytechtuts.com/2021-when-to-use-kubernetes-service-types-configip-loadbalancer-nodeport/)\n- [Connecting Kubernetes Deployments to Pods](https://tinytechtuts.com/2021-connecting-pods-to-deployments-kubernetes/)\n- [How to view a Kubernetes pods IP address](https://tinytechtuts.com/2021-how-to-view-kubernetes-pod-ip-address/)\n- [How to view the status data in a Kubernetes Deployment](https://tinytechtuts.com/2021-how-to-view-the-status-data-of-a-kubernetes-deployment/)\n- [Create your first Rails app cluster with Kubernetes and Docker](https://tinytechtuts.com/2021-create-your-first-kubernetes-rails-app-pt1/)\n- [Kubernetes kubectl commands for newbies](https://tinytechtuts.com/2021-kubernetes-kubectl-commands-for-newbies/)"},{"slug":"2021-how-to-use-a-secrets-file-for-postgres-credentials-kubernetes","category":"blog","title":"How to use a secrets file for postgres credentials using Kubernetes","description":"How to use a secrets file for postgres credentials using Kubernetes","tags":["kubernetes"],"body":"\nIn order to keep credentials safe in a Kubernetes environment there is a specific component called a secret. After a secrets configuration is applied in a Kubernetes environment its values will be available for configuring pods to connect to services such as a postgres db.\n\nMaking the secrets available in a K8's environment requires 3 steps:\n1) Encoding the values for the secrets in base64\n2) Defining the secrets component in a configuration file\n3) Applying the secrets file to the Kubernetes environment\n\n<h3>Encoding the values for the secrets in base64</h3>\nTo encode the credentials in base64 utilize the following command in the terminal:\n\n```\necho -n 'postgres_un' | base64\n```\n\nThis will output 'postgres_un' in base64.\n\n<h3>Defining the secrets component in a configuration file</h3>\n\nA few notes on the secrets configuration below:\n- `type: Opaque` - This indicates that the secrets in the file are unstructured, as opposed to types such as `ServiceAccount` or `ImagePullSecret` which have restrictions on the values that can be declared.\n- All of the secrets values that you want to reference reside under the `data` key. In this example `data.postgres-db-username` and `data.postgres-db-password`.\n\n```\napiVersion: v1\nkind: Secret\nmetadata:\n  name: reporting-app-secrets\ntype: Opaque\ndata:\n  postgres-db-username: cG9zdGdyZXM=\n  postgres-db-password: cG9zdGdyZXM=\n```\n\n<h3>Applying the secrets file to the Kubernetes environment</h3>\n\nTo make the secrets available in your environment run the `kubectl apply` command with a `-f` flag and pass in the filename.\n```\nkubectl apply -f /fullpath/to/reporting-app-secrets.yaml\n```\n\nAfter the secrets are deployed to your environment you can reference them in deployments and services. They can be referenced in the `env` section of on of those files. Take this deployment file as an example\n\n```\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: reporting-app-deployment\n  labels:\n    app: reporting-app\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: reporting-app\n  template:\n    metadata:\n      labels:\n        app: reporting-app\n    spec:\n      containers:\n      - name: reporting-app\n        image: jtburum/project1:v.0.0.4\n        ports:\n        - containerPort: 3000\n        env:\n        - name: POSTGRES_USER\n          valueFrom:\n            secretKeyRef:\n              name: reporting-app-secrets\n              key: postgres-db-username\n        - name: POSTGRES_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: reporting-app-secrets\n              key: postgres-db-username\n        - name: POSTGRES_URL\n          valueFrom:\n            configMapKeyRef:\n              name: reporting-app-configmap\n              key: database_url\n```\n\nThere is a lot of extra data in there unrelated to the secrets accessors, but I figured it would be more relevant to post the entire file. The secrets as you can see are accessed under `spec.template.spec.containers.env-name.valueFrom.secretKeyRef.key`. You mostly need to remember to pull secrets using `valueFrom.secretKeyRef.key`.\n\nSimilar posts:\n- [When to use which service type in Kubernetes](https://tinytechtuts.com/2021-when-to-use-kubernetes-service-types-configip-loadbalancer-nodeport/)"},{"slug":"2021-how-to-view-kubernetes-pod-ip-address","category":"blog","title":"How to view a Kubernetes pods IP address","description":"How to view a Kubernetes pods IP address","tags":["kubernetes"],"body":"\nTo begin you will first need to get the ID of the pod whose IP address you are looking for using the command:\n\n```\nkubectl get pods\n```\n\nThis will give you a list of pods your Kubernetes environment knows about along with status data. The `NAME` column is the ID for each pod.\n\nThen you can use the below command to get the IP address and additional data about the pod:\n\n```\nkubectl get pod reporting-app-deployment-8678d5688b-n2xvb -o wide\n```\n\nUsing the above command without the option `-o wide` would only have rendered the status data mentioned previously.\n\nSimilar post:\n- [Kubernetes kubectl commands for newbies](https://tinytechtuts.com/2021-kubernetes-kubectl-commands-for-newbies/)"},{"slug":"2021-how-to-view-the-status-data-of-a-kubernetes-deployment","category":"blog","title":"How to view the status data in a Kubernetes Deployment","description":"How to view the status data in a Kubernetes Deployment","tags":["kubernetes"],"body":"\nNote:\nIf you are interested in creating a Kubernetes Deployment check out this previous post:\n- [Create your first Rails app cluster with Kubernetes and Docker](https://tinytechtuts.com/2021-create-your-first-kubernetes-rails-app-pt1)\n\nOn with the show...\n\nIn every Kubernetes Deployment there are 3 sections to the configuration file:\n1) metadata\n2) spec\n3) status\n\nThe first two are explicitly written in a configuration file by you the engineer but the status section gets added by K8's when the deployment is triggered. It is the clusters master node's etcd component that contains this data as it tracks the expected state vs the currently deployment state of the cluster.\n\nTo print the output of the K8's deployment to your terminal and also view the status data in YAML format use the following command:\n\n```\nkubectl get deployment reporting-app-deployment -o yaml\n```\n\nYou will see a lot of data populated by K8's in each section of the output, but the key thing to note is the `status:` section which can be useful to see if your expected K8's environment matches what is currently running. Specifically check that the values for `status.availableReplicas` matches `spec.replicas`.\n\nSimilar post:\n\n- [Connecting Kubernetes Deployments to Pods](https://tinytechtuts.com/2021-connecting-pods-to-deployments-kubernetes/)\n"},{"slug":"2021-http-status-code-ranges","category":"blog","title":"HTTP Status Code Range Meanings - 100, 200, 300, 400, 500","description":"http status code general meanings","tags":["http"],"body":"\nI wanted to sure up that I knew what a general 100-500 status code's meant when I received them as response's from a server or browser so I went about exploring the internet and very generally derived:\n\n- 100's - Informational codes used to relay information between client and server during a request. Example 100 code: The server received the request headers and determined the client is okay to continue sending the request body.\n- 200's - success codes. These indicate that the request issued was successfully fulfilled.\n- 300's - redirect codes. These codes are used to tell the browser or server that some other action needs to take place to complete the previous request.\n- 400's - client errors. These indicates an error on the requesters behalf.\n- 500's - server errors. These indicates an error on the servers behalf.\n\n"},{"slug":"2021-introduction-to-elixir-processes-in-phoenix","category":"blog","title":"An introduction to BEAM/Elixir processes in Phoenix","description":"elixir processes in phoenix","tags":["elixir"],"body":"\nI will introduce this through a two example web interaction\n\n1) A web request that runs some application code.\n2) A web request that runs some application code and that application code reaches out to a database.\n\nEach step of this interaction is a separate Elixir Process.\n\nThe Phoenix web framework sets up an HTTP server using the libraries Cowboy and Ranch. When a request is sent to your application over HTTP a Cowboy process is spawned to handle it, once the request is received and validated another Elixir Process is spawned and therefore supervised by the Cowboy process. This newly spawned Process is for the application code to handle any business logic required before the HTTP server responds. Once the application process has finished executing a message is sent back to the Cowboy/HTTP process that generated it and the connection is closed.\n\nNow let's say the application code called an `Ecto.Repo` database for a query, this scenario is a slightly different.\n\nWhen your Phoenix application was started, assuming you are using Ecto for database interactions, a pool of (usually 10) long running processes are started immediately and waiting to be used for code execution. These are started immediately instead of being spawned each time the Repo is called because connecting to the database is a \"heavy\" task, meaning it takes more time and computer resources to execute than other processes that are not pooled. The Erlang and Elixir process pooling technology is Poolboy.\n\nWhen your application code makes a query using Repo, it uses one of the established pooled process connections to do so. Once the query completes then a message is sent to the application process. At that point the application process continues any additional code execution before sending the final response to the HTTP process.\n\nThere are many more processes running in any Phoenix application. My hope is after reading this it will give you confidence to explore more of the ecosystem.\n\n<h2>Aside: Observer</h2>\n\nTo get a visualization of Elixir processes in your Phoenix application run the following command:\n\n```elixir\niex -S mix phx.server\n```\n\nThis starts your server in interactive mode. From there you start Observer, Elixirs process introspection tool through this command:\n\n```elixir\n:observer.start\n```\n\nOnce opened navigate to the applications tab to get a diagram of all running processes, you can try restarting processes to get more hands on experience with their behavior.\n\nMore Elixir process posts:\n[Processes for web programmers](https://tinytechtuts.com/2021-beam-elixir-processes-explained/),\n[Let it crash explained](https://tinytechtuts.com/2021-let-it-crash-explained/),\n[Processes and concurrency](https://tinytechtuts.com/2021-elixir-processes-concurrency-and-parallelism/),\n[Process module cheatsheet](https://tinytechtuts.com/2021-elixir-process-module-cheatsheet/)"},{"slug":"2021-iterate-and-convert-xss-collection-in-ruby","category":"blog","title":"Iterate and convert an XSS collection to hash in Ruby","description":"xss elements formatted to hash","tags":["ruby","xml"],"body":"\nI was working with a collection of elements in an XSS payload. Here's the payload:\n\n```\n<fields>\n  <entry>\n    <key>Email</key>\n    <value>terry.blogger@blogs.com</value>\n  </entry>\n  <entry>\n    <key>GivenName</key>\n    <value>Terry</value>\n  </entry>\n  <entry>\n    <key>FamilyName</key>\n    <value>Blogger</value>\n  </entry>\n</fields>\n```\n\nIn order to work with this payload I first used `Nokogiri` to turn the payload into an XML document:\n`document = Nokogiri::XML(response_string)`\n\nThen I passed that document to a class method that converted the values to a formatted hash that would be easier to work with. I used the css method to iterate ones over each field and then a second time to the entry field name and values for the hash:\n\n```\ndef fields_to_hash(document)\n  account_hash = {}\n\n  document.css(\"fields\").map do |additional_params|\n    additional_params.css(\"entry\").map do |param|\n      account_hash[param.css(\"key\").text] = param.css(\"value\").text\n    end\n  end\n\n  account_hash\nend\n```\n\nI hope this helped you in solving whichever problem brought you here."},{"slug":"2021-jest-testing-cheatsheet","category":"blog","title":"Jest testing with React cheatsheet","description":"Jest testing with react tips","tags":["jest"],"body":"\nA few notes to refer to when needing to write JavaScript tests using Jest and React:\n\n*This is not a comprehensive post. It is a brief reference for developers with some experience using Jest but haven't used it recently.\n\n1) Two types of frequently used test expectations are:\n- Expecting the DOM tree to match that of a snapshot\n- A functional test where you execute an event and match an updated value against an expected state.\n\n<div></div>\n\n2) A few frequently used Jest expectations are:\n- `toHaveBeenCalled` - Use to expect a certain function to have been invoked.\n- `toHaveBeenCalledWith` - Use to expect a certain function to have been invoked with a specific argument(s).\n- `toMatchSnapshot` - Use to expect a DOM tree to match your expected HTML document.\n- `toHaveProperty` - Use to check if an object has a specific property.\n\n<div></div>\n\n3) To mock a JavaScript import you can use `jest.mock` that will be used in place of the typically imported file:\n\n```\njest.mock(\"components/results\", () => (() => (<div className=\"mock\">User Results</div>)));\n```\n\n4) Use `beforeEach` to perform any setup needed for a group of tests. You can use this to set shared variables/state or execute any functions that should be run before each test.\n\n<div></div>\n\n5) Use `jest.fn()` function to execute a mock function. You can also give the mock function a name using `jest.fn().mockName(\"myFunctionName\")`.\n\n<div></div>\n\n6) Some expectations also have an inverse using the `not` function. Example:\n\n```\nexpect({name: \"joe\"}).not.toHaveProperty(\"email\")\n```\n\n7) When mocking an import and you want to use some of the actual behavior of the module but not all, you can use `jest.requireActual`\n\n```\njest.mock(\"react-router-dom\", () => ({\n  __esModule: true,\n  ...jest.requireActual(\"react-router-dom\"),\n  useParams: jest.fn().mockName(\"useParams\")\n}));\n```\n"},{"slug":"2021-kubernetes-configfile-ports-explained","category":"blog","title":"Kubernetes configuration ports explained","description":"Kubernetes configuration ports explained","tags":["kubernetes"],"body":"\nWhen starting to work with Kubernetes there are many port declarations in configuration files and it can be easy to forget which port is responsible for which traffic, I hope this post can be a reference for you when those situations arise.\n\nPorts defined in deployment configuration:\n1) `spec.containers.ports.containerPort` - This is the port at which the pod/container is reachable.\n\nPorts defined in service configuration:\n1) `spec.ports.nodePort` - This is the port of the node(s) in the cluster. It is the port at which the node can be reached from external traffic.\n2) `spec.ports.port` - This is the port of the cluster service itself. After receiving a valid request the traffic will be forwarded to the pod/containers `targetPort`\n3) `spec.ports.targetPort` - This is the port the service will forward requests to. It is the port your pod/container is listening for requests on.\n"},{"slug":"2021-kubernetes-kubectl-commands-for-newbies","category":"blog","title":"Kubernetes kubectl commands for newbies","description":"Kubernetes kubectl commands for people new to Kubernetes","tags":["kubernetes"],"body":"\n\nThe goal with this post is to share K8's commands I've found useful in my first few attempts to deploy K8's components. I hope you find it to be a handy reference in your K8's journey.\n\n...\n\n\n```\nkubectl get pods\n```\nThis command can be replaced with many other K8's components like deployment, service, nodes etc. and will return a list of those components running in your environment and their status information\n\n```\nkubectl get pod pod_id\n```\n\nThis command can be replaced with many other K8's components like deployment, service, node etc. and will return status information about the given component\n\n```\nkubectl get pod pod_id -o wide\n```\nThis command will give you more detailed information about the component as well as its status information\n\n\n```\nkubectl exec -it pod_id -- sh\n```\nThis command will bring you into the shell of the container pod\n\n\n```\nkubectl delete deployment deployment_id\n```\nThis will delete the deployment and any pods associated. The same can be done with K8's services.\n\n\n```\nkubectl get endpoints\n```\nUse this command to get a list of service endpoints running in your environment and details about them such as IP address and port.\n\n\n```\nkubectl edit deployment deployment_id\n```\nThis command will allow you to update a deployment from the command line. After executing the update any new changes to the deployment environment will take place.\n\n```\nkubectl apply -f config-file-name.yaml\n```\nThis will take the config file and create the K8's components involved. This could be a service, deployment, configMap or secret.\n\n```\nkubectl describe service service_id\n```\nUse this command to get more detailed information about a K8's component such as a service, pod, etc.\n\n```\nkubectl get all\n```\nThis command can be used to see all running components in a K8's environment\n\n"},{"slug":"2021-kubernetes-master-node-processes-explained","category":"blog","title":"Kubernetes Control Plane processes explained","description":"Kubernetes Control Plane processes explained","tags":["kubernetes"],"body":"\n* This post assumes you are familiar with Kubernetes components such as pods and nodes.\n\nKubernetes Control Plane is the the overseer of your K8s cluster environment. It controllers the cluster state and it's nodes. The Control Plane has four distinct processes/responsibilities:\n1) kube-apiserver\n2) kube-scheduler\n3) kube-controller-manager\n4) etcd\n\n<h3>kube-apiserver</h3>\n\nThis is how users interact with a Kubernetes cluster. When you deploy a cluster or need to make updates you will do so through the kube-apiserver which can be accessed through a command line tool like kubectl or a Kubernetes dashboard. The kube-apiserver can be thought of as the entrypoint/gateway to the cluster.\n\n<h3>kube-scheduler</h3>\n\nThe kube-scheduler processes job is to <b>decide</b> which node to run a new pod on. This could be a pod that crashed and needs to be restarted or when deploying a new pod to the cluster. An important note is the kube-scheduler process does not actually perform the deployment of the new node, that is handled by the Kubelet process on the individual node that the pod is scheduled to run on, the kube-scheduler only job is to decide which node a pod should run within. It decides where to schedule a pod based on resource utilization of the existing nodes.\n\nScheduling a new pod flow:\nsend a request to the API server -> kube-scheduler decides where the new pod should reside in the node cluster -> kubelet on the node spins up the pod.\n\n<h3>kube-controller-manager</h3>\n\nThis process is monitoring for changes that occur within the cluster environment. If a pod fails and a new one needs to be started in its place the kube-controller-manager will detect it this and notify the kube-scheduler.\n\nDetecting state changes flow:\nA Pod dies -> kube-controller-manager notices this event and notifies the kube-scheduler -> kube-scheduler decides where the new pod should reside in the node cluster -> kubelet on the node spins up the pod.\n\n<h3>etcd</h3>\n\nThis is a Key Value store of a clusters state. Every time a change happens in the cluster the etcd data will be updated appropriately. It contains the data the other processes need to operate. For example:\n- The kube-controller-manager is able to monitor changes a K8s cluster through the data contained in etcd.\n- The kube-scheduler will look to etcd to see what node resources are available to determine where a pod should be scheduled.\n- If you need to check the state of a cluster through the kube-apiserver, the server will look to etcd for that data.\n\n\n"},{"slug":"2021-kubernetes-worker-node-processes-explained","category":"blog","title":"Kubernetes node processes explained","description":"Kubernetes node processes explained","tags":["kubernetes"],"body":"\n* This post assumes some familiarity with Kubernetes components such as pods, nodes, and services.\n\nEvery worker node in a K8's environment will have 3 processes running on the server.\n1) Container runtime\n2) Kubelet\n3) kube-proxy\n\n<h3>1) Container runtime</h3>\nThis is the process responsible for running the pod containers. It is a not a K8's specific process, it is the process of the container system you are using, for example Docker.\n\n<h3>2) kubelet</h3>\nThis is a K8's process that is responsible for running and stopping pods on a node as well as assigning resources to the pods container. This process interfaces with both the container runtime and the node itself.\n\n<h3>3) kube-proxy</h3>\nIn a K8's environment there will usually be replicas of each node for failover and load balancing. The K8's components that are responsible for managing what requests go to which node is called a service and a service uses another K8's worker process called kube-proxy to actually do the intelligent request forwarding.\n\n\n- [Connecting Kubernetes Services to Deployments](https://tinytechtuts.com/2021-connecting-services-to-deployments-kubernetes/)"},{"slug":"2021-let-it-crash-explained","category":"blog","title":"BEAM/Elixir 'let it crash': what it does and does not mean","description":"overview of beam processes","tags":["elixir"],"body":"\nWhat it does not mean:\n- Let application runtime errors fail repeatedly without acknowledging/handling/fixing them.\n\nWhen writing an application, you build it based off of what you know about the domain and consider the needed functionality to accomplish the programs task. As a part of that you also have to think about what could go wrong and handle those cases through mechanisms such as data validation.\n\nInevitably a scenario or two of what can go wrong will be missed and that will result in a system runtime error. These are not the types of scenarios to avoid addressing and just 'let it crash', instead you need to debug and fix the overlooked scenario as you would if you were building the application in any other programming language.\n\nWhat it means:\n- If one process fails, others do not need to fail along with it.\n- If an external system dependency is offline for a few seconds, it will not impact future processes from trying to access that system.\n\nIn other VM's like the Java VM, a single thread can be used to handle multiple HTTP requests and if one of those requests errors, the rest will crash along with it. This is not the case with the BEAM VM where if one process crashes, other processes are unaffected.\n\nWhen building applications we often have external systems that we rely on to handle tasks for us, for example a third party CDN that contains our applications images. If that third party system goes down for a short while, the rest of our application can continue to function without having to recover from the error.\n\nMore Elixir process posts:\n[Processes for web programmers](https://tinytechtuts.com/2021-beam-elixir-processes-explained/),\n"},{"slug":"2021-man-in-the-middle-attack-explained","category":"blog","title":"Man In The Middle (MITM) attack explained through q&a","description":"Man In The Middle (MITM) attack explained","tags":["web-security"],"body":"\nThis and the other \"Deck\" posts are a repurposing of flashcard study decks to Q&A blog posts. Google was not showing love to this content as a set of flashcards and I didn't want to delete them entirely, I hope you find it useful.\n\n<h3>How does a man in the middle attack work?</h3>\nMITM attacks generally occur on open wifi networks on users accessing a website over HTTP as opposed to HTTPS. In this event the attacker will be listening on the network for such requests, intercept them, and alter the transaction in a malicious way. The attacker may be trying to retrieve sensitive data like the users Social Security or Credit Card number.\n\nA common scenario is for an attacker to go to a location where they know wifi is accessible like a coffeeshop. Once there they mimic the coffeeshop wifi name using a physical hotspot device they brought with them. They then name the network something similar to the coffeeshops for example coffeeshop-GUEST and hope that unsuspecting users will connect to this wifi connection. From there they can see all requests and read requests made using HTTP in plain text. This is also an example of Phishing, since the attacker is attempting to gain sensitive information by tricking the user into doing something they think is OK but really is malicious.\n\n<h3>How does a MITM attack relate to Session Hijacking attack?</h3>\nIn a MITM if the attacker is listening on the network and is able to see your session token and the user it to act on your behalf, they have just used a MITM to hijack your session.\n\n<h3>If you are on a secure wifi connection are you protected from MITM attacks?</h3>\nSignificantly more protected because the traffic from that wifi connection can only be viewed by someone with the username and password to that router over insecure HTTP.\n\n<h3>How do JWT's help prevent successful MITM attacks?</h3>\nSince JWT's are signed by the issuing server, if the MITM attempts to alter the data contained in the JWT the server will know it was tampered with and will return an error.\n\n<h3>Does HTTPS help prevent MITM?</h3>\nYes it does on external network connections such as making an HTTPS request over the internet. Even if your computer is connected to public unprotected wifi the data will be encrypted through the HTTPS protocol which will be gibberish to the attacker.\n\nHTTPS connections can still be vulnerable on local networks, like in an office or school that has their systems and computers on the same LAN network.\n\nMore Web Attack/Security Decks:\n1. [Cross Site Request Forgery](https://tinytechtuts.com/2021-cross-site-request-forgery-explained/)\n2. [Cross Site Scripting](https://tinytechtuts.com/2021-cross-site-scripting-explained/)\n"},{"slug":"2021-memoizing-conditionals-in-ruby","category":"blog","title":"How to memoize a conditional in Ruby","description":"memoize a conditional in Ruby","tags":["ruby"],"body":"\nIn Ruby memoization is a performance optimization. It allows you to execute some code, save it in a variable and not have execute that code again if the method is invoked, instead just return the value of a variable.\n\nIn the below code `some_method` will only execute the `Account.find` call the first time the method is invoked in on the object.\n\n```Ruby\nclass MyClass\n  def some_method\n    @account ||= Account.find(3)  \n  end\nend\n```\n\nI learned recently that you can memoize the return value of a conditional expression as well. To do this wrap the expression in a `begin` block and if `some_method` is invoked more than once the condition will not be run after the first invocation. During the first invocation the conditions return value was saved to `@account` and will be returned on each subsequent call to the method.\n\n```Ruby\nclass MyClass\n  def some_method\n    @account ||= begin\n      if @organization.has_accounts?\n        Account.find(3)\n      else\n        Account.create(name: \"lisa\")\n      end\n    end      \n  end\nend\n```\n\nSimilar post:\n[How not to memoize in Ruby](https://tinytechtuts.com/2021-when-not-to-memoize-in-ruby/)"},{"slug":"2021-mock-custom-react-hooks-with-jest","category":"blog","title":"How to mock custom React Hooks with Jest","description":"mocking react hooks","tags":["react","jest"],"body":"\n*This post assumes you already have Jest configured in your application.\n\nI was using a custom hook in a component that needed to be mocked out in order to properly produce a snapshot test. I chose to mock the this particular function because it was dependent on a part of the DOM that was not available for the hook to be operational.\n\nFrom the below component I will show you how to mock only the `useClassNameWrapper` hook and leave the `useParams` hook unmocked.\n```\n<!-- presentation.js -->\n\nimport {useClassNameWrapper, useParams} from \"lib/hooks\";\n\n\nfunction Presentation(props) {\n  const [classNameWrapper, setClassNameWrapper] = useState(null);\n  if(!classNameWrapper) {\n    setClassNameWrapper(\"presentation-wrapper\");\n  }\n  useClassNameWrapper(classNameWrapper);\n}\n```\n\nIn the test file I had to mock the import from `lib/hooks`, in this case the custom hooks from my `/lib` folder.\n\nIn order to mock an import you need to call on the `mock` function from the `jest` object and then return an object that matches the exports. In the below example an object is returned containing the exported `usePageClass` as a mock function:\n```\n<!-- test.js -->\n\njest.mock(\"lib/hooks\", () => ({\n  usePageClass: jest.fn()\n}));\n```\n\nYou will notice that this does not quite match the exports from the example code because this is not returning `useParams` from the mock and that is because we want the actual function to be called. In order to accomplish this we will use the `jest` function `requireActual`, ex:\n```\n<!-- test.js -->\n\njest.mock(\"lib/hooks\", () => ({\n  ...jest.requireActual(\"lib/hooks\"),\n  usePageClass: jest.fn()\n}));\n```\n\nNow any additional hook(s) that needs to be mocked out can be added to the `jest.mock` and any that do not will be handled by the `requireActual` function.\n\nNote: I wrote a Jest cheatsheet for React developers that you may also find useful [here](https://tinytechtuts.com/2021-jest-testing-cheatsheet/). \n\n\n"},{"slug":"2021-npm-run-build-folder-location","category":"blog","title":"npm run build command explained","description":"building production code for a react app","tags":["javascript","npm"],"body":"\nWhen executing the command `npm run build` at the root directory of a React app you are preparing the application to push a testing or production environment.\n\nWhat the command does is minify (strip the whitespace) and bundles all your JS and CSS code each into single file so your browser only has to load one JS and CSS file to render the React application.\n\nThese bundled files are located at the root of the applications directory under a `build` folder. Often that build folder is created using `mkdirp` which makes it a private directory so to view it on the command line run `ls -a` from your the root of your application.\n"},{"slug":"2021-pushing-docker-image-to-dockerhub-tutorial","category":"blog","title":"How to push a local Docker Image to Docker Hub","description":"Pushing a local Docker Image to Docker Hub","tags":["docker"],"body":"\n* This post assumes you have Docker installed and running on your local machine, if that is not the case follow the steps outlined [here](https://docs.docker.com/get-docker/) for your respective OS.\n* This post assumes you have already built the image locally.\n\nThe steps required to push your first Docker image to Docker Hub:\n1) Login to or signup for Docker on their [website](https://www.docker.com/).\n2) Create an empty repository on the website. The only thing required here is a name for the repository. Make sure it is public, which it will be by default. Follow [this link](https://docs.docker.com/docker-hub/repos/) for more details.\n3) Login to docker on the command line `docker login` using the same credentials as the website.\n4) Find the local image you want to push to Docker Hub through the command `docker image ls`.\n5) Tag the Docker image, which is the equivalent to staging it for release:\n\n```\n<!-- template -->\ndocker tag local-image:local-tag-name docker-username/empty-repo-name:tag-name\n\n<!-- example -->\ndocker tag k8s-test-app:latest joe-britton/first-repo:v.0.0.1\n```\n6) Check that the tag was created through the command `docker image ls`.\n7) Push the image to Docker Hub through the command `docker push joe-britton/first-repo:v.0.0.1`\n8) Revisit the repository you created on Dockers website and you should see your image.\n\n"},{"slug":"2021-rails-controllers-and-nested-resources","category":"blog","title":"Rails controllers and nested resources","description":"Defining Rails controllers that are nested","tags":["rails"],"body":"\nThe nested resource I am going to be referencing in this example is a `Form` nested within a `User`. The routes are defined like so:\n\n```\n~/config/routes.rb\n```\n```\nRails.application.routes.draw do\n  resources :users do\n    resources :forms\n  end\nend\n```\n\nAnd the resulting route structure:\n```\n/users/:user_id/forms/:id\n```\n\nIn my forms controller methods I am gettings a form through a user, see the code below:\n```\nclass FormsController < ApplicationController\n  def update\n    @user =  User.find(params[:user_id])\n    @form = @user.forms.find(params[:id].to_i)\n  end\nend\n```\n\nThis structure works fine, you just need to remember to handle routing/redirections appropriately, like I discuss [here](https://tinytechtuts.com/2021-redirect-to-nested-resource-url-rails/). However there is another way to structure this code that to me feels more accurate to it's function and that is to update the controller to be a `user_forms` controller that inherits from the `forms` controller.\n\nWith this new setup any routes that need to access forms outside of the user context can query the `FormsController` and any forms that need to be accessed through a user can be handled through a `UserFormsController`. The resulting code changes follow.\n\nUpdate the routes to account for both methods of accessing form resources. For the nested forms you need to explicitly point to the new `UserFormsController`. \n\n```\n~/config/routes.rb\n```\n```\nRails.application.routes.draw do\n  resources :forms\n  resources :users do\n    resources :forms, controller: \"user_forms\"\n  end\nend\n```\n\nNow create a new `UserFormsController` that inherits from the `FormsController` to acquire general form behavior and migrate any actions in the `FormsController` that reference a form through a user to the `UserFormsController` like the below `#update` method.\n\n```\n~/app/controllers/user_forms_controller.rb\n```\n```\nclass UserFormsController < FormsController\n  def update\n    @user =  User.find(params[:user_id])\n    @form = @user.forms.find(params[:id].to_i)\n  end\nend\n```\n\nFollowing the controller change your new code structure should function the same as before and now be understood a little more easily."},{"slug":"2021-rails-db-encryption-cheetsheet","category":"blog","title":"Rails db encryption cheatsheet","description":"rails db encryption walkthrough","tags":["rails","encryption"],"body":"\n<h4>!Important. The lastest versions of Rails now ship with this functionality without needing the attr_encrypted gem.</h4>\n<br />\nA few notes to refer to when needing to add database encryption to a Rails app that uses ActiveRecord:\n\n*This is not a comprehensive post. It is a brief reference for developers with some experience using Rails but haven't used it recently.\n\n1) Install a third party gem, `attr_encrypted`\n\n```ruby\ngem install attr_encrypted\n```\n\n2) Generate a migration to add the encrypted column name. You must prefix the column name with \"encrypted\".\n\n```ruby\nrails g migration add_secret_to_users encrypted_secret\n```\n\n3) Add the method `attr_encrypted` to your ActiveRecord model, the first argument is your column name without the encrypted prefix. They key option below will be the key used to handle the actual encryption and decryption. A few other keyword options to the `attr_encrypted` method are available are `algorithm`, `insecure_mode`, and `mode`.\n\n```ruby\nclass User < ApplicationRecord\n  attr_encrypted :secret, key: \"the secret key\"\nend\n```\n\n4) When accessing the new columns data, you can leave off the encrypted prefix to get the actual value, or keep the encrypted prefix to get the encrypted value.\n\n```ruby\n# returns plain text\nUser.last.secret\n\n# returns encrypted\nUser.last.encrypted_secret\n```\n\n5) When saving the new columns data you will save it with the encrypted prefix. There is also a method defined on the ActiveRecord model for encrypting the columns data, in this case `User.encrypt_secret`.\n\n```ruby\nUser.create(\n  encrypted_secret: User.encrypt_secret(SecureRandom.urlsafe_base64)\n)\n```\n\nMore Ruby cheatsheets:\n[Ruby HTTP gem](https://tinytechtuts.com/2021-ruby-http-gem-cheatsheet/)"},{"slug":"2021-rails-handling-errors","category":"blog","title":"Rails error handling cheatsheet","description":"rails error handling explanation","tags":["rails"],"body":"\nA few notes to refer to for Rails JSON api error handling in controller actions:\n\n*This is not a comprehensive post. Reference for developers with some experience using Rails but haven't had to handle errors recently.\n\n1) To raise an error on a query that does not find a record use the bang operator (`!`) on the end of the query method:\n```ruby\n# if this query returns empty no error is raised\nStore.from_external_id(params[\"external_id\"])\n```\n\n```ruby\n# if this query returns empty an error is raised\nStore.from_external_id!(params[\"external_id\"])\n```\n\n2) The create and update methods will throw DB errors without having to use the `!` operator, like a SQL NOT NULL constraint violation. However it will not throw app validation errors. The errors will still be available as data on the object but the app will not crash. If you include the `!` while using the `create` or `update` methods an app error will be raised should a validation error occur.\n\n```ruby\n# does not raise app validation errors\nstore = Store.create(store_params)\n\nif store.errors\n  render json: {errors: app.errors.full_messages}\nend\n```\n\n```ruby\n# does raise app validation errors\nStore.create!(store_params)\n\nrescue => e\n  render json: {errors: [e.message]}\n```\n\n3) If you want to render a JSON error message instead of a default Rails error page, two options are to 1) explicitly return the error you want or raise 2) rescue the error and handle the JSON formatting for the error:\n\n```ruby\nstore = Store.from_external_id(params[\"external_id\"])\n\nif store\n  render json: {success: store}\nelse\n  render json: {error: {message: \"Store not found\"}}\nend\n```\n\nOr\n\n```ruby\nstore = Store.from_org_external_id!(params[\"external_id\"])\n\nrescue => ActiveRecord::RecordNotFound\n  render json: {error: {message: \"Store not found\"}}\n```\n\n4) ActiveRecords `.find` method will throw an error if a record is not found, but `.find_by` will return nil during the same event.\n\n```Ruby\n# If record doesn't exist raise NotFound.\nAccount.find(1234)\n\n# If not found returns nil.\nAccount.find_by(id: 1234)\n```\n\nMore Ruby cheatsheets:\n[Ruby HTTP gem](https://tinytechtuts.com/2021-ruby-http-gem-cheatsheet/)"},{"slug":"2021-rails-nested-resources-mvc-complete-example","category":"blog","title":"Rails nested resources MVC complete example","description":"how to setup models views and controllers for nested resources","tags":["rails"],"body":"\n\nThis post provides references to the code changes that need to be made to a scaffolded rails app in order to render a form for the resources. In the application I am providing the example from those resources are User and Form, where a form is rendered for a user. This is a survey rendering application, similar to TypeForm or SurveyMonkey.\n\nThis post will use the `form#edit` action as an example but this can be applied to any of the resources.\n\n\n<h3>Generating the scaffold</h3>\nFor those that want to code along with the post, you can start by creating a new rails application and generating the following two scaffolds:\n\n```\nrails g scaffold Form\nrails g scaffold User\n```\n\nThis will create all of the resources needed to create and render forms and users, but we will make changes to the generated files to account for forms being nested within users.\n\n<h3>Creating the tables and ActiveRecord relationships</h3>\n\nTo establish the relationships between the Form and User I added a reference to the users table in the form `create_table`. Adding the reference requires the users table to exist before running the migration:\n\n```\n~/db/migrate/20211111221212_create_forms.rb\n```\n```\nclass CreateForms < ActiveRecord::Migration[6.1]\n  def change\n    create_table :forms do |t|\n      t.references :user, index: true, null: false\n      t.string :name\n\n      t.timestamps\n    end\n  end\nend\n```\n\nIn the `Form` and `User` models add the `belongs_to` and `has_many` associations appropriately:\n```\n~/app/models/form.rb\n```\n```\nclass Form < ApplicationRecord\n  belongs_to :user\nend\n```\n\n```\n~/app/models/user.rb\n```\n```\nclass User < ApplicationRecord\n  has_many :forms\nend\n```\n\n<h3>Update routes to be nested</h3>\n\nUpdate the routes file so `:forms` are scoped under `:users` because in this system a `Form` will only exist under the context of a `User`. This will also update the url helpers rails providers, which we will need to update references to later in the post.\n\n```\n~/config/routes.rb\n```\n```\nresources :users do\n  resources :forms\nend\n```\n\nRun the `rails routes` command to see the changes to the routes definitions. For our edit example the new url is:\n\n```\n/users/:user_id/forms/:id/edit\n```\n\n\n\n<h3>Updating FormsController#edit</h3>\n\nIn the `FormsController` an update needs to be made to get form for a specific user. Since the route to access the `edit` action is `/users/:user_id/forms/:id/edit` we now have the `user_id` and `id` (from_id) available to us as parameters to query for data.\n\nIn the `edit` example below we query for the user first and then filter the forms to find the correct resource. Setting the `@form` and `@user` variables will give us access to them in the view template:\n\n```\nclass FormsController < ApplicationController\n  before_action :set_user, only: %i[ edit ]\n\n  def edit\n    @form = @user.forms.find(params[:id].to_i)\n  end\n\n  private\n\n  def set_user\n    @user = User.find(params[:user_id])\n  end\nend\n```\n\n<h3>Updating views for FormsController#edit</h3>\n\nWhen generating the scaffold for `Form` you an edit template was created for you that looks similar to this:\n\n```\n~/app/views/forms/edit.html.erb\n```\n```\n<h1>Editing Form</h1>\n\n<%= render 'form', form: @form %>\n\n<%= link_to 'Show', @form %> |\n<%= link_to 'Back', forms_path %>\n```\n\nSince the forms were updated to be nested, we will need to account for two changes:\n1. The new url path helpers\n2. The added data needed for the form to render\n\nAfter the updates the new `edit.html.erb` will look like the below code example. The links were updated with the correct url paths and the data we provide to the form partial is accounted for.\n\n```\n<h1>Editing Form</h1>\n\n<%= render 'form', form_and_user: [@user, @form] %>\n\n<%= link_to 'Show', user_form_path(@form) %> |\n<%= link_to 'Back', user_forms_path %>\n```\n\nFinally update the references in the form partially to account for the changed parameter name as the example below illustrates:\n\nOrginal form partial:\n```\n~/app/views/forms/_form.html.erb\n```\n```\n<%= form_with(model: form) do |form| %>\n# form elements\n<% end %>\n```\n\nUpdated form partial:\n```\n<%= form_with(model: form_and_user) do |form| %>\n# form elements\n<% end %>\n```\n\nAfter making these updates you should be able to navigate to `http://localhost:3000/users/1/forms/1/edit` successfully.\n\nThanks for tuning in! I hope you found this post helpful today."},{"slug":"2021-rails-params-cheatsheet","category":"blog","title":"Rails params cheatsheet","description":"rails params overview explanation","tags":["rails"],"body":"\nA few notes to refer to when not sure about how to handle rails parameters:\n\n*This is not a comprehensive post. It is a brief reference for developers with some experience using Rails but haven't used it recently.\n\n1) Use the `require` method on the `params` object when detecting the presence of a specific model, like author below:\n\n```ruby\nprivate\n\ndef author_params\n  params.require(:author).permit(:name, :organization_id, :post_id)\nend\n```\n\n2) Use the `permit` method, referenced above, when you want to save the params to the database using an ActiveRecord model.\n\n3) You don't need to use the `require` method before calling `permit`. The `require` method does not change the object.\n\n4) If you only need to reference one parameter key, you can just use the key/value accessor `[]` directly in the controller method:\n\n```\norg = Organization.find_by!(external_id: params[:external_id])\n```\n\n5) If you have a params object with complex data structures such as nested collections like the first below example you can permit those parameters by following the second code example below. Just make sure the collections are the last items to be permitted, for this example tags:\n\n```\n{\"author\" => {\"post_title\" => \"first post\", \"tags\" => [{\"id\" => 1, \"name\" => \"Food\"}]}\n```\n\n```\nparams.permit(author: [:post_title, tags: [:id, :name]])\n```\n\nMore Ruby cheatsheets:\n[Rails DB encryption](https://tinytechtuts.com/2021-rails-db-encryption-cheetsheet/)\n"},{"slug":"2021-rake-tmp-clear-vs-rails-cach-clear","category":"blog","title":"Difference between rake tmp:clear and Rails.cache.clear","description":"Difference between rake tmp:clear and Rails.cache.clear","tags":["rails","caching"],"body":"\nSometimes I forget the difference between the functionality of this rake task and Rails method. This is a reference post I wanted to have that I hope you find helpful.\n\n<h3>rake tmp:clear</h3>\nThis task only removes files from the Rails file system.\n\n<h3>Rails.cache.clear</h3>\nThis will clear objects stored in the application cache, unless the value for `config.cache_store` for your application is set to `:file_store`. In the latter case `Rails.cache.clear` will be functionally the same as `rake tmp:clear`.\n\nPost details [source](https://stackoverflow.com/questions/19017983/what-is-the-difference-between-rails-cache-clear-and-rake-tmpcacheclear).\n\n\n"},{"slug":"2021-redirect-to-nested-resource-url-rails","category":"blog","title":"Redirect to nested resource url in Rails","description":"Route Rails app to nested resource url","tags":["rails"],"body":"\nSometimes in our developer lives we have to nest our resources. In my case I was nesting a `Form` within a `User`, the resulting routes file and url are:\n\n```\n~/config/routes.rb\n```\n```\nRails.application.routes.draw do\n  resources :users do\n    resources :forms\n  end\nend\n```\n\nAnd the resulting route structure:\n```\n/users/:user_id/forms/:id\n```\n\nI ran into an issue when updating a form, I was getting the error `Undefined method or varaible form_path` when trying to redirect to just the form, like the below example shows:\n```\nif @form.update(form_params)\n  format.html { redirect_to @form, notice: \"Form was successfully updated.\" }\nend\n```\n\nWhat I had to do was update the redirect_to method to accept an array of resources, in this case both a user and form. The resulting working code is below:\n```\nif @form.update(form_params)\n  format.html { redirect_to [@user, @form], notice: \"Form was successfully updated.\" }\nend\n```\n\nJust like the url this form was rendered from has both a user and a form, the redirect_to also needs a user and form to navigate successfully.\n\nWhen you need to use the url path helper you can pass the objects in without the array brackets, like so:\n\n```\nredirect_to edit_user_form_path(@user, @form)\n```\n"},{"slug":"2021-rendering-forms-for-child-objects-rails","category":"blog","title":"Rendering forms for parent and child ActiveRecord objects in Rails","description":"Rendering form for child objects in Rails","tags":["rails"],"body":"\nTo understand the form rendering example that follows I posted the classes that are referenced and their associations below where a `User` has many `Form`'s and a `Form` has many `FormFields`.\n\n```\nclass User < ApplicationRecord\n  has_many :forms\nend\n```\n```\nclass Form < ApplicationRecord\n  belongs_to :user\n  has_many :form_fields\nend\n```\n```\nclass FormField < ApplicationRecord\n  belongs_to :form\nend\n```\n\nWhat I needed to do here was get one form rendered for the `Form` object and a collection of forms rendered form the `FormFields` object. The route the forms are rendered at are nested under `User` at the `Form#edit` controller action:\n```\n/users/:user_id/forms/:id/edit\n```\n\nThe edit action sets instance variables for `@user` and `@form`.\n\n```\ndef edit\n  @user =  User.joins(forms: :form_fields).find(params[:user_id])\n  @form = @user.forms.find(params[:id].to_i)\nend\n```\n\nAfter the controller is called the edit template is rendered which renders two partials, one for forms form and a partial for the form fields form.\n\nIn the code example below the key thing to point out is the rendering of the form partial in the same directory, we pass that rendered partial a form and user which will be accessible within the template.\n\n\n```\n~/app/views/forms/edit.html.erb\n```\n```\n<h1>Edit: <%= @form.name %></h1>\n\n<%= render 'form', form: @form, user: @user %>\n```\n\nThe below snippet is actual form file that was rendered in the previous example. We do two things here:\n1. Render a form for the actual form. To do this we need to pass both the `@user` and `@form` to account for the nested route.\n2. Render a collection of forms for the form fields. From the form object we get the collection `FormFields` data associated, which is another ActiveRecord object. During the iteration of those objects, we render the form partial for each form field and pass it the form_field object to build the form from.\n\n```\n~/app/views/forms/_form.html.erb\n```\n```\n<%= form_with(model: [@user, @form]) do |f| %>\n  <%= f.label :name %>\n  <%= f.text_field :name, value: @form.name %>  \n  <div class=\"actions\">\n    <%= f.submit %>\n  </div>\n<% end %>\n\n<% @form.form_fields.each do |form_field| %>\n  <%= render 'form_fields/form', form_field: form_field %>\n  <br />\n<% end %>\n```\n\nThis is the final rendered form_field partial, which utilizes the data passed into the form_field partial shown in the previous code snippet.\n```\n~/app/views/form_fields/_form.html.erb\n```\n```\n<%= form_with(model: form_field) do |form| %>\n  <%= form.label :html_input_type %>\n  <%= form.text_field :html_input_type, value: form_field.html_input_type %>\n  <%= form.label :html_element_type %>\n  <%= form.text_field :html_element_type, value: form_field.html_element_type %>\n  <%= form.label :name %>\n  <%= form.text_field :name, value: form_field.name %>\n  <%= form.label :options %>\n  <%= form.text_field :options, value: JSON.pretty_generate(form_field.options) %>\n  <div class=\"actions\">\n    <%= form.submit %>\n  </div>\n<% end %>\n```\n\nIf you followed along to the end you should now be able to view your forms at `http://localhost:3000/users/1/forms/1/edit`.\n"},{"slug":"2021-retrieving-data-from-join-query-rails","category":"blog","title":"Accessing data from a join query in Rails","description":"retrieving data from join query","tags":["rails"],"body":"\nTo understand the join example that follows I posted the classes that are referenced and their associations below where a `User` has many `Form`'s and a `Form` has many `FormFields`.\n\n```\nclass User < ApplicationRecord\n  has_many :forms\nend\n```\n```\nclass Form < ApplicationRecord\n  belongs_to :user\n  has_many :form_fields\nend\n```\n```\nclass FormField < ApplicationRecord\n  belongs_to :form\nend\n```\n\nWhen querying your database while using rails, if there exists a foreign key relationship on the model you're working on you can run the join query you can perform an inner join by calling the `.join` method on the model in the following way:\n\n```\n@user =  User.joins(forms: :form_fields).find(params[:user_id])\n```\n\nThe below query results in the following SQL statement where there are two joins performed, the first on the form and then another query for the forms fields:\n\n```\nSELECT \"users\".* FROM \"users\" \nINNER JOIN \"forms\" ON \"forms\".\"user_id\" = \"users\".\"id\" \nINNER JOIN \"form_fields\" ON \"form_fields\".\"form_id\" = \"forms\".\"id\" WHERE \"users\".\"id\" = $1\n```\n\nTo access the data you can use the accessors provided by rails and no new query will be called when you ask for `form` on the `@user` object or `form_fields` on the `@form` object\n\n```\n@user.form\n=> #<Form:0x000000013e579240\n```\n```\n@form = @user.form[1]\n@form.form_fields\n=> #<FormField:0x000000013e5793a8\n```"},{"slug":"2021-retroactively-add-timestamps-in-phoenix-ecto","category":"blog","title":"Retroactively add timestamps to a Phoenix/Ecto project","description":"adding timestamps to ecto db tables","tags":["ecto"],"body":"\nI chose not to add timestamps to a couple of tables in the DevDecks application at first, mainly because I was moving fast to build the app and prioritized other things first. As you and I both guessed, I needed to do that later on and here's what I had to do to get things working.\n\nFirst I created the migrations for the tables I was adding the datetime fields to; cards and decks. I created and ran the migrations one at a time, this example only shows what I did for cards but I mimicked these steps with decks as well.\n\n<h3>The migration:</h3>\n\nI found this [Stackoverflow answer](https://stackoverflow.com/questions/35744390/how-to-add-timestamps-to-an-existing-table-with-ectos-timestamps/52610636#52610636) to be helpful for creating the migration. I follow this migration file code snippet with explanations for what some the different steps are doing and why.\n```\ndefmodule DevDecks.Repo.Migrations.AddTimestampsToCards do\n  use Ecto.Migration\n\n  def up do\n    alter table(:cards) do      \n      timestamps null: true\n    end\n\n    execute \"\"\"\n    UPDATE cards\n    SET updated_at=NOW(), inserted_at=NOW()\n    \"\"\"\n\n    alter table(:cards) do\n      modify :inserted_at, :utc_datetime, null: false\n      modify :updated_at, :utc_datetime, null: false\n    end\n  end\n\n  def down do\n    alter table(:cards) do\n      remove :inserted_at\n      remove :updated_at\n    end\n  end\nend\n```\n\n<h3>The explanations</h3>\n```\ntimestamps null: true\n```\nWe need this because by default using the timestamps method creates a not null constraint and your code will error when trying to add timestamps against existing db rows because those rows wouldn't have values for the inserted_at and updated_at columns the timestamps method creates.\n\n```\nexecute \"\"\"\nUPDATE cards\nSET updated_at=NOW(), inserted_at=NOW()\n\"\"\"\n```\nUpdate cards records to have `updated_at` and `inserted_at` values.\n\n```\nmodify :inserted_at, :utc_datetime, null: false\nmodify :updated_at, :utc_datetime, null: false\n```\nUndo the original `timestamps null: true` call from above now that the existing records have values.\n\n```\nremove :inserted_at\nremove :updated_at\n```\nIf rolling back the migration is needed then remove the datetime columns.\n\nAfter running this migration my cards table was setup properly to timestamp new records.\n\n<h3>Adding to the schema and changeset:</h3>\n\nIn my `card.ex` context I updated the schema to include the `updated_at` and `inserted_at` fields and then also added them to the changeset:\n```\nschema \"cards\" do\n  field :updated_at, :utc_datetime\n  field :inserted_at, :utc_datetime\nend\n\ndef changeset(params \\\\ %{}) do\n  %DevDecks.Card{}\n  |> cast(params, [:updated_at, inserted_at])  \nend\n```\n\nThe last step was to update my create method in the same `card.ex` file. I updated the params to include values for the dates using the `NativeDateTime` module and then could cast the updated params to the changeset and insert into the database:\n```\ndef create(params \\\\ %{}) do\n  params = Map.merge(params, %{\"updated_at\" => NaiveDateTime.utc_now, \"inserted_at\" => NaiveDateTime.utc_now})\n\n  %DevDecks.Card{}\n  |> cast(params, [:uuid, :answer, :question, :deck_uuid, :deck_position, :inserted_at, :updated_at])\n  |> Repo.insert()\nend\n```\n\nIf you found this useful I also wrote a post about migrating to Elixir's Earmark for markdown processing [here](https://tinytechtuts.com/2021-elixir-earmark-code-parsing/):\n"},{"slug":"2021-retry-failed-gigalixir-paas-deploy","category":"blog","title":"Retry failed Gigalixir/PAAS deploy","description":"Retry failed Gigalixir/PAAS deploy","tags":["gigalixir"],"body":"\nMaybe your internet cut out in the middle of your deploy or another issue where your deployment to your PAAS provider failed (in my case the provider was Gigalixir but this also applies to Heroku and others). When you go try and rereun your failed deploy from the command line again, you are met with the message \"Everything up to date\". Now you need to find a way to deploy your changes. You could update some trivial text in your codebase and make a commit, but the route I prefer is to create an an empty commit with no changes to the files Git is tracking. You can do this through the following command:\n\n```\ngit commit --allow-empty -m \"rebuild\"\n```\n\nThe command above creates a commit with no changes to the files being tracked and sets a message for that commit of \"rebuild\". Since your PAAS provider has not built this commit before you are now ready to try to rerun your application deployment:\n\n```\ngit push gigalixir master\n```\n\nFor your continued enjoyment:\n- [Deploying a clean build to Gigalixir](https://tinytechtuts.com/2020-gigalixir-deploy-no-cache/)\n"},{"slug":"2021-return-dynamic-url-with-rails-route-helpers","category":"blog","title":"Issue a dynamic url with Rails route helpers","description":"Issue a dynamic url with Rails route helpers","tags":["ruby","http"],"body":"\nIn Rails you can use routing helper methods to access a URL for a declared route.\n\nAs an example:\n\n```ruby\n=> users_path\n\"http://localhost:3000/users\"\n```\n\nThis helps with a few things:\n\n1) You don't have to hard code the URL strings, which need to be updated everywhere anytime this route changed\n2) You don't have to check which ENV the app is in in order to get an accurate URL. Example:\n\n```ruby\nif Rails.env == \"development\"\n  url = \"http://localhost:3000/users\"\nelsif Rails.env == \"testing\"\n  url = \"http://stagingapp.io/users\"\nelse\n  url = \"http://productionapp.io/users\"\nend\n```\n\nBut what if you need to access a dynamic URL path, where an ID is passed to the URL for identifying a specific user in your application? In this case you can pass an argument to the helper like so:\n\n```ruby\n=> user_path(\"123\")\n\"http://localhost:3000/users/123\"\n```\n\nThis is all covered in the Rails routing guide, but I ran into a situation where:\n1) I needed to send a dynamic route to a third party system so they could call with any with any ID they wanted.\n2) It needed to still not be hard coded and be different based on environment.\n\nThe solution I came up with was to pass the route helper a string of `:id` like so:\n```ruby\n=> user_path(\":id\")\n\"http://localhost:3000/users/:id\"\n```\n\nNow the third party system can call our url using whichever ID they need. Note that URL path variables should be prefixed with a colon `:` like in the example to indicate it is a variable.\n\nIf you need to find what url helpers are available to you in your app run the following command in your terminal/command line:\n`rails routes`"},{"slug":"2021-returning-memoized-ruby-object-from-method","category":"blog","title":"Method returning memoized object is called with different arguments","description":"what happens when you call a method that returns memoized object with new parameters","tags":["ruby"],"body":"\nI wasn't sure what would happen if I called a method that returned a memoized object but that object that was memoized also used data passed into the method via a method argument so I created this test:\n\n```ruby\nclass NewClass\n  def updater\n    update1\n    update2\n  end\n\n  def update1\n    p \"test1: #{update_data(\"Admin review\")}\"\n  end\n\n  def update2\n    p \"test2: #{update_data(\"Completed\")}\"\n  end\n\n  def update_data(status=nil)\n    @body ||= {status: status}\n  end\nend\n\nNewClass.new.updater\n=> \"test1: {:status=>\\\"Admin review\\\"}\"\n=> \"test2: {:status=>\\\"Admin review\\\"}\"\n```\n\nIn the example above the `NewClass` object makes two calls to `update_data` which returns the object in question. Each of those calls passes a different parameter to the method, but the object does not get updated with the different data after it is memoized during the first method call.\n\nFor your continued enjoyment:\n- [How not to memoize in Ruby](https://tinytechtuts.com/2021-when-not-to-memoize-in-ruby/)\n"},{"slug":"2021-ruby-http-gem-cheatsheet","category":"blog","title":"Ruby http gem cheatsheet","description":"cheatsheet for Ruby http gem","tags":["ruby","http"],"body":"\nA few notes to refer to when needing to use the ruby http gem.\n\n*This is not a comprehensive post. It is a quick reference if you have some experience with ruby/http but haven't used it recently.\n\n1) Updating headers\n\nSay you have your http client defined within a method like this:\n\n```Ruby\ndef http\n  HTTP[\n    authorization: \"Bearer sometoken\",\n    accept: \"application/json\",\n    content_type: \"application/json\"\n  ]\nend\n```\n\nWhile building new functionality you realize you want to use this method, but need different headers, you can accomplish this through the `headers` method on the HTTP object like so:\n\n```ruby\ndef update_config\n  http\n  .headers(accept: \"application/x-www-form-urlencoded\", content_type: \"application/x-www-form-urlencoded\")\n  .put(\"https://somebaseurl/configuration\", form: config)\nend\n```\n\n2) Post JSON vs Form vs Body\n\nDepending on the `Content-Type` the server you are calling to is expecting you will need to send different post body options:\n\nWhen the expected `Content-Type` is `application/json` use `json:`:\n\n```ruby\nhttp.put(\"https://somebaseurl/configuration\", json: config)\n```\n\nWhen the expected `Content-Type` is `application/x-www-form-urlencoded` use `form:`:\n```ruby\nhttp.post(\"https://somebaseurl/configuration\", form: config)\n```\n\nWhen the expected `Content-Type` is `application/xml` use `body:`:\n```ruby\nhttp.post(\"https://somebaseurl/configuration\", body: config)\n```\n\n3) If some endpoints are expecting an `Authorization` header and others are not, you can just add the authorization header to the http client as exampled in the first note and if the server does not need authorization it will just ignore it."},{"slug":"2021-ruby-instance-based-to-classed-based-behavior","category":"blog","title":"Migrating behavior from instance based to class based","description":"ruby instance to class based","tags":["ruby"],"body":"\nI recently had to build a new Ruby class in an application I work on to group like behavior. I originally chose to implement the behavior within the class using instance methods because I wanted some initial state to work with. This was the original implementation:\n\n```ruby\nclass Recommendation\n  attr_accessor :recommendations\n\n  def initialize\n    @recommendations = []\n  end\n\n  def recommendations(options = {})\n    options[:first] ? options[:first] : options[:first] = 10\n\n    query = <<-GRAPHQL\n      query {\n        recommendations(#{options}) {\n          page_info {\n            end_cursor\n            has_next_page\n          }\n          edges {\n            node {\n              id\n              name\n            }\n          }\n        }\n      }\n    GRAPHQL\n\n    response = Api.post(\"/recommendations/graphql\", query: query).data\n    recs = response.data.recommendations\n    recommendations << recs.edges.map(&:node)\n\n    if recs.page_info.has_next_page\n      recommendations({after: recs.page_info.end_cursor})\n    end\n\n    recommendations.flatten\n  end\nend\n```\n\nIn the example above the class is initialized with an empty list of recommendations and when the `#recommendations` method is called it updates that state with all of the recommendations from the server by calling the method recursively until the server does not have any more records.\n\nThe issue here is this really is not an object that needs to be instantiated multipled times with a lot of different public interfaces, it is more like a helper method with a very specific function, return all the recommendations. In this case a class method makes more sense.\n\nThe part of this I had to think about was how to handle the recommendations state since I would no longer me initializing a class with shared state. Because this class only has one method I was able to just set an array object at the top of the new class method to hold the recommendations, which would be the new state. If other methods needed this data though I would have to figure out a new option, likely passing data as parameters between methods or returning the state from method calls. These would be more functional approaches to the problem.\n\nHere is the output of the conversion to class based behavior:\n\n```ruby\nclass Recommendation\n  def self.recommendations(options = {})\n    recommendations = []\n    options[:first] ? options[:first] : options[:first] = 10\n\n    query = <<-GRAPHQL\n      query {\n        recommendations(#{options}) {\n          page_info {\n            end_cursor\n            has_next_page\n          }\n          edges {\n            node {\n              id\n              name\n            }\n          }\n        }\n      }\n    GRAPHQL\n\n    response = Api.post(\"/recommendations/graphql\", query: query).data\n    recs = response.data.recommendations\n    recommendations << recs.edges.map(&:node)\n\n    if recs.page_info.has_next_page\n      recommendations({after: recs.page_info.end_cursor})\n    end\n\n    recommendations.flatten\n  end\nend\n```\n\nMore Ruby posts for you enjoyment:\n- [Redirect to nested resource url in Rails](https://tinytechtuts.com/2021-redirect-to-nested-resource-url-rails/)"},{"slug":"2021-same-db-table-parent-child-relationship-rails","category":"blog","title":"Same database table parent/child relationship using Rails","description":"rails parent/child relationships same db table","tags":["rails"],"body":"\nWhen developing an application you may come across the need for a context in your application to contain a sub-component like a sub-organization or sub-group. Said differently you may want an organization to be able to create many other organizations or a group to be able to create many other groups. \n\nUsing Rails you can handle this by first creating a migration to add a `parent_id` to the context, in this example Groups.\n\n```ruby\nclass CreateGroups < ActiveRecord::Migration[5.3]\n  def change\n    create_table :groups do |t|\n      t.integer :parent_group_id, index: true\n    end\n  end\nend\n```\n\n```ruby\nclass Group < ApplicationRecord\n  belongs_to :parent_group, class_name: :Group, optional: true\n  has_many :groups, foreign_key: :parent_group_id\nend\n```\n\nFrom there you can establish the relationship in the ActiveRecord model by declaring a Group can belong to another instance of a group through the use of the `parent_group_id` as its connection. Through this connection you can query for a Groups.\n\n```ruby\n=> group = Group.first\n#<Group:0x00000 id: 17, parent_group_id: 1>\n\n# get a groups parent group\n=> group.parent_group\n#<Group:0x00000 id: 1, parent_group_id: nil>\n```\n\nA Group will also have many groups through the `has_many`. Now for an instance of group you can call `.groups` to get all of the child groups associated with it.\n\n```ruby\n=> group = Group.first\n#<Group:0x00000 id: 17, parent_group_id: 1>\n\n# get all child groups for a parent group\n=> group.groups\n[\n  #<Group:0x00000 id: 34, parent_group_id: 17>,\n  #<Group:0x00000 id: 35, parent_group_id: 17>,\n]\n```\n\nSimilar posts:\n - [Creating a table with non id primary key in Rails](https://tinytechtuts.com/2021-creating-a-table-with-different-primary-key-rails/)\n\n"},{"slug":"2021-save-multiple-records-at-once","category":"blog","title":"Persist multiple records in one database transaction using Rails","description":"Persist multiple records in one database transaction using Rails","tags":["rails","databases"],"body":"\nMaybe you need to update your users and profiles table at the same time and if either call fails, they both fail, and if both succeed the transaction completes, or maybe you need to update an admins table and users table with the same use case.\n\nIn this event, if you are using Rails, you can reach for `ApplicationRecord.transaction` or one of its child classes and pass the call to it a block. Within the code block you can call the SQL statements you need to take place.\n\nThe below example finds an admin authentication and its organization, then deletes each. For this to succeed all calls must succeed.\n\n```\nApplicationRecord.transaction do\n  admin_auth = AdminUserAuth.find_by(token: token)\n  organization = admin_auth.organization\n\n  admin_auth.destroy!\n  organization.destroy!\nend\n```\n"},{"slug":"2021-set-value-to-multiple-variables-ruby","category":"blog","title":"Set multiple variables to a single value using Ruby or Elixir","description":"multiple variables single value Ruby/Elixir","tags":["elixir","ruby"],"body":"\nTo accomplish this you set each variable you need to have the same value on the same line like so:\n\n```\nvariable3 = variable2 = variable1 = \"the famous cats\"\n```\n\nNow each of the variables above will be equal to \"the famous cats\"\n\n```\n=> variable3\n\"the famous cats\"\n=> variable2\n\"the famous cats\"\n=> variable1\n\"the famous cats\"\n```\n\nFrom there you can overwrite each variable when/if needed.\n"},{"slug":"2021-sidekiq-delete-vs-kill","category":"blog","title":"The difference between Sidekiq's Kill and Delete functions","description":"The difference between Sidekiq's Kill and Delete functions","tags":["rails","sidekiq"],"body":"\nWhen using the Sidekiq UI, there are two buttons for removing jobs from the queue and those are `delete` and `kill`.\n\nThe `delete` option destroys the job entirely with no possibility of replaying in the future.\n\nThe `kill` option moves the job from the queue to the dead tab. From there you can re-enqueue the job anytime you want. This can be useful when testing jobs. If a job or jobs are failing over and over again it can get noisy and difficult to keep track of what is going on so having the `kill` option helps to alleviate this issue.\n\nSimilar post(s):\n[Delete Sidekiq cache key](https://tinytechtuts.com/2021-delete-sidekiq-cache-key/)"},{"slug":"2021-the-missing-guide-to-troubleshooting-rubygem-issues","category":"blog","title":"The missing guide to troubleshooting RubyGem issues","description":"troubleshooting RubyGem issues","tags":["ruby"],"body":"\n* This post assumes you are using RVM to manage your Ruby versions.\n\nIn this post I run through:\n1) How to get insight into your RubyGem env\n2) Uninstalling a Gem and it's dependencies\n3) Gem install vs bundle install\n4) Resolving native file extension issues\n5) A few more potentially useful notes\n\n<h3>1) How to get insight into your RubyGem env</h3>\nType the command `gem env` into your terminal. The output here will show you useful information like:\n- What RubyGems version you're using\n- What RVM version you're using\n- The Gem installation path\n- Other potentially useful information...\n\nWith this output you can change directories to view what RubyGems are installed for your Ruby version:\n\n```\ncd /gem/installation-path/output && cd gems\n```\n\nNote that when you install a gem you are only installing it for the specific version of Ruby that you are running. If you update your Ruby version you will need to reinstall any gems that are missing.\n\nA few additional RVM tips: If you want to use a different version of Ruby execute the command `rvm use ruby-2.5.7` and if you want to see a list of Ruby versions you have installed locally execute `rvm list`. If you want to see the current RVM version you are using `rvm -v` and if you want to install a different version `rvm install \"ruby-2.6.0\"`.\n\n<h3>2) Uninstalling a Gem and its dependencies</h3>\n\nWhen you install a gem that has dependencies, those dependencies are not automatically uninstalled. RubyGems will give you a warning before uninstalling a gem that has dependencies:\n\n```\ngem uninstall tty-cursor\n=> You have requested to uninstall the gem:\n\ttty-cursor-0.7.1\n\ntty-reader-0.9.0 depends on tty-cursor (~> 0.7)\nIf you remove this gem, these dependencies will not be met.\n```\n\nTo satisfy this message first run `gem uninstall tty-reader-0.9.0`, which could have its own dependencies you will need to uninstall.\n\nTo find the list of dependencies a gem has you can view the profile page of the gem on the [RubyGems website](https://rubygems.org/).\n\n<h3>3) Gem install vs bundle install</h3>\n\nYou never want to install a gem that you will use in a project with other dependencies using the command `gem install gemname`. If you have done that you should uninstall the gem and reinstall it by adding it to your projects Gemfile and running `bundle install`. The reason for this is Bundler is a dependency management tool that will install the version your project needs based on other gems in your project uses.\n\n<h3>4) Resolving native file extension issues</h3>\n\nIf you are programming on a Mac and install Mac system updates you may find face a native file extensions error when updating or installing gems. This will occur when trying to install a gem that uses low level `C` bindings. To fix this issue I find it easiest to delete and reinstall CommandLineTools using the two commands below:\n```\nsudo rm -rf /Library/Developer/CommandLineTools\nxcode-select --install\n```\n\n<h3>5) Two more potentially useful notes</h3>\n\n```\ngem 'wisper', '~> 1.0', '<= 1.4.0'\n```\n* The above Gemfile line asks for a version greater than or equal to 1.0 and less than or equal to 1.4.0. What happens if you have Wisper 1.3.0 installed locally? Will it use that or pull from remote because 1.4.0 exists remotely? It turns out it will pull the remote 1.4.0 version.\n* If you install a gem for one project locally, that gem will be available for use by another local project as long as it is using the same version of Ruby.\n\nI hope these notes helped you solve the RubyGem issue you're facing, I know they can be tricky.\n\nSimilar post:\n- [How to read Ruby Gemfile versions](https://tinytechtuts.com/2021-how-to-read-gemfile-versions-in-ruby/)\n"},{"slug":"2021-understanding-cross-origin-resource-sharing-for-new-developers-pt2","category":"blog","title":"Understanding Cross Origin Resource Sharing (cors) for new developers","description":"Cross Origin Resource Sharing (cors) for new developers","tags":["web-security"],"body":"\nThis and the other \"Deck\" posts are a repurposing of flashcard study decks to Q&A blog posts. \n\n<h3>What is CORS?</h3>\n\nIt can be thought of as a configuration item for backend applications. This configuration item decides what origins/hosts the server will accept requests from, so if you want another application to be able to talk to your server you can enable this through CORS.\n\n\n<h3>What does CORS stand for?</h3>\n\nCross-origin Resource Sharing.\n\n\n<h3>What security policy prevented cross origin sharing before CORS was implemented?</h3>\n\nThe Same Origin Policy.\n\n\n<h3>What does a server check for in a request from a client to ensure that the client is one of the hosts that it can communicate with?</h3>\n\nIt checks that the origin header contains a value of one of the domain's it has allowed. If the origin value is permitted, the server will respond with a header of its own called Access-Control-Allow-Origin containing the permitted domain policy.\n\n\n<h3>Describe the relationship between the SOP and CORS.</h3>\n\nSOP's intent is to prevent malicious third parties from acting on behalf of logged in users by checking the origin of the request. The CORS mechanism was implemented after it was realized there was a significant need for better system to system communication. CORS enabled servers check that requests come in from one of the allowed domains that the server is aware of. The check is made using HTTP headers.\n\n\n<h3>Why was CORS developed?</h3>\n\nTo understand this it is helpful to have an idea of what prevented cross origin sharing in the first place, which was the Same Origin Policy. This policy prevented servers from accepting requests from hosts/domains/origins other than its own, it was developed to enhance security. Some years later the tech community decided there should be a secure means of allowing the communication between systems that want to integrate with one another to enhance their product or systems capabilities. The mechanism that came to allow this is what is known as CORS."},{"slug":"2021-understanding-elixir-agent","category":"blog","title":"Understanding Elixir Agent","description":"Understanding Elixir Agent through explanation","tags":["elixir"],"body":"\nThis and the other \"Deck\" posts are a repurposing of flashcard study decks to Q&A blog posts. \n\n<h3>What is an Elixir Agent?</h3>\nThey are a means of spawning an Elixir Process but with added the intention of keeping track of state.\n\n<h3>When should you used an Agent vs GenServer?</h3>\nThis is a matter of the developers personal preference. `Agent` requires less code to write, but is slightly less efficient than a GenServer.\n\n<h3>Agents are said to separate the client and server API's, explain this through an example Server: </h3>\n\n```elixir\n# Compute in the agent/server \ndef get_something(agent) do \n  Agent.get(agent, fn state -> do_something_expensive(state) end)\nend \n\n# Compute in the agent/client \ndef get_something(agent) do \n  Agent.get(agent, & &1) |> do_something_expensive() \nend\n```\n\nIn the first `get_something` function above the agent process is calling the `do_something_expensive/1` function. In the second `get_something` function it is client process (the process that called `get_something/1`) that computes `do_something_expensive/1`. In the case of a long running process it is generally preferred to handle the expensive function in the client so the `Agent` is not blocked. If the function were `do_something_inexpensive` where the process would not be blocked by heavy compute, then it could make more sense to handle it within the agent process. Code example from https://hexdocs.pm/elixir/1.12/Agent.html\n\n\n<h3>Why do we not want clients to be able to pass callback functions to the Agent?</h3>\nIf the client were to pass in a function that does a lot of processing the `Agent` would be blocked until the request is completed. Keeping the client and server API's separate alleviates this concern.\n\n<h3>Are Agents usually supervised or unsupervised?</h3>\nSupervised. An `Agent` is usually started under a `Supervisor`.\n\n"},{"slug":"2021-understanding-elixir-comprehensions","category":"blog","title":"Understanding Elixir Comprehensions","description":"Understanding Elixir Comprehensions through explanation","tags":["elixir"],"body":"\nThis and the other \"Deck\" posts are a repurposing of flashcard study decks to Q&A blog posts. \n\n<h3>What is an Elixir Comprehension?</h3>\nIt is another way to loop over an Enumerable, just like the Enum module, only with a different syntax.\n\n\n<h3>What Elixir data types are Enumerable?</h3>\n`List`, `Map`, `Range`, `MapSet`.\n\n\n<h3>How does an Elixir Comprehension differ from an Enum?</h3>\nThere is no difference in terms of performance and what you can accomplish functionally. The difference is in developer preference.\n\n\n<h3>What is the generator in a Comprehension?</h3>\nIt is the Enumerable being passed into the comprehension. In the below example `<- [1, 3, 5]` is the generator being passed into the comprehension. \n```\nfor n <- [1, 3, 5], do: n * 2\n```\n\n\n<h3>Can multiple generator's be used within a Comprehension?</h3>\nYes. If you need to perform a set of operations on an Enumerable, you can use multiple generators.\n\n\n<h3>Can you use pattern matching with Comprehensions?</h3>\nYes. The below example pattern matches a keyword list of http responses for user requests and returns only the successes. \n\n```\n=> responses = [ok: %{name: \"Joe\", email: \"joe@friendo.com\"}, error: \"invalid request\", error: \"invalid request\", ok: %{name: \"Jen\", email: \"jen@friendo.com\"}] \n=> for {:ok, msg} <- responses, do: msg \n[\n  %{email: \"joe@friendo.com\", name: \"Joe\"},\n  %{email: \"jen@friendo.com\", name: \"Jen\"}\n]\n```\n\n\n<h3>Write the equivalent Comprehension and Enum code for accepting a List and multiplying it by two.</h3>\n\n```\n=> for n <- [1, 3, 5], do: n * 2\n[2, 6, 10]\n``` \n\n```\nEnum.map([1,3,5], &(&1 * 2))\n```\n[2, 6, 10]\n\n"},{"slug":"2021-understanding-elixir-enum","category":"blog","title":"Understanding Elixir Enum Module","description":"Understanding Elixir Enum","tags":["elixir"],"body":"\nThis and the other \"Deck\" posts are a repurposing of flashcard study decks to Q&A blog posts.\n\n<h3>What is an Elixir Enum?</h3>\nIt's a Protocol that defines a set of functions to operate on enumerable data types.\n\n\n<h3>When should you use the Enum module?</h3>\nWhen you need to perform an operation against a collection and the collection's type does not implement the function you are looking for, the `Enum` module likely implements it.\n\n\n<h3>What data types is the Enum module implemented for?</h3>\n`List`, `Map`, `Range`, `MapSet`.\n\n\n<h3>What does it mean to say \"functions on the Enum module run in linear time\"?</h3>\nWhen performing operations Elixir's `Enum` always begings with the first element and ends with the last, the larger the enum is the less efficient the operation will be.\n\n\n<h3>What does the Enum.concat/2 function do?</h3>\nIt combines the first enum argument with the second enum argument. \n\n```\n=> Enum.concat(%{user: \"kevs_burgers\"}, %{name: \"Kevin\"})\n[user: \"kevs_burgers\", name: \"Kevin\"]\n```\n\n<h3>What does the Enum.find/2 function do?</h3>\nIt accepts an enumerable and a callback function as arguments. It returns the first element that the function passed to it returns a truthy value for. \n\n```\n=> colors = [\"blue\", \"yellow\", \"red\"] \n=> Enum.find(colors, fn (color) -> color == \"red\" end) \n\"red\"\n```\n\n\n<h3>What does the Enum.map/2 function do?</h3>\nIt accepts an enumerable and a function as arguments. It returns a new Enum containing the result of the callback function for each element in the Enum. \n\n```\n=> colors = [\"blue\", \"yellow\", \"red\"] \n=> Enum.map(colors, fn (color) -> \"#{color}ish\" end) \n[\"blueish\", \"yellowish\", \"redish\"]\n```\n\n"},{"slug":"2021-understanding-elixir-functions-for-new-developers-pt1","category":"blog","title":"Understanding Elixir Functions for new developers part 1","description":"elixir functions explained for new devs","tags":["elixir"],"body":"\nThis and the other \"Deck\" posts are a repurposing of flashcard study decks to Q&A blog posts. \n\n<h3>What does it mean to say \"Functions are first class citizens.\" in Elixir?</h3>\n\nFunctions are a foundational data type in Elixir and can be assigned to a variable. Which is not the case in other languages, for example, Ruby where functions exist as methods on objects.\n\n\n<h3>What are some benefits of using a programming language with functions as first class citizens?</h3>\n\n1. You can pass functions as arguments to other functions. \n2. You can return functions from other functions. \n3. Functions can be stored in other data structures like Maps and Lists.\n\n\n<h3>How do modules relate to functions in Elixir?</h3>\n\nModules are used as the way to group functions to a business/entity context of our application. In the example below `Account` is our module/business context and the functions are defined inside of it: \n```\ndefmodule Account do \n  def get_details(id) do \n  end \n\n  def some_other_function_related_to_account do \n  end \nend \n```\n\n\n<h3>Are functions always defined within a module?</h3>\n\nNamed functions are, but anonymous functions do not have to be.\n\n\n<h3>What are the different ways to define a function in Elixir?</h3>\n\nYou can define them within a module as named functions: \n```\ndefmodule Account do \n  def get_details(id) do \n  end \nend\n``` \nOr as an anonymous function, which there are two ways to define: \n\n```\nsubtract = fn (a, b) -> a - b end\n``` \n\n```\nsubtract = &(&1 - &2)\n```\n\n\n<h3>Write the code for how you would invoke the functions mentioned in the previous question.</h3>\n\n```\ndefmodule Account do \n  def get_details(id) do \n  end \nend\n``` \n```\nsubtract = fn (a, b) -> a - b end\n``` \n```\nsubtract = &(&1 - &2)\n``` \n\n```\nsubtract.(2,1)\n``` \n\n```\nAccount.get_details(\"agf23EDf4weDre5r\")\n```\n\n\n<h3>Why must named functions be defined within a module?</h3>\n\nBy grouping functions within a module we keep the global namespace of our programs cleaner and make our programs easier to reason about. If we didn't have named functions scoped in modules we could quickly run into an issue where we defined the same named function later on in our project which change s the behavior of the initial implementation entirely.\n\n\n<h3>When are anonymous functions most used?</h3>\n\nAs callback functions aka arguments to other functions. `Enum.map` is a good example: \n```\nEnum.map(fn(num) -> num * 3 end)\n```\n\n\n<h3>What is the difference between the def and the defp statements when defining named functions?</h3>\n\n`defp` indicates that the function is private to the module it is defined in and can only be invoked by the other functions in that module. `def` functions can be invoked from other modules and the module it is defined in.\n\n\n<h3>What is the syntax for setting a default parameter to a function?</h3>\n\n`\\\\`. In the function below if params are not provided, the params variable will be set to an empty Map. \n```\ndef create(params \\\\ %{}) do \n  %DevDecks.User{} |> cast(params, [:email, :name]) |> Repo.insert() \nend\n```\n"},{"slug":"2021-understanding-elixir-functions-for-new-developers-pt2","category":"blog","title":"Understanding Elixir Functions for new developers part 2","description":"elixir functions explained for new devs","tags":["web-security"],"body":"\nThis and the other \"Deck\" posts are a repurposing of flashcard study decks to Q&A blog posts. \n\n<h3>What is the another way of saying a function accepts 4 arguments in Elixir?</h3>\n\nThe function has an arity of 4.\n\n\n<h3>Can named functions have multiple definitions in Elixir?</h3>\n\nNamed functions can have multiple definitions inside a module, but they should have a different arity otherwise the last definition will always match.\n\n\n<h3>How do function clauses work with Elixir named functions?</h3>\n\nWhen calling a function with multiple definitions Elixir will invoke the one that matches the argument(s) passed to it, aka the clause that matches it. This is another example of pattern matching where the function invoked is that which matches the pattern of the argument(s).\n\n\n<h3>How do function clauses work in Elixir anonymous functions?</h3>\n\nWhen defining an anonymous function you can have it pattern match against expected results. This is often seen with response tuples like in the example below: \n```\nresponse = fn \n  {:ok, response} -> IO.puts(\"successful operation\")  \n  {:error, error} -> IO.puts(\"unsuccessful operation\") \nend\n```\n\n\n<h3>What are function guard clauses?</h3>\n\nThese are checks, often in the beginning of a function definition, that determine if a function should continue execution or return early. As an example guards are often used in web applications by checking for authorization and returning early if the request is unauthorized.\n\n\n<h3>How can you define guard clauses in Elixir?</h3>\n\nYou can use the `when` statement to only execute a function if a condition is met. \n```\ndefmodule Account do \n  def is_admin?(id) do \n    # admin check to return boolean \n  end \n    \n  def get_admin_details?(id) when is_admin(id) do \n    # only get admin details if admin \n  end \nend\n```\n\n\n<h3>What happens if a there is no clause defined for an argument passed to a function?</h3>\n\nElixir will error with a `FunctionClauseError`.\n\n\n<h3>How do you indicate that a function will return a boolean value?</h3>\n\nEnd the function name with a ?. For example: \n```\ndef is_admin?(user = %{}) \n  user.admin? \nend\n```\n\n\n<h3>How do you bind a named function to a variable?</h3>\n\nUsing the capture operator. In the example below Elixir uses the capture operator to store the Map.put function, with an arity of 3. \n```\nupdate_map = &Map.put/3 \nupdate_map.(\n  %{name: \"Humphry Dobs\", email: \"thedobinator@emailsalot.com\"}, \n  :age,  \n  25\n)\n```\n\n\n<h3>Can the capture operator be used for creating shorter anonymous functions?</h3>\n\nYes. The examples below accomplish the same thing. The &1, &2, &3 refer to the first second and third arguments of the shorthand capture function. \n```\nadd_three_without_capture = fn (a, b, c) -> a + b + c end \nadd_three_without_capture.(2, 4, 3) \n\nadd_three_with_capture = &(&1 + &2 + &3) \nadd_three_with_capture.(2, 4, 3)\n```\n"},{"slug":"2021-understanding-elixir-genserver","category":"blog","title":"Understanding Elixir GenServer","description":"Understanding Elixir GenServer through explanation","tags":["elixir"],"body":"\nThis and the other \"Deck\" posts are a repurposing of flashcard study decks to Q&A blog posts. \n\n<h3>What is an Elixir GenServer?</h3>\nIt is a means of spawning an Elixir Process but with the added intention of keeping track of state. GenServer comes with a set of predefined callback functions to help with this.\n\n\n<h3>What are the advantages of GenServer vs other process management tools?</h3>\n1) `GenServer`s callback functions are standardized. Once you understand them, you understand how to work with any `GenServer`. \n2) `GenServer`s provide a mechanism for keeping track of state. \n3) `GenServer`s provide the ability to execute asynchronously or synchronously. \n4) `GenServer`s provide functionality for tracing and error reporting.\n\n\n<h3>Are GenServer processes supervised by a parent process?</h3>\nThey can be, but it's not required.\n\n\n<h3>Do all GenServer callback functions need to be implemented in each GenServer?</h3>\nNo. Each `GenServer` only needs to implement the callback functions it needs. The only required callback function is `init`.\n\n\n<h3>What is the init callback function used for?</h3>\nThis is invoked whenever the server is started. It can be used to pass initial state to the GenServer.\n\n\n<h3>What is the handle_call callback function used for?</h3>\nThis callback is used whenever you want to handle synchronous messages to the server. It is invoked through `GenServer.call`.\n\n\n<h3>What is the handle_cast callback function used for?</h3>\nThis callback is used whenever you want to handle asynchronous messages to the server. It is invoked through `GenServer.cast`.\n\n\n<h3>What is the handle_info callback function used for?</h3>\nThis is used for all other messages to the server, for example process crash messages. It is invoked in different ways including the `Kernel.send` function or `Process.monitor`.\n\n\n<h3>How many GenServer callback functions exist and what are they?</h3>\n8. `init`, `handle_call`, `handle_cast`, `handle_info`, `code_change`, `format_status`, `handle_continue`, `terminate`.\n\n\n<h3>Are GenServers used for code organization, for handling mutable state, or for providing concurrency?</h3>\nGenServers are used to for handling of mutable state and for providing concurrency. GenServer's are not used for code organization.\n\n"},{"slug":"2021-understanding-elixir-maps-for-new-developers","category":"blog","title":"Understanding Elixir Maps for new developers","description":"elixir maps explained for new devs","tags":["elixir"],"body":"\nThis and the other \"Deck\" posts are a repurposing of flashcard study decks to Q&A blog posts. Google was not showing love to this content as a set of flashcards and I didn't want to delete them entirely, I hope you find it useful.\n\n<h3>What is an Elixir Map?</h3>\n\nThey are the most often used key/value store data type in Elixir.\n\n\n<h3>What is a Map used for?</h3>\n\nMaps are used to associate data elements with meaningful keys and the data associated with that key can be retrieved or updated using its key.\n\n\n<h3>What are different ways to add a new value to a Map?</h3>\n\nUsing the Map module: \n```\nMap.put(%{name: \"Humphry Dobs\", email: \"thedobinator@emailsalot.com\"}, :age, 24)\n``` \nOr Using the Kernel module: \n```\nput_in %{name: \"Humphry Dobs\", email: \"thedobinator@emailsalot.com\"}[:age], 24\n```\n\n\n<h3>Does Elixir contain an operator for updating a keys value?</h3>\n\nYes, the operator is `|`, but key has to exist, otherwise the code will error. The first example below updates the value for key `one:`, the second example tries to update the value for key `three:`, which doesn't exist so a `KeyError` is thrown. \n```\n=>map = %{one: 1, two: 2} \n=> %{map | one: \"one\"} \n%{one: \"one\", two: 2}\n``` \n```\n=> map = %{one: 1, two: 2}\n=> %{map | three: 3} \n(KeyError)\n```\n\n\n<h3>How can you read a value from a Map without pattern matching?</h3>\n\nThrough access syntax, `[]`. \n```\n=> %{:key => \"value\"}[:key] \n\"value\"\n``` \nIf the key is an atom you can also use the static lookup syntax. \n```\n=> %{:key => \"value\"}.key \n\"value\"\n```\nOr through the Map module. \n```\n=> Map.get(%{a: 1}, :a) \n1\n```\n\n\n<h3>How can you read a value from a Map using pattern matching?</h3>\n\n```\n=> %{:a => a} = %{:a => 12, :b => 14} \n=> a \n12\n``` \nThe variable `a` above is set using pattern matching. It will return the value of the key `:a`. In this case that is 12.\n\n\n<h3>What happens when you try to pattern match on a key that doesn't exist?</h3>\n\nAn error is thrown. The below will return a `MatchError`. \n```\n%{:c => c} = %{:a => 12, :b => 14} \n=> (MatchError)\n```\n\n\n<h3>Can you use a variable for defining a key?</h3>\n\nYes. In the example below the variable `t` is a variable used as a key for the value \"dog\". \n```\n=> t = :type\n=> %{t => \"dog\", :name => \"Abby\"}[:type] \n\"dog\"\n```\n"},{"slug":"2021-understanding-elixir-mapset","category":"blog","title":"Understanding Elixir MapSet","description":"Understanding Elixir MapSet through explanation","tags":["elixir"],"body":"\nThis and the other \"Deck\" posts are a repurposing of flashcard study decks to Q&A blog posts. \n\n<h3>What is a MapSet?</h3>\nA `MapSet` is a `Set`. Sets are data structures that can contain unique elements of any kind.\n\n<h3>How does a MapSet differ from a Map?</h3>\nA `Map` is an associative data structure where a `MapSet` is not.\n\n<h3>Can a MapSet contain duplicate values?</h3>\nNo. If a duplicate value is provided to a `MapSet` it will result in a no-op.\n\n<h3>When do you use a MapSet?</h3>\n`MapSet`s are really fast data structures and are often used when in need of optimum search performance.\n\n<h3>How do you create a MapSet?</h3>\nUsing `MapSet.new/0`. All data must be added to the `MapSet` after it is constructed.\n\n<h3>How do you add a value to a MapSet?</h3>\nUsing `Mapset.put/2`\n``` \n=> ms = MapSet.new() #MapSet<[]> \n=> MapSet.put(ms, \"new_value\") \n#MapSet<[\"new_value\"]> \n```\n\n\n<h3>How do you remove a value in a MapSet?</h3>\nUsing `Mapset.delete/2`\n```\n=> ms = MapSet.new() \n=> MapSet.put(ms, \"new_value\") \n=> MapSet.delete(ms, \"new_value\") \n```\n\n<h3>How do you iterate a MapSet?</h3>\nA `MapSet` is an Elixir Enumerable. Like other Enumerables you can use the `Enum` module to iterate the collection ex `Enum.map/2`\n\n"},{"slug":"2021-understanding-elixir-mix","category":"blog","title":"Understanding Elixir Mix","description":"Understanding Elixir Mix through explanation","tags":["elixir"],"body":"\nThis and the other \"Deck\" posts are a repurposing of flashcard study decks to Q&A blog posts. \n\n<h3>What do Elixir developers use Mix for?</h3>\nMany different things. Mix is used for creating Elixir apps, for compiling Elixir apps after code changes, to run an apps test suite, to resolve third party dependency compatibility, and for executing custom tasks.\n\n<h3>What does it mean to say Mix is an Elixir executable?</h3>\nExecutable files are files that can be run by a computer's operating system, they are not data files like your projects source code. Elixir has its own executable and Mix is another executable built on top of Elixir's.\n\n<h3>How does Mix help with dependency management?</h3>\nThrough an integration with Hex package mananger Mix applications can use third party dependencies. Hex is the tool doing the package compatibility resolution. Mix provides a way to declare dependencies and command line tasks for installing, removing, or updating dependencies, these tasks use Hex to accomplish this.\n\n<h3>How can you tell Mix that you are using third party dependencies in your project?</h3>\nIn your applications `mix.exs` file you can declare a private `deps` function which includes a list of your dependencies and then execute `mix deps.get` to install them. \n\n```\ndefmodule MyApp.MixProject do \n  use Mix.Project \n\n  def project do \n    [ deps: deps() ] \n  end \n  \n  defp deps do \n    [ {:ecto, \"~> 2.0\"} ] \n  end \nend\n```\n\n\n<h3>How to you find the PATH that the Mix executable exists on macOS?</h3>\nYou can do this through the command line by executing `which mix`.\n\n\n<h3>Below is an example of a custom Mix task, how would you invoke this task?</h3>\n\n```\ndefmodule Mix.Tasks.Hello do \n  use Mix.Task \n  \n  def run(_) do \n    Mix.shell().info(\"Hello world\") \n  end \nend\n```\n\nOn the command line execute `mix hello`.\n\n\n<h3>If using Ecto for database interactions what are some Mix tasks you might use?</h3>\n- `mix ecto.create` - creates the Ecto db. \n- `mix ecto.dump` - creates a file showing the db structure. \n- `mix ecto.gen.migration create_accounts` - creates a migration file that will be used to alter the db structure, in this case create the accounts table. \n- `mix ecto.migrate` - runs migrations that have not been previously run.\n\n\n<h3>What tasks does Mix provide that are specific to Phoenix applications?</h3>\n- `mix phx.new app_name` - creates a new Phoenix project \n- `mix phx.routes` - shows a list of routes \n- `mix phx.server` - starts the application and all servers\n\n"},{"slug":"2021-understanding-elixir-process","category":"blog","title":"Understanding Elixir Process","description":"Understanding Elixir Process through explanation","tags":["elixir"],"body":"\nThis and the other \"Deck\" posts are a repurposing of flashcard study decks to Q&A blog posts. \n\n<h3>What are BEAM Processes?</h3>\nThey are lightweight execution contexts that run Elixir code in their own memory space. Processes can communicate with one another through message passing.\n\n\n<h3>How are BEAM Processes created?</h3>\nThere are multiple modules and mechanisms for creating processes but they use `spawn/1` function under the hood.\n\n\n<h3>What is a PID in relation to BEAM processes?</h3>\nIt is the process identifier. Anytime a process is spawned it will return a PID you can use to inspect the process and send messages to it.\n\n\n<h3>How can you check if a specific BEAM Process still exists?</h3>\nThere is an `is_alive?` function in the `Process` module that accepts a pid and returns a `true` or `false` boolean.\n\n\n<h3>How does Elixir's `receive` block relate to processes?</h3>\nA `receive` block is waiting for a message to be sent to the process that defines it. When a `receive` block is encountered further processing is paused until a message is sent to the process and executed by the `receive` block.\n\n\n<h3>Is there a function to send a message to another BEAM Process?</h3>\nYes, the Kernels `send/1` function.\n\n\n<h3>What are BEAM Supervisor's used for?</h3>\nThey help manage processes. Another way to think about it is they are linked to the child processes they supervise. Supervisors are frequently used to spawn new processes if one fails, but other strategies exist as well.\n\n\n<h3>What is a supervision tree?</h3>\nThere can be Supervisors for other Supervisors. This creates a network/tree of supervisor processes known as a supervision tree.\n\n\n<h3>Is it possible to get a graphical view of an Elixir applications supervision tree?</h3>\nYes. When you start an Elixir application in interactive mode using `iex` you can call `:observer.start` in the terminal and a GUI will appear. If you navigate to the applications tab it will show you the supervision tree of your application.\n\n\n<h3>What are process pools?</h3>\nProcess pools are a group of long running processes that are waiting to be used. A good example is the Ecto database management library. It will spawn a pool of ten connections at startup time to be used by your application. It does this instead of spawning a new process for each connection because establishing a database connection can be a heavy task in terms of resource utilization.\n\n\n<h3>What are some examples of processes in a Phoenix application?</h3>\n1. Each HTTP request spawns a new process using the Cowboy and Ranch libraries. \n2. Ecto uses a process pool to handle database connections.\n\n"},{"slug":"2021-understanding-elixir-range","category":"blog","title":"Learn Elixir through Q&A: Ranges","description":"Understanding Elixir Range through explanation","tags":["elixir"],"body":"\nThis and the other \"Deck\" posts are a repurposing of flashcard study decks to Q&A blog posts. \n\n<h3>What is an Elixir Range?</h3>\nIt is way to work with a sequence of integers more effectively without having to explicitly define each integer in the sequence. It also helps with more efficiently checking if a values falls within a sequence of integers. Instead of having to write `[1,2,3,4,5, ...]` you can instead write `1..5`.\n\n\n<h3>Can a Range be either ascending or descending?</h3>\nYes the following two examples are both valid ranges: \n\nASC\n```\n2..20\n``` \n\nDESC\n```\n20..2\n```\n\n\n<h3>How can pattern matching be used to set a variables to contain the values of the start and end integers of a range?</h3>\nUsing left hand assignment where the range variables are declared left of the equals sign (match operator) like so: \n\n```\nscore_range = 2..20 \nstart..finish = score_range \n=> start\n2\n=> finish 20\n20\n```\n\n\n<h3>Do Enum module functions work with Ranges?</h3>\nYes. `Enum` module functionality is implemented for Ranges. Two example functions: \n\n```\nEnum.member?/2\n``` \n\n```\nEnum.count/1\n```\n"},{"slug":"2021-understanding-elixir-steams","category":"blog","title":"Understanding Elixir Streams","description":"Understanding Elixir Streams through explanation","tags":["elixir"],"body":"\nThis and the other \"Deck\" posts are a repurposing of flashcard study decks to Q&A blog posts. \n\n<h3>What is an Elixir Stream and what is its purpose?</h3>\nThey are a collection of data elements with a distinct difference from other collections; the data is available and processed in specified chunks when it becomes available. This is opposed to bringing the entire collection into application memory and processing the collection all at once.\n\n<h3>Streams are most often used when there are memory usage concerns with a large amount of data. How does a Stream mitigate this concern?</h3>\nInstead of bringing the large dataset into memory and operating against it at once, which could result in an Out of Memory error, a stream brings data into memory one chunk at a time and operates on each data element individually.\n\n\n<h3>When would you want to use a Stream?</h3>\n1) When processing large amounts of data in a file, for example translating a large text file into a different language or generating reports against large amounts of data. \n2) When processing an unknown amount of data coming over a network at any time.\n\n\n<h3>Does every Enum function exist on the Stream module?</h3>\nNo, but you can find a reference of Stream functions at https://hexdocs.pm/elixir/Stream.html#functions.\n\n\n<h3>Annotate the processing steps the below range goes through:</h3>\n```\n1..3 |> Stream.map(&(IO.inspect &1)) |> Stream.map(&(&1 + 2)) |> Stream.map(&(IO.inspect &1)) |> Enum.to_list\n```\n1) The range is piped one element at a time into a Stream containing the functions that will process the stream. \n2) Once the stream is piped into `Enum.to_list` the first element of the enumerable is run against all of the functions in the order they occurred. \n3) After the three stream functions are executed against the first element in the range the second element is run through the stream functions. \n4) This occurs until the range is completed. \n\n```\n1\n3\n2\n4\n3\n5\n=> [3, 4, 5]\n```\n\n\n<h3>How do the processing steps the previous range differ from the same range piped to Enum?</h3>\n\n```\n1..3 |> Enum.map(&(IO.inspect &1)) |> Enum.map(&(&1 + 2)) |> Enum.map(&(IO.inspect &1)) |> Enum.to_list\n```\n\n1) The range is immediately operated on by the first Enum.map call. \n2) The entire range is operated on in each step before being piped into the next Enum.map call. \n\n```\n1\n2\n3\n3\n4\n5\n[3, 4, 5]\n```\n\n"},{"slug":"2021-understanding-elixir-supervisor","category":"blog","title":"Understanding Elixir Supervisor","description":"Understanding Elixir Supervisor through explanation","tags":["elixir"],"body":"\nThis and the other \"Deck\" posts are a repurposing of flashcard study decks to Q&A blog posts. \n\n<h3>What is the function of an Elixir Supervisor?</h3>\nIt is a process that monitors other processes and restarts them based on a specified supervision strategy.\n\n\n<h3>How are supervisors related to the Elixir axiom \"let it crash\"?</h3>\nSupervisors will spin up new processes in the event of a failure. If a process errors/fails a new one will be started without the developer having to step in and restart anything. Aka they can \"let it crash\".\n\n\n<h3>How are processes under supervision related to the Supervising process?</h3>\nThey are considered child processes of the supervisor.\n\n\n<h3>How do you start a supervisor that monitors child processes?</h3>\nYou pass a list of child processes to the supervisor. Each child process is a `Map` that contains keys of `id` and `start`. The `id` is the process and `start` is a `Tuple` containing information on how to run the process. Example below: \n\n```\nchildren = [ %{ id: ChildProcess, start: {ChildProcess, :start_link, [[:initial_state]]} } ] \n{:ok, pid} = Supervisor.start_link(children, strategy: :one_for_one)\n```\n\n\n<h3>What supervision strategy should be used if you want only the specific child process that terminates to be restarted?</h3>\n`one_for_one`\n\n\n<h3>What supervision strategy should be used if you want all child processes to be restarted if any of them terminate?</h3>\n`one_for_all`\n\n\n<h3>What supervision strategy should be used if you want all processes started after the terminated one to also be terminated and restarted?</h3>\n`rest_for_one`\n\n\n<h3>What is a supervision tree?</h3>\nIt is a hierarchy of process supervisors. This means that a process that is under supervision can also have its own child processes that it supervises.\n\n"},{"slug":"2021-understanding-elixir-task","category":"blog","title":"Understanding Elixir Task","description":"Understanding Elixir Task through explanation","tags":["elixir"],"body":"\nThis and the other \"Deck\" posts are a repurposing of flashcard study decks to Q&A blog posts. \n\n<h3>What is an Elixir Task?</h3>\nIt is a means of spawning an Elixir Process but with asynchronous capabilities, which is its main use case.\n\n\n<h3>When do you use a Task?</h3>\nThey are often used for interacting with external services. Using a `Task` in this way makes otherwise synchronous code asynchronous, so your code can do other work while the `Task` is working.\n\n\n<h3>What does the code look like for spawning an asynchronous Task and reading its message upon completion?</h3>\n```\n=> task = Task.async(fn -> IO.puts(\"processing\") end) \n=> Task.await(task)\n``` \nIn the above example the `Task` is executed using `async/1` and its message will be available as a result of `await/1`.\n\n\n<h3>What Task function should be used when you have no interest in the result of its completion?</h3>\n`start/1`, which accepts an anonymous function to be executed. The anonymous function must have no arguments.\n\n\n<h3>Can you spawn multiple Tasks and await all of their completion?</h3>\nYes. You can map over a list of `Task`s and provide the `Task.await` function as the callback to each task in the list.\n\n```\n=> tasks = Enum.reduce(0..9, [], fn _, acc -> [Task.async(&any_job/0) | acc] end) \n\n=> Enum.map(tasks, &Task.await/1)\n```\n\n<h3>Do Tasks use message passing?</h3>\nNot often. A `Task` is used for one specific action.\n\n"},{"slug":"2021-understanding-jwt","category":"blog","title":"Understanding JWT","description":"Understanding JWT through q&a","tags":["web-security"],"body":"\nThis and the other \"Deck\" posts are a repurposing of flashcard study decks to Q&A blog posts. \n\n<h3>What is a JSON web token (JWT)?</h3>\nIt is an access / authorization token that can be used when making requests to application servers to grant or deny access to server resources using the contents of the token for this determination.\n\n\n<h3>There are 3 components of a JWT what are they?</h3>\nHeader, Payload, and Signature.\n\n\n<h3>What is the role of the payload in a JWT token?</h3>\nThe payload contains the data the systems are interested in. Often it will be data about a user but it could be anything like bank transfer information.\n\n\n<h3>What are claims in a JWT?</h3>\nClaims are essentially the payload but with different categories of types of payload data. There are registered claims which are predefined payload keys such as iss (issuer), exp (expiration). Claims exist as public or private, which are covered later in this deck.\n\n\n<h3>What is the role of the header?</h3>\nThe header contains metadata about how the server signed the token, which algorithm it used. The server will use the header determine which algorithm to use to decode it.\n\n\n<h3>What is the role of the signature?</h3>\nThe signature is what verifies the validity of the token. It is created using a secret key and is comprised of the contents of the token header and payload. The signature is used to verify that the contents of the token were not changed.\n\n\n<h3>Is a JWT an access token?</h3>\nYes it is. It is what grants users access to different server resources.\n\n\n<h3>List options for storing JWT in the browser.</h3>\nThe two most common options are to store it as a cookie or in localStorage.\n\n\n<h3>If you store a JWT as localStorage in the browser how does it get sent back to the server as a part of a web request?</h3>\nYou will have to query for the token from localStorage and alter your request to include the token either as a header or parameter.\n\n\n<h3>If you store a JWT as a cookie in the browser how does it get sent back to the server as a part of a web request?</h3>\nCookies are sent with every browser request, so this will be sent with each request the browser makes to the origin server (the server that rendered the html).\n\n\n<h3>When it's said that the server signed the token, what does that mean?</h3>\nThis is the servers way of saying the data it is signing needs to be returned in its current form, otherwise when the server checks for the token for validity it will not pass inspection.\n\n\n<h3>Describe the relationship between a browser client and application server that generated the JWT? </h3>\nThe client often store's the JWT in client side storage and passes the token back to the server on requests to verify that the user still has a valid session and has access to the resource they are requesting.\n\n\n<h3>What is a refresh token and how can they be used with JWT's?</h3>\nSince our JWT is an access token, the refresh token is an optional second token that can be used to issue a new access token when the current one expires. This can be useful to limit your exposure if an attacker is able to obtain a valid token.\n\n\n<h3>What additional security benefit does JWE provide what JWT does not?</h3>\nJWE adds encryption. This means that the data in the token cannot be read without a key that is only distributed to trusted systems to unlock it, allowing you to store more sensitive data than would be stored in a traditional JWT. Try decoding a JWT to see anyone can unlock it. Run atob(\"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9\") in your developer tools. This is the header part of the example token on jwt.io.\n\n\n<h3>If you are going to store private/sensitive data in a token what type of token would you use?</h3>\nJWE because the data would be encrypted and unreadable by another party without your consent.\n\n\n<h3>Why is it important to expire a JWT?</h3>\nYou want to expire a JWT so that a bad actor has a smaller time period to use a valid token as a means of authentication. An example could be one of your users is logged into your system and you store a JWT on their computer, then they step away from their computer and a few minutes later a bad actor sees the computer left alone and decides to perform unwanted actions without the users knowledge. If the token had expired then the user would not have been vulnerable to such an event.\n\n\n<h3>How are refresh tokens used?</h3>\nAfter a token has expired a client will send a post request to a different authorization server endpoint than they one that granted them the JWT, this endpoint might be called /renew. That post request will include the refresh token which the auth server will then make sure is valid and issue a new access token as a response.\n\n\n<h3>When might you opt for session authorization over JWT when building an application?</h3>\nIf you are building a monolithic application where your application does not need to communicate with other servers in your system then it may make sense to use session storage mechanisms your backend technology provides for auth.\n\n\n<h3>What is the difference between a public and private claim?</h3>\nConsider the difference between a public API vs a private API. A public API is well documented and can be read by anyone, while a private API can only be read by the API team and those who are consuming it and that data is agreed upon in advance by the parties involved. The same can be said of claims, they differ in their level of exposure. Private claims can only be read by the parties that agree to them and public claims can be read by anyone.\n\n\n<h3>What happens when a JWT is tampered with or altered?</h3>\nIt is invalidated. Since the tokens signature is generated from the contents of the header and payload any alterations made to either will cause the token to become corrupted.\n"},{"slug":"2021-understanding-preflight-requests","category":"blog","title":"Understanding Preflight Requests","description":"Understanding Preflight Requests security concepts","tags":["web-security"],"body":"\nThis and the other \"Deck\" posts are a repurposing of flashcard study decks to Q&A blog posts. \n\n<h3>What is a preflight request?</h3>\nBefore certain HTTP requests are made to a server a preflight HTTP request is first sent to that server using the OPTIONS method to make sure the request that follows is safe. A request will be preflighted if: - Any custom request headers are included. Custom request headers are any outside of the following: Accept, Accept-Language, Content-Language, Content-Type, DPR, Width, Downloadlink, Save-Data, Viewport-Width. - If any values are set for the Content-Type header that are not: application/x-www-form-urlencoded, multipart/form-data, text/plain - Preflight is automatically issued when using the following HTTP methods: PUT, PATCH, DELETE, CONNECT, TRACE.\n\n\n<h3>What does the preflight request do to make sure the request that follows is safe?</h3>\nIt makes sure that the server that is receiving the request is a CORS enabled server. Older servers built before the time of or without implementing CORS and the Same-origin Policy could be susceptible to an attack from a malicious 3rd party sending requests on behalf of an unsuspecting user.\n\n\n<h3>What is a simple request?</h3>\nA simple request is any HTTP request that is not preflighted these requests must satisfy the following conditions: - Do not include custom headers. - Do not include values set for the Content-Type header outside of: application/x-www-form-urlencoded, multipart/form-data, text/plain. - Use either the GET, POST, or HEAD methods.\n\n\n<h3>If a request is preflighted, when is the actual request sent?</h3>\nAfter the preflight request has completed and your request is determined to be safe the request that was intended will be automatically sent.\n\n\n<h3>What request headers can be included in an HTTP request that will not trigger a pre-flight request? </h3>\nAccept, Accept-Language, Content-Language, Content-Type are the four most often noted headers, but also DPR, Width, Downloadlink, Save-Data and Viewport-Width.\n\n\n<h3>What are the HTTP methods that by default will not trigger a preflight request?</h3>\nGET, POST, or HEAD.\n"},{"slug":"2021-understanding-same-origin-policy","category":"blog","title":"Understanding the Same Origin Polcy","description":"Understanding the Same Origin Polcy","tags":["web-security"],"body":"\nThis and the other \"Deck\" posts are a repurposing of flashcard study decks to Q&A blog posts. \n\n<h3>What attacks/vulerabilities does the Same Origin policy help prevent?</h3>\nUser impersonation. Often websites store auth credentials in a cookie on your browser. Without SOP another website could read your credentials and act as you. This might not so bad if they're posting nonsense to your social media account. It would be very bad if they're stealing your banking information.\n\n\n<h3>Is there any relation between the SOP and CORS?</h3>\nSOP's intent is to prevent malicious third parties from acting on behalf of logged in users by checking the origin of the request. The CORS mechanism was implemented after it was realized that some cross origin requests may be necessary for certain systems and instead of ensuring all checks originate from the same domain, it checks that the request comes from one of the allowed domains that the server is aware of using HTTP headers. It may be helpful to think of CORS as a more flexibile SOP.\n\n\n<h3>Why doesn't SOP prevent external images, scripts and css stylesheets from being loaded from other hosts?</h3>\nBrowsers don't enforce SOP restraints when handling the embedded content including HTML image tags, script tags, or CSS links.\n\n\n<h3>Does your web browser or application server enforce the SOP?</h3>\nYour web browser.\n\n\n<h3>What attributes of the origin are verified as a part of SOP?</h3>\nThe protocol, hostname, port. The port expected by default is 80. Below is an attempt to illustrate this: https:// (protocol) devdecks.io (hostname) :80 (port)\n\n\n<h3>What does the Origin in the Same Origin policy refer to?</h3>\nIt refers to the domain of the server that rendered a page in your browser (ex: google.com).\n\n\n<h3>Why do browsers not apply SOP to Posts requests?</h3>\nSOP was implemented to protect the identity of a user by preventing the of reading of client side storage/cookies across domains. So reading client side data is restricted to each domain. Protecting against malicious POST/write requests requires a different security technique usually involving authenticity tokens hidden in the form that are validated on post requests learn more about this in the CORS deck.\n\n\n<h3>How does SOP apply to subdomains of a website? Can one subdomain read cookies from another?</h3>\nA domain/origin acts as it's own independent domain so one subdomain will not pass a Same Origin Policy of another, ex: store.company.com will get an SOP error if it tries to make a request to blog.company.com. Separately, each of these subdomains can set the document.domain to company.com (the top level domain) and pass SOP checks in the origin server.\n\n\n<h3>What is the responsibility of the Same-origin Policy?</h3>\nIt prevents webpages rendered from one server from accepting read/get requests from any other server, ex. https://stackoverflow.com's server can't make a request to https://hankerrank.com. If you are on a webpage then you can also make additional read requests to the server that issued the webpage unless there is a CORS mechanism in place. Write/post requests do not have SOP restrictions.\n"},{"slug":"2021-understanding-url-fragments","category":"blog","title":"Understanding URLs: Fragments","description":"Understanding URL Fragments","tags":["urls"],"body":"\nThis and the other \"Deck\" posts are a repurposing of flashcard study decks to Q&A blog posts. \n\n<h3>What is a URL fragment?</h3>\nIt is a hash containing a single value appended to a url.\n\n\n<h3>What is a URL fragment used for?</h3>\nA fragment is used to identify locations on a page. It can be used to direct users further down on a page where the information they are looking for resides.\n\n\n<h3>Is a URL fragment sent to the server?</h3>\nNo, a fragment is understood and used by the browser only.\n\n\n<h3>When would you use a fragment vs query parameter?</h3>\nYou would use a fragment when you need to scroll the page to a certain section of content, you would use a query parameter to filter specific elements in a collection of data.\n\n\n<h3>What is the syntax for using a URL fragment?</h3>\nThe fragment begins at the # and contains a single value. devdecks.io/about#founding-team or devdecks.io/about#contact-details (these are non functioning examples).\n"},{"slug":"2021-understanding-url-path-parameters","category":"blog","title":"Understanding URLs: Path Parameters","description":"Understanding URL Path Parameter concepts","tags":["urls"],"body":"\nThis and the other \"Deck\" posts are a repurposing of flashcard study decks to Q&A blog posts. \n\n<h3>What is a URL Path?</h3>\nA URL path is the location of a resource within a domain, ex. domain.com/parent_resource/sub_resource.\n\n\n<h3>When should you use a URL Path vs Query Parameter?</h3>\nQuery parameters are most often used to filter for resources within a collection while URL Paths are used to locate a resource type. For example cars.co/toyota/camry is using a url path to find all cars of type Camry but cars.co/toyota/camery?color=red is using the URL path and a query param to filter the collection of Camry's to only give back results that include a color red.\n\n\n<h3>When would you use URL Path vs Subdomain?</h3>\nYou will want to use a URL path instead of a subdomain when the resource is specific to the business function of your main application. Subdomains are used to identify different functions from the core application or for different organizations accessing your application.\n"},{"slug":"2021-understanding-url-query-parameters","category":"blog","title":"Understanding URLs: Query Parameters","description":"Understanding URL Query Parameter concepts","tags":["urls"],"body":"\nThis and the other \"Deck\" posts are a repurposing of flashcard study decks to Q&A blog posts. \n\n<h3>What is a query parameter?</h3>\nA query parameter is a key value pair or set of pairs appended to the end of a URL.\n\n\n<h3>When would you use a path parameter vs query parameter?</h3>\nQuery parameters are most often used to filter for resources within a collection while URL Paths are used to locate a resource type. For example cars.co/toyota/camery is using a url path to find all cars of type Camry but cars.co/toyota/camery?color=red is using the URL path and a query param to filter the collection of Camry's to only give back results that include a color red.\n\n\n<h3>What is a query parameter used for?</h3>\nA query parameter is most often used to filter a collection of data by some attribute of that data. ex data.com/cars?color=red which filters a collection of cars for only those whose color is red.\n\n\n<h3>What is the syntax for using a query parameter?</h3>\nYou first indicate you are using query parameter by using a ? followed by the key value pair, all query parameters after the first use an & to indicate there is another query param `someurl.com?firstQp=bah&secondQp=humbug`.\n"},{"slug":"2021-understanding-urls-subdomains","category":"blog","title":"Understanding URLs: Subdomains","description":"Understanding URL Subdomain concepts","tags":["urls"],"body":"\nThis and the other \"Deck\" posts are a repurposing of flashcard study decks to Q&A blog posts. \n\n<h3>What is a subdomain?</h3>\nIt is a prepended string that is added before the domain of a URL example: blog(subdomain).devdecks.io(domain).\n\n\n<h3>What might you use subdomains for in a web application?</h3>\nSubdomains are used as identifiers within an application often to differentiate between separate functions of an application or organizations. Separating by organization will most often be done in a B2B application eg: fedex.procurementsaasapp.com or forum.procurementsaasapp.com. There can also be multiple if needed: fedex.forum.procurementsaasapp.com.\n\n\n<h3>What is a wildcard subdomain?</h3>\nThis is a DNS CName record with your hosting provider that points all traffic coming in from a subdomain to the root domain for example if there were wildcard subdomains enabled for devdecks.io, then both blog.devdecks.io, and jobs.devdecks.io would point to devdecks.io.\n\n\n<h3>When is it more appropriate to use a URL path instead of a subdomain?</h3>\nYou will want to use a URL path (domain.com/url/path) instead of a subdomain (subdomain.domain.com) when the resource is specific to the business function of your main application. Subdomains are used to identify very different functions from the core application or for different organizations accessing your application.\n\n\n<h3>What is a non wildcard subdomain?</h3>\nHere you would add a DNS CNAME record with your hosting provider for each subdomain you needed. In this case blog.devdecks and jobs.devdecks would have their own CNAME record, all other subdomains would not be recognized by the server.\n"},{"slug":"2021-unique-values-for-db-column-rails","category":"blog","title":"How to get unique values for a database column in Rails","description":"rails unique db values","tags":["rails","databases"],"body":"\nThe below database call through `ActiveRecord` will return all the unique/distinct values for a single column.\n\n```ruby\nActiveRecordTable.distinct.pluck(:column)\n```\n\nThe distinct method called on an `ActiveRecord` model tells `ActiveRecord` whether the values should be unique or not. If you didn't care about unique values you could use a method like `select`.\n\nPluck is then used to query the column or columns you want the values for. An example from an application:\n\n```ruby\nUser.distinct.pluck(:email)\n```\n\n\n"},{"slug":"2021-usings-mixins-and-variables-in-scss","category":"blog","title":"Mixins and mixin variables in SCSS, a brief example","description":"mixins and variables scss","tags":["scss"],"body":"\nUsing SCSS Mixins allows you to reuse more styles in your codebase. They work like this:\n\nFirst declare the Mixin:\n\n```\n/* mixins.scss */\n\n@mixin flex-space-between {\n  display: flex;\n  justify-content: space-between;\n}\n```\n\nThen use it by including it in other style declarations. The file below adds the flex-space-between\nstyles from the Mixin to the footer.\n```\n/* footer.scss */\n\n#footer {\n  include flex-space-between;\n}\n```\n\nMixins can also be passed arguments like this:\n```\n/* mixins.scss */\n\n@mixin flex-space($spacing) {\n  display: flex;\n\n  @if $spacing == space-between {\n    justify-content: space-between;\n  }\n  @if $spacing == space-around {\n    justify-content: space-around;\n  }\n}\n```\n\nWhich is invoked like so:\n```\n/* footer.scss */\n\n#footer {\n\n  include flex-space(space-between);\n}\n```\n\nLastly, you can also pass case specific styles to a Mixin, which is often used in the wild to set different styles based on screen size like the example below. There is also the `@content` directive, which is what references the case specific styles:\n```\n/* mixins.scss */\n\n@mixin max-width($screen-size) {\n  @if $screen-size == m {\n    @media (max-width: 50em) { @content ; }\n  }\n}\n```\n\nThe case specific styles are passed through the `{}`. In this example the `@content` directive above will include the style of `font-size: 12px;` as seen below:\n```\n/* footer.scss */\n\n#footer {\n  include max-width(m) {\n    font-size: 12px;\n  };\n}\n```\n"},{"slug":"2021-when-not-to-memoize-in-ruby","category":"blog","title":"How not to memoize in Ruby","description":"memoization in ruby not to","tags":["ruby"],"body":"\nIf you are not familiar with memoization, [this](https://www.justinweiss.com/articles/4-simple-memoization-patterns-in-ruby-and-one-gem/) is a good post about the topic.\n\nFirst I will show an example of where I was using memoization correctly and why that was the case. After that I will show the example where I reworked the code and the memoization introduced a bug into my codebase.\n\n```ruby\ndef create\n  {\n    details: account.profile,\n    login_url: account.create_url_with_token\n  }\nend\n\ndef account\n  @account ||= Account.new(\n    params[\"email\"],\n    params[\"name\"]\n  ).find_or_create\nend\n```\n\nIn the above example the `create` method references account twice and account in this method should never change so it would make sense to memoize the account so the application does not need to make a second call to `find_or_create`.\n\nA problem occurred when I needed to create a handful of accounts from one request and process them. In the below example you cannot memoize the account because then the same account would be used for each of the accounts requested. But in my codebase, I had, which introduced a not so fun bug I had to fix and write a script to clean the bad data.\n\n```ruby\ndef create\n  accounts_processed = 0\n  return if !params[\"accounts_requested_count\"].to_i == accounts_processed\n  {\n    details: account(accounts_processed).profile,\n    login_url: account(accounts_processed).create_url_with_token\n  }\n  accounts_processed++\n  create\nend\n\ndef account(index)\n  Account.new(\n    params[index][\"email\"],\n    params[index][\"name\"]\n  ).find_or_create\nend\n```\n\nLesson learned the hard way, but should have known better.\n\nSimilar post(s):\n[How to memoize a conditional using Ruby](https://tinytechtuts.com/2021-memoizing-conditionals-in-ruby/)\n"},{"slug":"2021-when-to-make-a-js-library-available-through-npm-and-cdn","category":"blog","title":"When to make your JavaScript library available through a CDN and NPM package","description":"JavaScript library publishing options","tags":["javascript","npm"],"body":"\nWhen building a JavaScript library one of the things you need to think about is \"How will users consume this?\".\n\nIf the library is going to be used through a system that is bundling modules through NPM you can publish your library through the default NPM public registry and that will make it available to the entire NPM ecosystem of users.\n\nAnother option is to also publish your app through a CDN and expose the library through a JS script. This makes your library accessible to any application using JS through the browser through a `<script>` tag.\n\nThe downfalls of the CDN though are it introduces added build complexity and a third party CDN will charge for hosting so if you want to limit costs and complexity you may want to limit your libraries exposure to just NPM but if you are looking for maximum reach publishing to both a CDN and NPM would be a better idea.\n"},{"slug":"2021-when-to-use-kubernetes-service-types-configip-loadbalancer-nodeport","category":"blog","title":"When to use which service type in Kubernetes","description":"When to use which service type in Kubernetes","tags":["kubernetes"],"body":"\nWhen creating a K8's service there are 3 types to choose from:\n1) ConfigIP\n2) NodePort\n3) LoadBalancer\n\n<h3>ConfigIP</h3>\nThis is the default K8's service type. If no type is explicitly declared this is will be what K8's uses. Use this type when you do not need external communication from outside the cluster, said another way, use this type when you only need app to app traffic. This would be a commonly used service type in a microservice architecture environment.\n\n<h3>NodePort</h3>\nThis service needs to be explicitly declared in your service configuration at the key-path `spec.type`. This service type assigns a static port to each node in your K8's cluster and makes the service accessible outside of the cluster. When using this service you will also need to declare the port you want to reach the nodes in the cluster using the following key-path in your service configuration `spec.ports.nodePort`. The value of the nodePort port is limited in range to 30000-32767. When applied this service will be accessible using the IP address of the node and the defined port. This is used the least frequently in practice because it gives external clients (ex web browser) access to the nodes directly.\n\n<h3>LoadBalancer</h3>\nThis is the most frequently used service type for accepting external traffic. Using this type makes the service available externally using your cloud providers load balancer. This load balancer will need to use created to make use of this service type. This makes the external requests for secure because they are not hitting the nodes directly.\n\nFinal note:\nThese three service types is an extension of the previous types. NodePort is an extension of ConfigIP with additional functionality and LoadBalancer is an extension of NodePort.\n"},{"slug":"2021-why-private-directories-exist-on-macos","category":"blog","title":"Why private directories exist on macOS","description":"Why private directories exist on macOS","tags":["macos","operating-systems"],"body":"\nWhen software is installed on an operating system, directories and links are created that tie the softwares componments together. Sometimes those folders or files will be hidden, this is to protect those files from accidental changes or deletion of those files/directories. If you were to make a change to one of those files unknowingly, the software may not perform as expected and most people using operating systems are not developers that can troubleshoot such issues. \n\nTo see which files are hidden in a directory on macOS run the `ls` command and pass it the `-a` option:\n\n```\nls -a /path/to-directory\n```\n\nTo create a hidden file or directory you can use the `touch` command:\n\n```\ntouch .my-hidden-file\n```\n\nTo test that the file is hidden run the `ls` command in the directory without the `-a` option. If the file does not appear then run `ls -a` to ensure it is there.\n\n```\n=> touch .my-hidden-file\n=> ls\n# nothing to see here\n=> ls -a\n.my-hidden-file\n```\n"},{"slug":"2021-windowlocation-open-replace-assign-differences","category":"blog","title":"Differences between window assign, open, replace, and href= in JS","description":"Javascript differences between window.location assign, open, replace, and href=","tags":["javascript"],"body":"\nWhen using JavaScript there are a number of ways to load new documents in the browser. In this post I attempt to shed some light on differences between some/most of the options frequently reached for.\n\n<h3>window.location.assign(\"some_url\") vs window.location.href = \"some_url\"</h3>\nFunctionally there is no difference between these two methods for loading a new document ([source](https://stackoverflow.com/questions/10302905/location-href-property-vs-location-assign-method)).\n\nIt has been mentioned that using `window.location.href = \"some_url\"` may be slightly more performant because setting a property value uses fewer resources than invoking a function, eg `window.location.assign(\"some_url\")`.\n\nIn both of these cases a new document will be loaded and the browser history will be preserved so clicking the back button in the browser will take the user back the the previous page they came from. The document will be opened in the same browser window the user came from.\n\n<h3>window.location.replace(\"some_url\")</h3>\nThis function will open a new document. The document will be opened in the same browser window the user came from. The difference here is the history will be reset so clicking the back button in the browser will not take the user back to the previous page.\n\n<h3>window.open(\"some_url\")</h3>\nThis function will open the new document in a new browser window.\n\nSimilar post\n- [How to copy text from a collection of non input elements in JavaScript](https://tinytechtuts.com/2021-copy-collection-text-to-clipboard-js/)"},{"slug":"2022-$$-in-postgres","category":"blog","title":"$$ in postgres","description":"learn about $$ in postgres","tags":["postgres"],"body":"\n`$$` in postgres is a string literal. Function bodies in postgres (and sql) as plain text strings. Check out this example from a [previous post](https://tinytechtuts.com/2022-create-and-execute-stored-procedure-postgres/) on stored procedures:\n\n```\ncreate or replace procedure report_status_update(\n  new_status varchar(20),\n  report_id int\n)\nlanguage plpgsql   \nas $$\nbegin\n   update reports\n   set status = new_status\n   where id = report_id\n   commit;\nend;$$;\n```\n\nYou will notice we capture the actual function body (starts with the `begin` keyword) in `$$` and after we have finished defining the function body (ends with `end` keyword) then we close the string literal with another `$$`.\n"},{"slug":"2022-abstract-class-ruby","category":"blog","title":"Abstract class vs regular class in ruby","description":"learn about abstract classes","tags":["ruby"],"body":"\nIn Ruby programming we use classes to represent real world objects and encapsulate behavior relevant to each object, respectively. We then create instances of those classes and call methods on them to make our programs run:\n\n```ruby\nclass Dog\n def bark\n   \"woof\"\n end\nend\n \nputs Dog.new.bark\n\n```\n\nClasses can also inherit from other classes, creating an inheritance chain. When we inherit from a class we get access to all of the behavior that exists on the class we inherit from, as well as any classes that that class inherits from:\n\n```\nclass Animal\n def eats?\n  true\n end\nend\n \nclass Dog < Animal\n def bark\n   \"woof\"\n end\nend\n \nputs Dog.new.eats?\nputs Animal.new.eats?\n\n```\n\nNotice in the above example that we are able to create instances of both `Animal` and `Dog` and call the method Animal.\n\nNow the difference between these types of classes and an abstract class is that an abstract class can only be inherited from, you never create instances of the inheriting class directly. A good example of this in the ruby ecosystem is the Rails framework's ActiveRecord library. You will notice you never see `ActiveRecord::Base.new` called in a project, it is always only inherited from, thus making it “abstract”.\n\nIf you need more ruby posts to keep you happy then I'm happy to oblige, check out [this one](http://localhost:4000/2022-convert-nested-array-to-hash)."},{"slug":"2022-access-property-off-object-vscode","category":"blog","title":"Access property off object through destructuring","description":"javascript destructuring and object access","tags":["javascript"],"body":"\nPattern matching is a super useful way to cleanup our code. Instead of heaving to access keys directly off of objects in callback functions, we can use destructuring to get access to the key as its own variable from within a closure.\n\n```\nevent.locations.filter(({localtionId}) => console.log(locationId)\n```\n\nIn the above, instead of having to write `location.locationId` everywhere in the callback function, we are able to access the `locationId` directly.\n\n"},{"slug":"2022-add-element-to-tuple-at-an-index","category":"blog","title":"Add element to tuple at an index postion","description":"How to add element to tuple at an index postion","tags":["elixir"],"body":"\nFor example's sake, let's say you were working with an Elixir tuple that has four elements:\n```\nfour_elem_tuple = {\"one\", \"two\", \"three\", \"four\"}\n```\n\nIn this made up scenario you want to add an element after in the second position of the tuple, or index position 1. You can do that using the `Tuple` modules `insert_at/3` function. \n```\nfour_elem_tuple = {\"one\", \"two\", \"three\", \"four\"}\nTuple.insert_at(four_elem_tuple, 1, \"one.five\")\n=> {\"one\", \"one.five\", \"two\", \"three\", \"four\"}\n```\n\nIf you just want to add an element to the tuple as the last element in the collection, you can use the `Tuple.append/2` function.\n\n```\nfour_elem_tuple = {\"one\", \"two\", \"three\", \"four\"}\nTuple.append(four_elem_tuple, \"five\")\n\n=> {\"one\", \"two\", \"three\", \"four\", \"five\"}\n```\n\nIn [another post](https://tinytechtuts.com/2022-remove-element-from-tuple-at-an-index/) I review how to delete an element from a tuple at a given index position.\n"},{"slug":"2022-add-nofollow-to-page-in-phoenix-application","category":"blog","title":"Add nofollow to pages in a Phoenix application","description":"How to add nofollow to pages in a Phoenix application","tags":["phoenix","seo"],"body":"\nIn a [previous post](https://tinytechtuts.com/2020-seo-in-elixir/) I outlined how you can add meta tags to a template in a phoenix application to help with SEO. In this post I will review the functionality that's needed to accomplish setting `<meta>` tags in the `<head>` of your html document. The tags will be used to tell Google and most other search engines that this page should not be included in their index.\n\n`<meta>` tags are usually used to communicate with an outside service regarding something you'd like them to know, in the SEO example you want a search engine to understand more information about the content of the page. For this example we want search engines to know that we don't want this page to be included in their index.\n\nTo add meta tags to templates in your html documents first we will create functions in your Phoenix LayoutView that can be invoked by any other template in your application. By adding the functions here we can optionally choose to call them within any other template we create, so we don't have to have the tags on every page, just the ones that need it.\n\nThat code looks like:\n```elixir\ndefmodule DevDecksWeb.LayoutView do\n  use DevDecksWeb, :view\n\n  def meta_tags(attrs_list) do\n    Enum.map(attrs_list, &meta_tag/1)\n  end\n\n  def meta_tag(attrs) do\n    tag(:meta, Enum.into(attrs, []))\n  end\nend\n```\n\nIn the root layout file (root.html.leex) call the `meta_tags` function if `meta_tags` are provided to `assigns`. Call `assigns[:meta_attrs]` directly here instead of `@meta_attrs` so that if `@meta_attrs` is not provided the application does not error and stop execution.\n```elixir\n<%= if assigns[:meta_attrs], do: meta_tags(assigns[:meta_attrs]) %>\n```\n\nIf you're using a LiveView template add the `meta_tags` to `assigns` in mount like the below:\n```elixir\ndef mount(_params, _session, socket) do\n    meta_attrs = [\n      %{name: \"robots\", content: \"noindex\"},\n      %{name: \"googlebot\", content: \"noindex\"}\n    ]\n\n  {:ok, assign(socket, meta_attrs: meta_attrs)}\nend\n```\n\nIf you're using an MVC approach you can add the `meta_attrs` to your controller that is generating the template:\n```elixir\ndef index(conn, _params) do\n  meta_attrs = [\n    %{name: \"robots\", content: \"noindex\"},\n    %{name: \"googlebot\", content: \"noindex\"}\n  ]\n\n  render(conn, \"index.html\", meta_attrs: meta_attrs)\nend\n```\n\nThe meta tags shown in this example are directions from [Google's documentation](https://developers.google.com/search/docs/advanced/crawling/block-indexing). It should be noted that these tags should prevent *most* web crawlers from indexing your page, but it's possible that other crawlers handle indexing differently.\n\nFurther reading:\n- [How to paginate an in memory array](https://tinytechtuts.com/2022-in-memory-pagination-by-example/)\n"},{"slug":"2022-adding-a-guard-to-a-block","category":"blog","title":"How to add a guard to a block in Ruby","description":"Learn how to add a guard to a block in Ruby","tags":["ruby"],"body":"\n\"I don't want specific items in this array to be processed by this ruby block\" is [another](https://tinytechtuts.com/2022-breaking-out-of-a-block/) scenario often faced when programming in Ruby. Like the post on [extiting from a block](https://tinytechtuts.com/2022-breaking-out-of-a-block/), I think a lot of people try to `return` from the block as a first attempt, but that doesn't return from the block, it returns from the entire method, which in this case isn't the desired behavior. So when you need to exit the current iteration of a block you can use the `next` keyword. \n\n```ruby\n[1,2,3,4].each{|int| next if int == 3}\n``` \n"},{"slug":"2022-adding-and-accessing-env-vars-phoenix","category":"blog","title":"How to add and access env variables in Phoenix","description":"learn a simple env variable solution for phoenix","tags":["elixir","phoenix"],"body":"\nAdding environment variables for a Phoenix web app is fairly straightforward but if googling it can take some time to find a simple answer. In this tutorial I will show you how to set up your environment variables using a `.env` file.\n\n1. In the root of your Phoenix directory create a new `.env` file.\n2. Add that file to your `.gitignore` so you don't expose secrets to the outside world. If you accidentally forget to add this to your .gitignore and make a commit, anyone who gains to that commit will be able to view your secrets to that point.\n3. Add and export your env variables in the .env file:\n```\nexport STRIPE_API_KEY=\"some test_key\"\n```\n4. On your terminal execute `source .env` from the root directory of your project.\n\n\nFollowing the execution of that last step you will be able to access environment variables throughout your project through: \n```\nSystem.get_env(\"STRIPE_API_KEY\")\n```\n\nIn my case I made reference to this config value in `config.exs`:\n```\nconfig :stripity_stripe, api_key: System.get_env(\"STRIPE_API_KEY\")\n```\n"},{"slug":"2022-alias-module-explained","category":"blog","title":"Elixir: alias __MODULE__ explained","description":"What does alias __MODULE__ do in elixir","tags":["elixir"],"body":"\nWhen you come across the code below in Elixir it is fairly reasonable to assume you are aliasing the module in which it is used. But what does it allow you to do?\n\n```\ndefmodule Engine.Middelware do \n\talias __MODULE__\nend \n```\n\nAfter using `alias __MODULE__` like code above does, we can more simply create or reference the struct for `Engine.Middelware` throught this modules code. Since we’ve aliased the `Middleware` module, we can now refer to Middleware structs as `%Middleware{}` instead of `%Engine.Middelware{}`. "},{"slug":"2022-before-save-vs-before-update-or-create-in-rails","category":"blog","title":"Difference between before_save and before_update and before_create in Rails","description":"before_save vs before_update vs before_create in Ruby on Rails","tags":["rails","active-record"],"body":"\nWhen defining ActiveRecord callbacks I've sometimes needed to ask myself \"should I use `before_save` here or `before_create`\" and when coming to the answer for this question there are also implications for when to use `before_update`. \n\nUltimately if you only need the callback to be invoked when the record is first created, use `before_create`. If you need the callback to be invoked every time the record is updated you can use the `before_update` callback. And if you need the ballback invoked when the object is both created and updated you would use the `before_save` callback method.\n\nAs with all ActiveRecord public instance methods you will also have access to the object within the invoked callback method, it can be referenced explicitly through `self`. Or you can just call its attribute methods directly because `self` is the default object.\n\n```ruby\nclass Account < ApplicationRecord\n  before_save :clean_record\n\n  def clean_record\n    p \"#{self.inspect}\"\n    p \"#{name}\"\n  end\nend\n\nAccout.create(name: \"blue bacon\", email: \"blue@bacon.istasty\")\n# Puts output from clean_record invocation:\n# \"#<Account id: nil, name: \\\"blue bacon\\\", email: \\\"blue@bacon.istasty\\\", admin: nil, created_at: nil, updated_at: nil>\"\n# \"blue bacon\"\n```\n\nIf you enjoyed this post, you might also enjoy [Ruby on Rails integration testing cheatsheet](https://tinytechtuts.com/2022-rails-integration-testing-cheatsheet/)\n"},{"slug":"2022-breaking-out-of-a-block","category":"blog","title":"How to break out of a block in Ruby","description":"How to break out of a block in Ruby","tags":["ruby"],"body":"\nWhen first learning to program in Ruby it can be difficult to find an answer to the question; \"I need to stop iterating this collection once I find the desired element\". I think a lot of people try to `return` from the block as a first attempt, but that doesn't return from the block, it returns from the entire method, which in this case isn't the desired behavior. \n\nSo when you need to exit a block early you can use `break` to handle this, it will exit the block and return control back the method the block was running in.\n\nThis is different from if you want to just skip the current iteration of the block, in that event you would want to use the [next](https://tinytechtuts.com/2022-adding-a-guard-to-a-block/) keyword.\n\n```ruby\n[1,2,3,4].each{|int| break if int == 3}\n``` \n\nOr if you want to assign a value before breaking:\n```ruby\n[1,2,3,4].each do |int| \n  if int == 3\n    @desired_number = int\n    break\n  end\nend\n```\n"},{"slug":"2022-can-you-call-map-filter-reduce-on-an-html-collection-object","category":"blog","title":"Can you call map/filter/reduce on an HTMLCollection?","description":"How do you iterate an HTMLCollection","tags":["javascript","html"],"body":"\nTo iterate over a HTMLCollection object you will first need to transform the object into an Array.\n\nYou can accomplish this by passing the collection to the `Array.from` function.\n\n```\nparent = document.querySelectorAll(\".blog\")[0]\ncollection = Array.from(parent.children)\n```\n\nNow you have a collection that works with standard Array prototype functions.\n\n```javascript\nparent = document.querySelectorAll(\".blog\")[0]\ncollection = Array.from(parent.children)\n\n// these will all work now\ncollection.filter()\ncollection.find()\ncollection.reduce()\ncollection.map()\n```\n\nFor more filtering joy, I wrote a post on retrieving and filtering previously executed [mac commands](https://tinytechtuts.com/2021-how-to-get-and-filter-previously-executed-commands-macos/)."},{"slug":"2022-check-if-a-module-exists-in-class","category":"blog","title":"Check if a module has been included in a class in ruby","description":"check if module included in class ruby","tags":["ruby"],"body":"\nWhen programming in ruby you may have to reach for a module that has encapsulated some helper functions that you want to use in your class. To tell if the module has been included in your class you can use the `Module` classes `include` method. Likewise, to tell if you choose to extend the module you can check that through the `extend` method.\n\nBelow is a working example. Notice we do not need to instantiate our classes to invoke these methods:\n\n```\nmodule SomeModule\n  def self.included(base)\n    p base.inspect\n  end\n\n  def self.extended(base)\n    p base.inspect\n  end\nend\n\nclass IncludedClass\n  include SomeModule\nend\n\nclass ExtendedClass\n  extend SomeModule\nend\n```\n\nRunning this script will print:\n```\n\"IncludedClass\"\n\"ExtendedClass\"\n```\n\nTo fill your hearts desire for more ruby programming blog posts check out [this one](https://tinytechtuts.com/2022-breaking-out-of-a-block/)."},{"slug":"2022-check-list-contains-value-in-elixir","category":"blog","title":"Check if an Elixir List has specific value","description":"example of how to check an elixir list for a value","tags":["elixir"],"body":"\nTo check if an elixir `List` contains a specific value we utilize the `Enum` module which defines a function `member/2`. The two arguments this function accepts as parameters are the enum itself, in this case a `List` and the value you want to check for. The function will return a boolean. Below is an example usage:\n\n```\niex(3)> list = [\"cat\", \"dog\", \"turtle\"]\n[\"cat\", \"dog\", \"turtle\"]\niex(4)> Enum.member?(list, \"cat\")\ntrue\n```\n\n"},{"slug":"2022-checklist-for-creating-uniform-urls","category":"blog","title":"Checklist for creating uniform URL scheme","description":"Uniform URL scheme checklist","tags":["web urls"],"body":"\nThis post is a list of considerations and todo's for creating uniform URLs in your application, it does not cover implementation:\n\n1. Check the URL matches your custom scheme\n2. Ensure they use the HTTP protocol\n3. Check for leading whitespace\n4. Check for trailing whitespace\n5. Check for trailing slashes\n"},{"slug":"2022-class-eval-with-file-and-line","category":"blog","title":"class_eval with execution lines","description":"learn how to get the execution line when using class_eval","tags":["ruby"],"body":"\nIf you find yourself using Ruby's `class_eval` method to define some functions within a multi-line string, you may have difficult troubleshooting should an error occur in one of the functions you define.\n\n```ruby\nclass SomeObject\n  %w(method_name_1 method_name_2).each do |method|\n    class_eval <<-RUBY\n      def #{method}\n        raise\n      end\n    RUBY\n  end\nend\n```\n\nIn the code above I define two methods (`method_name_1`, `method_name_2`) on the `SomeObject` class using `class_eval`. Each method will raise an error. Now when that error is raised, it will be hard to debug because there will be no coherent backtrace, since we are metaprogramming in this way ruby doesn't know where the error occurred.\n\nIn order to get details of where the error occurred when using `class_eval` in this manor, you will need to pass two arguments to the ruby multiline string, `__FILE__` and `__LINE__ + 1`. Now when you that error is raised you will have an accurate account of where it occurred within your program.\n\n```ruby\nclass SomeObject\n  %w(method_name_1 method_name_2).each do |method|\n    class_eval <<-RUBY, __FILE__, __LINE__ + 1\n      def #{method}\n        raise\n      end\n    RUBY\n  end\nend\n```\n\nRuby dooby doo, says Scooby at a ruby conference. If you want to make Scoob happy, check out this post [Convert nested array to hash in Ruby](https://tinytechtuts.com/2022-convert-nested-array-to-hash/).\n\n"},{"slug":"2022-configure-git-and-remote","category":"blog","title":"Steps to configure Git and remote origin","description":"Learn how to configure Git and remote origin","tags":["git"],"body":"\nThese were the steps I took to setup Git on my new computer to work with Github through SSH.\n\nFirst, set your global git config on your machine. I am using a Mac so Git came preinstalled. You'll want to configure your username and email associated with your account using the commands below.\n```\ngit config --global user.name \"coldsoup23\"\ngit config --global user.email \"coldsoup23@gmail.com\"\n```\n\nThen to push your commits using SSH you will need to create a new public / private key pair:\n```\nssh-keygen -t rsa\n```\n\nOn a Mac this will create a file at `/Users/username/.ssh/id_rsa` and also `/Users/username/.ssh/id_rsa.pub`.\n\nYou will need to add the contents of the pubic key to your Github profile, you can print the contents to your terminal using the command:\n```\ncat /Users/username/.ssh/id_rsa.pub\n```\n\nLastly, you will need to paste that into your Github profile:\n1. Click on your profile\n2. Click SSH keys at settings\n3. Click SSH and GPG keys\n4. Add a new key and paste the contents of id_rsa.pub\n\nAfter that last step you will be configured to use Git on your local machine and push commits to a remote origin, in this case, Github.\n\nIf you found this post juicy, wait until you check out [How to run two different git branches locally](https://tinytechtuts.com/2022-running-two-git-branches-locally/)\n"},{"slug":"2022-convert-nested-array-to-hash","category":"blog","title":"Convert nested array to hash in Ruby","description":"Learn how to convert nested array to hash in Ruby","tags":["ruby"],"body":"\nLet's say you have a complex data structure containing nested arrays like this:\n\n```ruby\narr = [\n  [:id, 233],\n  [:name, \"ruby tuesday\"],\n  [:email, \"ruby@tuesday.com\"]\n]\n```\n\nAnd you want to convert it to a hash where the keys of the hash are the first element of each subarray and the keys value is the second item in the subarray. you can accomplish using the `Hash` classes class method `[]`, like so:\n\n```ruby\nHash[arr]\n=> {:id=>233, :name=>\"ruby tuesday\", :email=>\"ruby@tuesday.com\"}\n```\n\nLooking for more red jewel programming insights? Why not head over to [Ruby [0..-2] explained](https://tinytechtuts.com/2022-ruby-0..-2-explained/)"},{"slug":"2022-count-of-each-item-in-elilxir-list","category":"blog","title":"Elixir List count of each unique element","description":"Get a count of elements occurance in Elixir List","tags":["elixir"],"body":"\nThere may come a time where you need to get a count of how many times a specific element occurs in a List. It might be needed for reporting, or to show to a user in an admin dashboard.\n\nTo accomplish this in Elixir you can use the `Enum.frequencies/1` function. This function will take one argument, the enumerator, and return map with each unique element and it's occurence count.\n\n```elixir\nEnum.frequencies([\"football\", \"baseball\", \"baseball\", \"hockey\", \"baseball\"])\n=> %{\"baseball\" => 3, \"football\" => 1, \"hockey\" => 1}\n```\n\nFurther reading:\n- [Rendering a LiveView template outside of router](https://tinytechtuts.com/2022-rendering-liveview-template-outside-of-router/)"},{"slug":"2022-create-and-execute-db-view-postgres","category":"blog","title":"Postgres: create and execute database view","description":"learn about views and how to execute them in postgres","tags":["ruby"],"body":"\nThere is a lot that happens behind the scenes in modern SQL databases. I say this because so many of our interactions with databases happen through libraries and ORM’s in the web frameworks we use. The danger there is it can be easy to not learn as much about database’s as developers of the past have had to, so when a cryptic issue arises, it can take much longer to bring to a resolution. The title topic, postgres views, can be one of those easily areas. \n\nThere are a few different types of views (read-only, materialized, updatable), but here we will focus on read only views. Two of the use cases for using view:\nHide the complexity of a complex query. If you create a view that encapsulates a complex query, it can be well named for simpler understanding as to the queries purpose and also reused to make even more complex queries more readable:\n\n```\nCREATE VIEW all_decks AS complex_multi_level_join_query;\n\nSELECT * FROM all_decks INNER_JOIN other_query;\n```\n\nLimit exposure to tables for non administrators. In this case you would create a view containing only columns / tables you want to expose and give those users access only to that view.\n\nCreating and executing a view:\nThis was covered above, but for explicitness you can create a view through the `CREATE VIEW` SQL keywords. Example:\n```\nCREATE VIEW all_decks AS SELECT * FROM decks;\n```\nAnd then to use that view:\n```\nselect * from all_decks;\n```\n\nI think it’s worth noting if you create a view using the asterisk wildcard, only the columns existing at the time of view creation will be captured within that view. Said differently, if you add columns to the table the view was created for, the new columns will not be accessible in that view.\n\nIf you enjoyed that post on views, you might also enjoy a trip to the Great Smoky Mountains, or [this post](https://tinytechtuts.com/2022-pg_ctl-vs-psql/) on `psql` vs `pg_ctl`.\n"},{"slug":"2022-create-and-execute-stored-procedure-postgres","category":"blog","title":"Postgres: create and execute stored procedure","description":"learn about stored procedures how to execute them in postgres","tags":["postgres"],"body":"\nSimilar to the previous post on [database views](https://tinytechtuts.com/2022-create-and-execute-db-view-postgres/), stored procedures are something we don’t use quite as frequently in modern software development. They are essentially functions you can execute against a database and like functions they accept parameters to make them dynamic.  \n\nStored procedures are not used frequently in modern web development for a variety of reasons but a some of the bigger ones are: \nThey are slow to write\nNon trivial to change\nUncommon knowledge in today's dev environment, making maintenance more challenging.\n\nThey can be useful though if you and your team are open to using SQL for handling some business logic.\n\nTo illustrate this through example, let’s create a stored procedure called `update_status` that updates the status of a report:\n\nFirst you need to define the procedure and declare any arguments that may be needed, as well as the language, then finally the actual procedure to take place. Also note if you’re not used to reading SQL the $$ is a string literal.\n```\ncreate or replace procedure report_status_update(\n   new_status varchar(20),\n   report_id int\n)\nlanguage plpgsql    \nas $$\nbegin\n    update reports \n    set status = new_status\n    where id = report_id\n    commit;\nend;$$;\n```\n\nYou can execute this stored procedure using:\n```\ncall report_status_update(‘COMPLETE’, 2)\n```\n"},{"slug":"2022-create-new-map-using-keys-of-existing-map","category":"blog","title":"Create new map using keys of existing map","description":"Create new map using keys of existing map","tags":["elixir"],"body":"\nLet's start the party by defining an Elixir Map that we will use to pull keys from to create our new map:\n```\npinteresting = %{\n  pumpkin: true,\n  snowfall: false,\n  apple: true,\n  pine_tree: false\n}\n```\n\nNow to complete the objective of this titled blog post we will reach from the `Map` module and the `split/2` function on that module. This function accepts a map as its first argument and a list of keys as a second argument. The function will use the keys defined in the second argument to create the new map containing only those keys and it will also return another map containing the remaining keys. Example below:\n```\n=> {truly_pinteresting, not_very_pinteresting} = Map.split(pinteresting, [:pumpkin, :apple])\n{%{apple: true, pumpkin: true}, %{pine_tree: false, snowfall: false}}\n```\n\nIn the above you can see that we are returned a two item tuple, containing the previously mentioned maps. The first with all the keys we passed as the second argument to `split/2`. The second is a map containing the remaining keys.\n\nAnd because Elixir is immutable we still have access to the original object, unchanged:\n```\n=> pinteresting\n%{\n  pumpkin: true,\n  snowfall: false,\n  apple: true,\n  pine_tree: false\n}\n```\n\nNow if you need to remove multiple k/v pairs there is a `drop` function on the `Map` module that can be utilized. I review that [here](https://tinytechtuts.com/2022-remove-single-key-value-pair-from-map/).\n\n"},{"slug":"2022-creating-an-elixir-project-without-phoenix","category":"blog","title":"How to create a mix/Elixir project without Phoenix","description":"creating a mix project","tags":["elixir"],"body":"\nIn Elixir use mix to create projects, Phoenix is just an Elixir library. You can use `mix new project_name` to generate a project and just not include Phoenix as a dependency. To run `mix new` you need to have both mix and elixir installed and in your PATH.\n\n<image src=\"/images/blog/mix-project-generation.png\" alt=\"mix-project-gen\" />"},{"slug":"2022-database-server-vs-database","category":"blog","title":"Database server vs database","description":"Walk through the difference between a database server and a database","tags":["postgres"],"body":"\nAs a software engineer you'll often hear about and interact with databases, but then you will inevitably hear of a database server and it's easy to think that these two concepts are on in the same. That is not the case. In this post I will walk through a brief overview of what differentiates these two terms.\n\n<h2>Database Server</h2>\nA database server is the computer/server under which databases will exist. It is what knows how to create databases and manage their data. You can install multiple database servers on a single physical machine.\n\n<h2>Database</h2>\nWithin a database server can exist many databases. These are the objects that contain your database tables, among other objects like database functions, indexes, and views.\n\nThe main takeaway here is that a database exists within the context of a database server and a database server exists as an application on physical or virtual hardware.\n\nEver seen a coyote share a meal with a barred owl? That would be a sight. While we wait for that day to come, you may enjoy a post on [Postgres backslash commands](http://www.devdecks.io/2022-postgres-backslash-commands)."},{"slug":"2022-dns-system-request-flow-explained","category":"blog","title":"DNS system request flow explained","description":"Explain how a DNS system handles requests","tags":["dns"],"body":"\nA DNS system takes a *fully qualified domain name and translates it into your web server's IP address. There are a few steps a DNS system takes to handle this translation. This translation is also referred to as resolving a domain name.\n\nThe DNS resolution will occur before your actual web server is accessed because your web server can only be accessed using its IP address.\n\nTo resolve a DNS request:\n\n1) A browser or other HTTP client sends a request to www.devdecks.io.\n2) Your browser will first reach out to a DNS server known as a resolver. This is the server that is responsible for making all of the requests needed to handle the domain name translation and will ultimately send your resolved IP address back to your client. It is typically run by your local internet service provider (ISP).\n3) The Resolver first talks to a **Root Name Server** (behind the scenes this is a grouping of name server's, but it will only reach out to one). This server is responsible for interpreting the top level domain, eg .com, .io, .org, etc. Once it has deciphered the top level domain, it will return a pointer to the resolver. That pointer is the address of the appropriate top level domain name server, each top level domain will have a set of servers responsible for the next step in the request chain.\n4) Using that pointer the resolver then reaches out to the **Name Server** for .io domains. This will check the requests domain (devdecks) and respond to the resolver with a pointer to the **DNS Provider Server**. The name server knows where to look for this because when you registered your domain name, your dns provider made an entry into the .io name server with a pointer back to their system.\n5) Using this pointer the resolver reaches out to the DNS server for devdecks, which responds with the IP address. It knows about this domain entry because when you registered the domain name you created a hosted zone in the registrars system. The hosted zone contains the details of your domain name, including your IP address.\n6) The resolver returns the IP address to the http client.\n\nThis IP address is then used by your browser client to issue the request to your web server.\n\nTL/DR:\n1) HTTP request made to www.devdecks.io.\n2) This request first hits a resolver.\n3) The resolver reaches out to the root name server for the IP of the name server.\n4) The resolver reaches out the name server for the DNS server IP.\n5) The resolver reaches out the the DNS server for the IP of your web server.\n6) HTTP client makes a request to the IP for www.devdecks.io.\n\n*Fully qualified domain name: the complete domain name a web server can be reached at. For example www(subdomain).devdecks(domain).com(root domain). This does not include the http(s) protocol.\n\nContinued reading:\n- [How subdomains work with dns](https://tinytechtuts.com/2022-how-do-subdomains-work-with-dns/)\n"},{"slug":"2022-dynamically-add-methods-with-def-method","category":"blog","title":"Dynamically add methods in ruby with define_method","description":"Dynamically add methods in ruby with define_method","tags":["ruby","metaprogramming"],"body":"\nIn a recent post I went over adding methods dynamically with [method_missing](https://tinytechtuts.com/2022-dynamically-add-methods-with-method-missing/). I also issued a word of caution when overriding `method_missing` in that manor.\n\nIt turns out there is a better way to handle an event where you need to define methods at runtime in ruby, through the use of `define_method`. The benefit to using `define_method` in this case is it will have any unintended side effects like `method_missing` does with impacting [respond_to?](https://tinytechtuts.com/2022-dynamically-add-methods-with-method-missing/).\n\nIn the code below I use `define_method` to add attribute methods to the `Account` class. When this file is first read by the ruby interpreter it will iterate the `@@attributes` array and create the setter methods. Then we can use them later on in our code, like where the example below illustrates when we set a value for email.\n\n```\nclass Account\n  @@attributes = [:email, :first_name, :last_name]\n\n  @@attributes.each do |name|\n    define_method(:\"#{name}=\") do |value|\n      @attributes[name] = value\n    end\n  end\n\n  def initialize\n    @attributes = {}\n  end\nend\n\nAccount.new.email = \"wizbang@buck.com\"\n```\n\nIf it's not clear, what makes this dynamic is our code is defining the attribute methods for us inside of `define_method` as it runs rather than us declaring them within our code.\n\nI've seen this used in production where a remote API contains data you want to attach to a class in a different ruby/rails app. The data is fetched from the API and `define_method` is used to attach that data to the model.\n\n"},{"slug":"2022-dynamically-add-methods-with-method-missing","category":"blog","title":"Dynamically add methods in ruby with method_missing","description":"Dynamically add methods in ruby with method_missing","tags":["ruby","metaprogramming"],"body":"\n*Note if you need to define methods dynamicallly I found a better way to do so with the [define_method](https://tinytechtuts.com/2022-dynamically-add-methods-with-def-method/), but if you're interested in learning about overriding `method_missing` or another way of dynamically adding methods in ruby, please read on.\n\nWhen you call a method that doesn’t exist in ruby, internally ruby will call it’s own `method_missing` method, which will raise the undefined method error:\n\n```\nhello_world\n=> `<main>': undefined local variable or method `hello_world' for main:Object (NameError)\n```\n\nBut if needed you can override the default `method_missing` implementation with behavior to suite your applications needs.\n\nFor example you could use `method_missing` to catch unknown methods and define them dynamically. In the implementation below `ActiveRecordImplementation` initializes an empty hash of attributes which `method_missing` will reference and add to if the attribute does not currently exist on the object.\n\n```\nclass ActiveRecordImplementation\n  attr_reader :attributes\n\n  def initialize\n    @attributes = {}\n  end\n\n  def method_missing(name, *args, &block)\n    if name.end_with?(\"=\")\n      @attributes[name.to_s[0..-2].to_sym] = args.first\n    else\n      @attributes[name]\n    end\n  end\nend\n\nActiveRecordImplementation.name = \"Jimmy Bones\"\n```\n\nIf it's not clear, what makes this dynamic is our code is defining the attribute methods for us inside of `method_missing` as it runs rather than us declaring them within our code.\n\nA note of caution in using this, if you’re not careful overriding method_missing can cause other issues with ruby behavior, a noted example is with `respond_to?`. It may be helpful to include a default conditional that just calls the ruby implementation by calling `super` in this case.\n\nFurther reading:\n- [Handling system authentication in software engineering](https://tinytechtuts.com/2022-system-auth-in-software-engineering/)"},{"slug":"2022-ecto-convert-query-to-sql","category":"blog","title":"Ecto: convert query to sql","description":"how to convert an ecto query to sql","tags":["elixir","ecto"],"body":"\nThere may come a time in your Ecto life where you want to know what the actual SQL statement is that the Repo module is generating for you. When that special time comes, you have a wonderful function you can leverage that exists on the `Ecto.Adapters.SQL` module, `to_sql/3`. To use this function you need to pass the Repo function (expressed as an atom) and the `Ecto.Query` as arguments. Example:\n\n```\nquery = from s in \"stores\", select: s.name\nEcto.Adapters.SQL.to_sql(:all, query)\n```\n\nIn a [previous post](http://localhost:4000/2022-ecto-direct-sql-query){:taget=\"_blank\"} I detailed how if you're using one of these Ecto database adapters:\n1. Postgres\n2. MySQL\n3. SQLServer\n\nThen you don't need to use the `Ecto.Adapters.SQL` module because the `.to_sql` function will be imported into your Repo module.\n\nIf you found this post helpful you might also like [Ecto: example inner join query](https://tinytechtuts.com/2022-example-ecto-inner-join-query/).\n"},{"slug":"2022-ecto-delete-associated-records","category":"blog","title":"Ecto: delete associated records","description":"how to delete associated records in ecto","tags":["elixir","database"],"body":"\nIf you have a one to many or many to many association in your Ecto schema and you need to handle deleting all associated records when the primary record is deleted `Ecto.Schema` includes a keyword option you can pass to your association `on_delete: :delete_all` that you can utilize. This will make sure that all child records are deleted before the operation is complete:\n\n```\nhas_many :items, on_delete: :delete_all\n```\n\nInterest in more Ecto options? I wrote on post on [setting primary keys](https://tinytechtuts.com/2022-set-a-primary-key-ecto/)."},{"slug":"2022-ecto-direct-sql-query","category":"blog","title":"Ecto: using SQL for a query","description":"using sql with ecto","tags":["elixir","ecto"],"body":"\nThe Ecto library has a large number functions we can leverage to query the database without writing SQL. These are mostly found on the `Ecto.Repo` module, for example `Repo.get/3`, `Repo.all/2`, `Repo.aggregrate/3`, etc.\n\nBut what if you need to write a more complicated SELECT or INSERT? For this circumstance you can leverage the `Repo.query/3` as long as your application is using the Postgres, MySQL, or SQLServer database adapter. The `query` function along with [additional sql functions](https://hexdocs.pm/ecto_sql/Ecto.Adapters.SQL.html) are injected into the `Repo` module if you are using one of those adapters. A screenshot of available functions:\n\n<image src=\"/images/ecto-sql-query-adapter-functions.png\" alt=\"ecto: query adapter functions\" />\n\nIf you're not using one of the previously mentioned database adapters you can still get access to these helper functions by importing the `Ecto.Adapters.SQL` module into your project.\n\nAn example use of `Repo.query`:\n```\nRepo.query(\"select id, name from stores where id >= 10\") \n```\n\nIf you found this post helpful you might also like [Ecto: example inner join query](https://tinytechtuts.com/2022-example-ecto-inner-join-query/).\n"},{"slug":"2022-ecto-insert_all-returning-nil","category":"blog","title":"Ecto: insert_all returning nil","description":"return vals from insert_all","tags":["elixir","ecto"],"body":"\nBy default `Repo.insert_all` will return a tuple of the count of objects that were inserted and nil. If you want to return values for the inserted data, you need to explicitly do so by specifying a “returns” option. That looks like this in practice:\n\n```\nRepo.insert_all(\"store\", [%{name: \"Foot Locker\"}, %{name: \"Subway\"}], returning: [:uuid, :name])\n#=> {2, [%{uuid: “dsf45-fdf-1234”, name: \"Foot Locker\"}, %{uuid: “gggf45-ff-11233”, name: \"Subway\"}]}\n````\n"},{"slug":"2022-ecto-return-count-of-records","category":"blog","title":"Ecto: return a count of records","description":"ecto records count","tags":["elixir","ecto"],"body":"\nTo handle aggregates in Ecto there is a utility function we can leverage on `Repo` called `aggregate/3`. This function takes three arguments but the third is optional:\n1. The database table name\n2. The desired aggregate operation (in this case count)\n3. A field to count\n\nBelow is an example of executing the function:\n```\nRepo.aggregate(“stores”, :count, :uuid)\n=> 4\n```\n"},{"slug":"2022-elixir-enum-fetch-vs-find","category":"blog","title":"Elixir Enum fetch vs find functions","description":"Differences between elixirs fetch and find","tags":["elixir"],"body":"\nIn Elixir the `Enum` modules `fetch/2` and `find/3` methods sound a little similar at first thought, this post will share what makes them similiar, different, and provide examples.\n\n`fetch/2` and `find/3` are similarity in that their job is to locate a specific element inside of an enumerable object. However these functions handle this task quite differently. `fetch/2` will take in an enumerable and an index value as parameters and return a tuple with the matched element at the index value parameter provided. `find` on the other hand will accept three arguments, an enumberable, an optional default value, and a callback function and return the first matched element found in the callback function.\n\n```elixir\nEnum.find([2, 3, 4], fn int -> int == 2 end)\n=> 2\n```\n\n```elixir\nEnum.fetch([2, 3, 4], 0)\n=> {:ok, 2}\n```\n\nI have also written another `Enum` post on [iterating a List with_index in elixir](https://tinytechtuts.com/2022-list-with-index-in-elixir-example/) if you're interested."},{"slug":"2022-elixir-ternary-operator","category":"blog","title":"Elixir ternary operator","description":"elixir-ternary-operator-equivalent","tags":["elixir"],"body":"\nIf you’re coming into elixir from a language like Javascript or Ruby you are familiar with ternary expressions and how to use them to simplify conditionals. In practice they look something like this:\n\n```\nconst val = condition ? truthy_handler : falsy_handler\n```\n\nIn elixir it is handled differently, the most common and frequently used way being:\n\n```\nif(condition, do: truthy_handler, else: falsy_handler)\n```\n\nIf you like conditions, you might also enjoy the post [Get the index position from element in a matched condition](https://tinytechtuts.com/2022-get-index-of-a-matched-conditions-element/).\n"},{"slug":"2022-ensure-all-tests-pass-before-commit-elixir","category":"blog","title":"Elixir: ensure all tests pass before commit","description":"using pre-commit in eliixr","tags":["elixir"],"body":"\nIf you want to run automated tests or a formatter before making a git commit in your project there is a helpful Elixir library called `elixir-pre-commit`. This library is a hook that will run before a commit is finalized. The module works by overwriting your pre-commit file in your `.git/hooks` directory.\n\nTo use the library add it to your deps in `mix.exs` and update your dependencies with `mix deps.get`.\n\n```\ndef deps do\n  [{:pre_commit, \"~> 0.3.4\", only: :dev}]\nend\n```\n\nAnd then you will need to add the config to your development config. In Phoenix applications that would be `.config/dev.exs`. Below is an example configuration, the verbose keyword is optional but helps with debugging:\n\n```\nconfig :pre_commit,\n  commands: [\"formatter”, \"test\"]\n  verbose: true\n```\n\nNow when you run `git commit` within this project your formatter will be run and then your test suite, if either of those fail then the commit will not succeed.\n\nIf you enjoyed this post you may also enjoy [Helper function for setting default Struct key](https://tinytechtuts.com/2022-helper-function-set-default-struct-key/).\n"},{"slug":"2022-example-ecto-inner-join-query","category":"blog","title":"Ecto: example inner join query","description":"example of how to write a join query in ecto","tags":["ecto","elixir"],"body":"\nTo write an inner join query using Ecto we will need to reach for the `Ecto.Query` module. This will give us access to a keyword-based approach to writing queries. This module was designed to be expressive and closely mimic SQL queries using keywords.\n\nBelow is an example using a single inner join. In this query we join the `employees` and `stores` tables using the `join:` keyword and return the store and employee names as a map. You'll notice we create two variables we can reference in our queres `e` and `s` respectively, these are known as query bindings:\n```\nimport Ecto.Query\n\nquery = from s in \"stores\",\n          join: e in \"employees\", on: s.id == e.store_id,\n          where: s.id > 10,\n          select: %{store: store.name, employee: e.name}\nRepo.all(query)\n```\n\nBelow is an example using multiple inner joins. In this query we join the `employees` and `stores` tables again but then also join the `schedules` table using an additional `join:` keyword and then return a value for scheduled in our select:\n```\nimport Ecto.Query\n\nquery = from s in \"stores\",\n          join: e in \"employees\", on: s.id == e.store_id,\n          join: sc in \"schedules\", on: sc.employee_id == e.id,\n          where: s.id > 10,\n          select: %{store: store.name, employee: e.name, scheduled: sc.scheduled}\nRepo.all(query)\n```\n\nIf you found this post helpful you might also like [Ecto: using SQL for a query](https://tinytechtuts.com/2022-ecto-direct-sql-query/)."},{"slug":"2022-execute-task-inside-rails-app","category":"blog","title":"How to execute a task inside a Rails app","description":"execute a task inside a Rails app","tags":["rails"],"body":"\nSometimes we want to be able to execute a rails command inside our actual applications. In my instance I wanted to be able to create and run database migrations dynamically. \n\nFor this all you need to do is call the task with backticks. In the example below any instance call to `build_form` will generate a migration using the form name.\n```\nclass FormEngine\n attr_reader :form\n \n def initialize(form)\n   @form = form\n end\n \n def build_form\n   `rails g migration create_form_#{form.name}`\n end\nend\n```\n\nYou can execute the above using: \n```\nFormEngine.new(Form.new(name: \"signup\")).build_form\n```\n\nHe is an example of the generated file:\n\n<image src=\"/images/migration-ss.png\" alt=\"migration\" />\n"},{"slug":"2022-exiting-elixir-iex-options","category":"blog","title":"Options for exiting Elixirs IEx.pry debugger","description":"How to an IEx debugger in Elixir","tags":["elixir","iex"],"body":"\nI've found myself getting stuck on this a few times and wanted to have a list of options for handling this but couldn't find exactly what I was looking for. I hope this helps you!\n\nAfter you require the IEx module invoking the `IEx.pry` function it in your codebase like so:\n```elixir\nrequire IEx\n\ndefmodule SomeModule do\n  def my_function \n    some_var_1 = \"data\"\n    some_var_2 = [\"data2\", \"data3\"]\n    IEx.pry\n  end\nend\n\nSomeModule.my_function\n```\n\nWhen the `IEx.pry` function is called your application will pause and allow you to inspect the current runtime environment. Once you are done with your inspection you can break out of the debugger with the following options:\n1. `respawn` \n2. CTRL + c \n\nCalling `respawn` allows you to resume code execution by starting a new IEx shell and releasing the current one.\n\nCTRL + C will kill your running process(es).\n"},{"slug":"2022-export-sql-to-csv-or-stdout","category":"blog","title":"Export SQL records to CSV or STDOUT","description":"Export SQL records to CSV or STDOUT","tags":["sql"],"body":"\nIf you need to export SQL to a file, particularly a CSV you can do so using the `COPY` command. The `COPY` command has a few different options we will use to achieve this goal, namely `TO`, `DELIMITER`, `CSV` and `header`.\n\n`TO` will specifiy where to dump the results. `CSV` specifies what type of file to create, while `HEADER` will make sure the first row of the file is allocated to column headers. `DELIMITER` denotes the character to separate the columns from within the file.\n\nBelow is an example of the command I tried to use to handle this:\n```sql\nCOPY (SELECT * FROM users where users.organization_id='123') TO '/path/to/newfile' WITH DELIMITER ',' CSV HEADER;\n```\n\nI mentioned I \"tried to\" use this command, as often happens in tech it was not so straightforward much like solving the [sql ordering timeout](https://tinytechtuts.com/2022-sql-timeout-ordering/). This time I received an error because I didn't have root access to the sql server and was met with the error:\n\nERROR:  must be superuser or a member of the pg_write_server_files role to COPY to a file\n\nHINT:  Anyone can COPY to stdout or from stdin. psql's \\copy command also works for anyone.\n\nSo I listened to the HINT and printed my results to STDOUT in my terminal. This is what the resulting command looked like:\n\n```sql\nCOPY (SELECT * FROM users where users.organization_id='123') TO STDOUT;\n```\n\nPrinting to STDOUT is more helpful if you have unlimited scroll back set in your terminal. If you’re using iterm on a Mac you can enable this through:\npreferences -> profiles -> unlimited scroll back. \n\nWithout that you would only see the last 1000 rows printed.\n\nFurther reading:\n- [SQL inner join not returning records](https://tinytechtuts.com/2022-sql-inner-join-not-returning-records/)\n"},{"slug":"2022-filter-array-for-html-element-type-javascript","category":"blog","title":"Filter a JavaScript array for HTML element type","description":"filter javascript array for specific html element type","tags":["javascript"],"body":"\nTo accomplish this task you will first need to [convert the HTMLCollection](https://tinytechtuts.com/2022-can-you-call-map-filter-reduce-on-an-html-collection-object/) into an Array it is not already.\n\nFrom there you can call the `.filter` function on the array and check to see if the `nodeName` property of each element in the collection matches the condition you are expecting.\n\nIn practice that looks like the below example where the last line in the code example filters for and returns all elements in the collection that are `<div>`.\n\n```javascript\nparent = document.querySelectorAll(\".blog\")[0]\ncollection = Array.from(parent.children)\n\ncollection.filter(node => node.nodeName == \"DIV\")\n```\n\n"},{"slug":"2022-function-not-being-called-in-jest-test","category":"blog","title":"Tip: function not being called during Jest test","description":"mock function not triggering actual function","tags":["jest","javascript"],"body":"\nI found myself in a situation where I knew a function was being invoked I couldn’t see the `console.log` I added to the function being printed to the terminal when I ran my test.\n\n\nThe issue I was facing wasn’t an issue with the code, but an issue with my understanding of the test implementation. It turned out that the function I was trying to invoke was being overwritten by a mock function in the test suite. When a mock function is declared, the original function definition is never called, but rather it is intercepted by the mock.\n"},{"slug":"2022-generating-uuids-in-rails","category":"blog","title":"How to generate uuids in a Ruby on Rails application","description":"How to generate uuids in a Ruby on Rails application","tags":["rails"],"body":"\nHave you decided to use universally unique identifiers instead of auto incrementing integers for primary keys in your database table? \n\nYou can generate those UUID's using `SecureRandom.uuid`\n\n```\n=> SecureRandom.uuid\n\"7c8fdaa5-830e-44e0-9a8c-d9785ed60802\"\n```\n\nTip: I cover creating a table with a non-id primary key in [this post](https://tinytechtuts.com/2021-creating-a-table-with-different-primary-key-rails/).\n\nIf you need to exchange a unique identifier with another system, there is another method to handle that, `SecureRandom.urlsafe_base64`.\n\n```\n=> SecureRandom.urlsafe_base64\n\"mEUXmeXenXUiCNI69xULbQ\"\n```"},{"slug":"2022-generating-vs-saving-files","category":"blog","title":"Generating vs Saving files in software development","description":"how to decide whether to generate or save a file in software development","body":"\nThis post discusses options for when you have to build files in your application. An example might be a user wants to download a csv report or you you need to send a PDF of a sales receipt. \n\nWhen I refer to processes I am talking about server processes and to clarify what I mean by generating vs saving a file:\n\nGenerating a file: Build a store the file in your application and when a user wants to retrieve it, you pull it from your database.\n\nSaving a file: Write the file outside of your application to a separate storage provider. This could be Amazon's S3 service or Google Cloud Storage. In this scenario when the user wants to download the file it will be retrieved from the service provider.\n\nWhen deciding whether you are going to generate a file or saving there are a few considerations to make:\n\n1. If you were to generate the file, how long would it take? This is important because you don't want the main application process to be busy generating PDFs for a long time, in a single threaded application this would block other incoming requests while the PDF is building. With this in mind you will always want to handle file generation or saving in a separate process from your application to free up valuable server resources.\n2. Would it be simpler to use a storage provider? In most cases there would be less custom development by saving a file to a storage provider, most languages / frameworks have libraries to handle it.\n3. Do you have the budget for a storage provider? Perhaps you need to save on recurring costs, then it might make more sense to build it yourself.\n\nThese are the considerations I thought through before deciding that generating files was the route I was going to go. If it ends up being a server bottleneck though I will offload this work to a storage provider later on.\n"},{"slug":"2022-get-column-names-and-types-postgres","category":"blog","title":"How to get column names and their types using Postgres","description":"Learn how to get column names and their types using Postgres","tags":["postgres"],"body":"\nThere may come a time when you're working with a postgres db that contains many tables and you want some meta data about a specific table, in this instance that tables column names and its types. \n\nTo accomplish this you will first need to access your postgres database through either a library provided by the programming language you are using to interact with the database or accessing the database directly on the command line. \n\nIf you have privileged access to the database you can login to it on the command line using:\n\n```\npsql name_of_database\n```\n\nAfter you're in the database, to get the list of column names and types from a table you can use this query:\n\n```sql\nSELECT column_name, data_type FROM information_schema.columns WHERE table_name='users';\n```\n\nThis query accesses a special table in postgres called information_schema and queries for the column_name and data_type on the users table.\n\nIf you thought that article was awesome, wait until you read [Postgres pg_ctl vs psql](https://tinytechtuts.com/2022-pg_ctl-vs-psql/) it'll knock your socks off. If you're not wearing any socks then don't even bother reading it."},{"slug":"2022-get-index-of-a-matched-conditions-element","category":"blog","title":"Get the index position from element in a matched condition","description":"Get the index position from element in a matched condition","tags":["elixir"],"body":"\nTo achieve the desired outcome of the post title, you can use the `Enum` modules `find_index/2` function. This function will accept two arguments, the enumberable itself and a callback function as parameters. If the callback function finds a matched condition it will return that items index position. If there are more than two of the same item it will return the first matches index position. If there are no matches found, it will return `nil`.\n\n```Elixir\nEnum.find_index([\"football\", \"baseball\", \"hockey\", \"basketball\"], fn sport -> sport == \"hockey\" end)\n=> 2\n\nEnum.find_index([\"football\", \"baseball\", \"hockey\", \"hockey\"], fn sport -> sport == \"hockey\" end)\n=> 2\n\nEnum.find_index([\"football\", \"baseball\", \"hockey\", \"hockey\"], fn sport -> sport == \"soccer\" end)\n=> nil\n```\n\nFurther reading:\n- [Rendering a LiveView template outside of router](https://tinytechtuts.com/2022-rendering-liveview-template-outside-of-router/)\n- [How to paginate an in memory array](https://tinytechtuts.com/2022-in-memory-pagination-by-example/)\n"},{"slug":"2022-git-nuke-and-pave","category":"blog","title":"Git: nuke and pave","description":"deploy to staging or test using gits nuke and pave strategy","tags":["git"],"body":"\nOn some programming teams, you might not need permission to push your code changes to a test/staging environment. There is likely a dedicated test/staging/regression branch your team will use to push testing changes to. In that circumstance, when you want to execute a test environment build you have a couple of options many of us are familiar with:\n1. Merge your changes into the testing branch through `git merge`.\n2. Merge your changes into the testing branch through `git rebase`.\n\nAn issue that might come up though is you might not need whichever changes currently exist in the regression branch, it’s possible someone already pushed testing changes to that branch that you don’t need. To get around this dilemma you can use a strategy known as nuke and pave. It works like this:\n1. From your current branch, delete the current local testing branch `git branch -D staging`.\n2. Create a new regression branch from your branch `git checkout -b staging`.\n3. Force push your branch `git push origin -f staging`.\n\nThat should trigger your build hooks to start deploying your changes to your testing environment. "},{"slug":"2022-handle-controller-responses-in-before-action","category":"blog","title":"Handle controller responses using Rails before_action","description":"How to handle controller responses using Rails before_action","tags":["rails"],"body":"\nUsing Rails `before_action` you can return an HTTP response *before* the actual controller action is invoked, in the example below, the create action. This allows you to clean up your controller code, so instead of having the create action running the code defined in `setup_request` and `verify_request` you can have a before action handle it for you.\n\nThe `head` method used below is an alias for responding only with the status given (as a symbol), headers, and an empty body.\n\n```ruby\nclass ExampleController < ApplicationController\n  before_action :verify_request, :setup_request\n\n  def create\n    # handle action if before_action's have not rendered head\n  end\n\n  private\n  def setup_request\n    head :ok unless application_exists\n  end\n\n  def verify_request\n    head :unauthorized unless auth_token.present?\n  end\nend\n```\n"},{"slug":"2022-handling-unavaible-data-rails","category":"blog","title":"Handling unavailable server data in Rails","description":"handling data resources that are not immediately available in Ruby on Rails","tags":["rails","sidekiq"],"body":"\nIf you need a resource to be present from another system, but you don’t know when it will be available, it would be nice if the system whose resource you needed would send a notification to let you know when the resource is there, but if that is not the case, then you might want to try polling for the resource in a background job. This has a few benefits:\n\n1) By using a background job, you are not consuming valuable primary application processing resources to handle this task.\n2) If the resource you need is not present at the time of polling, you can fail the job which will put it back in the queue to be tried again later.\n3) When a failed job is put back in the queue it will be scheduled using an incremental backoff, so each time it fails it waits a longer before retrying the job. Background job processors like Sidekiq provide incremental backoff functionality with their default configuration."},{"slug":"2022-helper-function-set-default-struct-key","category":"blog","title":"Helper function for setting default Struct key","description":"Helper function for setting default Struct key in elixir programming.","tags":["elixir"],"body":"\nSetting a default key for an Elixir Struct was something I had searched Google for and had a hard time finding a solution for. I hope this quick post is able to be the solution needed for some of you beautiful devs out there just trying your best.\n\nThe `set_struct_default` function below has an arity of three, accepting a struct, a key to set a default for and a default value. The function body checks if the struct already has a value for the key being checked, if it does it will just return the struct, otherwise it will set the default value.\n\n```\ndef set_struct_default(struct, key, default) do\n  if Map.has_key?(struct, key) do\n    struct\n  else\n    Map.put(struct, key, default)\n  end\nend\n```\n\nNote if you're trying to set a default for a schema based struct like with Ecto or Absinthe then those types libraries typically allow you to define a default for a \"field\" in the struct as a keyword list option `default: \"some default string\"`.\n\nIf you enjoyed this post you may also enjoy [Update what Ecto considers nil / empty](https://tinytechtuts.com/2022-update-what-ecto-considers-empty/).\n"},{"slug":"2022-how-do-subdomains-work-with-dns","category":"blog","title":"How subdomains work with DNS","description":"Explain how a DNS system handles subdomains","tags":["dns"],"body":"\nTo gain an understanding of DNS systems in general refer to this [previous post](https://tinytechtuts.com/2022-dns-system-request-flow-explained/) on the DNS system request flow.\n\nThis post is a grouping of main takeaways I came up with with after researching subdomains:\n\n- In the URL www.devdecks.io the www is the website's subdomain. \n- A subdomain can point to an entirely separate server or all of your subdomains can point to the same server, it is up to the engineer to decide what works best for their system.\n  - Example 1: www.devdecks.io might point to a webserver but mail.devdecks.io might point to a separate mail server.\n  - Example 2: org1.mysaasapp.com might point to the same server as org2.mysaasapp.com. In this scenario the subdomains would be used in your application to decipher which organization the request is being made on behalf of.\n- You can point subdomains to a different IP address using an ARECORD that you register with your DNS provider.\n- You can point subdomains to a different domain name using a CNAME that you register with your DNS provider.\n- A wildcard DNS record allows you to point all existing and non-existing subdomains to a specific area. For example, www.example.com and test.example.com would both direct to www.example.com when a wildcard subdomain is enabled. A wildcard subdomain would be used for our previous example of org1.mysaasapp.com and org2.mysaasapp.com.\n"},{"slug":"2022-how-does-rails-handle-referential-integrity","category":"blog","title":"How does Rails handle referential integrity","description":"how does rails handle referential integrity","tags":["rails","databases"],"body":"\n<h3>Primary Key / Foreign Key</h3>\nTo properly illustrate this concept lets first outline the primary key / foreign key relationship:\n- Primary key: this is a column (sometimes multiple columns) in a table that uniquely identify a row in a database table. Relational databases enforce the uniqueness of primary keys, each row in a table must have a unique primary key and they are almost always auto generated.\n- Foreign key: this is a column in a table whose value matches the primary key of a record in another table. If you are to add a database row with a foreign key column, the primary key record must already exist.\n\nThe primary key / foreign key relationship sets up the one to many relationship in rails where the primary key record can have many related foreign key records.\n\n<h3>What is referential integrity</h3>\nReferential integrity is a constraint that enforces a relationship between two records. It ensures that values in a foreign key column must either be exist in primary key that is referenced by the foreign key or they must be null. This is usually configured and handled at the database layer of an applications system.\n\n<h3>How does Rails handle referntial integrity</h3>\nThe Rails way and specifically here, the Active Record way says that we should handle as much behavior and contraints as possible at the application level so rails suggests first adding application level validations in your Active Record models like so:\n\n```ruby\nclass Product < ApplicationRecord\n  validates :user_id, uniqueness: true\nend\n```\n \nAnd we can also add the `dependent: :destroy` option to our models to destroy child objects when parent objects are destroyed. But Rails also gives you the option of adding the database level contraint to guarantee referential integrity and you can do that by `add_foreign_key :products, :users`.\n\nSimilar posts:\n- [Rails integration testing cheatsheet](https://tinytechtuts.com/2022-rails-integration-testing-cheatsheet/)"},{"slug":"2022-how-to-call-a-rails-method-before-validations-occur","category":"blog","title":"How to call a Rails method before a validations occur","description":"rails before_validation callback","tags":["rails","active-record"],"body":"\nIf you need some behavior to occur before validations take place on an ActiveRecord object, you can add the `before_validation` callback to your ActiveRecord model. This method accepts a method name as an argument which will be automatically invoked before validations are run.\n\nYou will also have access to the ActiveRecord within the invoked callback method, it can be referenced explicitly through `self`. Or you can just call its attribute methods directly because `self` is the default object.\n\n```ruby\nclass Account < ApplicationRecord\n  # is called second\n  validates_presence_of :name, :email\n  # is called first\n  before_validation :clean_record\n\n  def clean_record\n    p \"#{self.inspect}\"\n    p \"#{name}\"\n  end\nend\n\nAccout.create(name: \"blue bacon\", email: \"blue@bacon.istasty\")\n# Puts output from clean_record invocation:\n# \"#<Account id: nil, name: \\\"blue bacon\\\", email: \\\"blue@bacon.istasty\\\", admin: nil, created_at: nil, updated_at: nil>\"\n# \"blue bacon\"\n```\n\nIf you enjoyed this post, you might also enjoy [How does Rails handle referential integrity](https://tinytechtuts.com/2022-how-does-rails-handle-referential-integrity/)\n"},{"slug":"2022-how-to-delete-characters-from-ruby-string","category":"blog","title":"How to delete characters from a string in Ruby","description":"How to delete characters from a string in Ruby","tags":["ruby"],"body":"\nIf you need to delete characters from a string in Ruby you can do so using the `#delete` method on the `String` object.\n\nYou can pass it any number of arguments you would like, for each argument passed to the method ruby will look for a substring or substrings that matches the arguments contents and remove them from the string, the returned value being the string minus any matched patterns passed to the `delete` method.\n\n```ruby\n=> \"I like pie\".delete(\"e\")\n\"I lik pi\"\n```\n\nBe careful with this though, it can sometimes have unexpected behavior. In the event you wanted to delete the word \"like\" you might try this:\n```ruby\n=> \"I like pie\".delete(\"like\")\n\"I  p\"\n```\n\nBut since \"like\" contains an \"i\" and \"e\", it method also deleted those characters from the word \"pie\".\n\nTo delete a full word, I would use [gsub](https://tinytechtuts.com/2022-how-to-replace-string-content-in-ruby) like so:\n\n```ruby\n=> \"I like pie\".gsub(\"like\", \"\")\n\"I  pie\"\n```\n\n\nFurther reading:\n- [How to iterate a string containing newlines in Ruby](https://tinytechtuts.com/2022-how-to-iterate-string-with-newlines-in-ruby/)\n"},{"slug":"2022-how-to-delete-leading-and-trailing-whitespace-ruby-string","category":"blog","title":"How to delete the leading and trailing whitespace of a string in Ruby","description":"How to delete the leading and trailing whitespace of a string in Ruby","tags":["rails","turbo"],"body":"\n\nWhen programming, from time to time you will encounter strings in the format of `\"  some leading whitespace\"` or `\"some trailing whitespace  \"`. You can remove these spaces through the use of methods on the `String` object, `lstrip` and `rstrip`.\n\n`lstrip` will delete all the whitespace characters that are present before the first non whitespace character in a string. \n\n```ruby\n=> \"  some leading whitespace\".lstrip\n\"some leading whitespace\"\n```\n\n`rstrip` will delete all the whitespace characters that are present after the last non whitespace character in a string. \n\n```ruby\n=> \"some trailing whitespace  \".rstrip\n\"some trailing whitespace\"\n```\n\nTo delete both the leading and trailing whitespace you can use the `strip` method.\n\n```ruby\n=> \"    some leading trailing whitespace  \".strip\n\"some leading trailing whitespace\"\n```\n\nFurther reading:\n- [How to replace the contents of a string in Ruby](https://tinytechtuts.com/2022-how-to-replace-string-content-in-ruby/)\n"},{"slug":"2022-how-to-handle-token-auth-in-rails","category":"blog","title":"How to handle token auth in Rails","description":"how to handle token auth in rails","tags":["rails","auth"],"body":"\nThis post is going to demonstrate how to set up a central tokens table for your Rails application, with the goal to better organize access to resources in your application.\n\nIf you did not have a centralized tokens table in your Rails application then each entity that needed different token auth would have to have its own token column on the model and if that entity needed multiple types of tokens, it would have multiple columns on the model. In practice that looks like:\n\n```\nUser.last.admin_auth_token\nUser.last.report_view_token\n```\n\n```\nReport.last.auth_token\n```\n\nInstead of having these tokens spread across various domains, let's create a new tokens database table to house all of these different kinds of tokens and associate them with the application entities they belong to.\n\nThe migration file:\n```\nclass CreateTokens < ActiveRecord::Migration[5.4]\n def change\n   create_table :tokens do |t|\n     t.string :kind\n     t.datetime :expires_at\n     t.string :token\n     t.integer :tokenable_id\n     t.string :tokenable_type\n     t.timestamps null: false\n \n     t.index :token\n     t.index [:tokenable_id]\n   end\n end\nend\n \n\n```\n\nThe new table columns above briefly defined:\n\n- tokenable_id - id of the user or account that the token is associated with\n- tokenable_type - was the token created for a user or an account. \n- token - The actual token string\n- expires_at - When to revoke the token\n- kind - Synonym for token type (eg :ADMIN_AUTH_TOKEN)\n\nNow we need to set up our application to work with this new tokens table. Let’s first define the Token model. The model does two things: \n1) Defines two callbacks to set the token and expiry.\n2) Enables the polymorphic relationships using the `tokenable_id` and `tokenable_type` in the `belongs_to :tokenable` method.\n\n```\nclass Token < ApplicationRecord\n belongs_to :tokenable, polymorphic: true\n before_create :set_token, :set_expires_in\n \n private\n \n def set_token\n   self.token = SecureRandom.urlsafe_base64\n end\n \n def set_expires_in\n   expires_in = case kind.to_sym\n   when :INVITE_TOKEN then nil\n   when :AUTH_TOKEN then 30.days\n   when :LOGIN_REDIRECT then 1.day\n   else\n     raise StandardError\n   end\n \n   self.expires_at ||= DateTime.now + expires_in\n end\nend\n\n```\n\n\nAnd for the models that are we are going to be able to create tokens for we will need to define the other side of the relationship. I’ll use Account as an example:\n\n```\nclass Account < ApplicationRecord\n has_many :tokens, as: :tokenable, dependent: :destroy\nend\n```\n\nNow that we have both sides of the relationship setup to test, load the Rails console and try it out. Let’s create a Token for an Account and then try to look it up.\n\n```\n=> Token.create(tokenable_type: Account, tokenable_id: 1, kind: :LOGIN_REDIRECT)\n#<Token:0x0018 id: 1 ….>\n```\n\n```\n=> Account.find(1).tokens.find_by(kind: :LOGIN_REDIRECT)\n#<Token:0x0018 id: 1 ….>\n```\n\nThis is a good example of a refactoring opportunity. If your application has different tokens spread across various domains consider consolidating into a central database table and using the power of Rails polymorphism to make your code cleaner.\n\n\nSimilar posts:\n - [Rails nested resources MVC complete example](https://tinytechtuts.com/2021-rails-nested-resources-mvc-complete-example/)\n "},{"slug":"2022-how-to-iterate-string-with-newlines-in-ruby","category":"blog","title":"How to iterate a string containing newlines in Ruby","description":"How to iterate a string containing newlines in Ruby","tags":["ruby"],"body":"\nLet's say you have a string that resembles `\"a string that \\n is really multiple paragraphs \\n\"` and you want to work with each section of the string with a newline, Ruby has a method to handle that called `each_line`.\n\n```ruby\nparagraph = []\nexample_paragraph = \"a string that \\n is really multiple paragraphs \\n\"\nexample_paragraph.each_line do |line|\n  paragraph << line\nend\n\n=> paragraph\n[\"a string that \\n\", \" is really multiple paragraphs \\n\"]\n```\n\nIt can also iterate over the string any time it encounters a substring passed to it:\n\n```ruby\nparagraph = []\nexample_paragraph = \"a string that \\n is really multiple paragraphs \\n\"\nexample_paragraph.each_line(\"really\") do |line|\n  paragraph << line\nend\n\n=> paragraph\n[\"a string that \\n is really\", \" multiple paragraphs \\n\"]\n```\n\nFurther reading:\n- [How to read Ruby open source code locally](https://tinytechtuts.com/2022-how-to-read-ruby-open-source-code-locally/)"},{"slug":"2022-how-to-pretty-print-json-ruby","category":"blog","title":"How to pretty print JSON in ruby","description":"How to pretty print a JSON object in ruby","tags":["ruby","json"],"body":"\nThe easiest way I’ve found to accomplish this is using `puts`\n\nThe call below will print the json object and return nil\n\n```\nputs data.to_json\n{\"admin\":true,\"email\":\"admin@gmail.com\"}\n```\n\nIf you need the object to be printed on a multi-line basis you can use the command line tool [jsonpp](https://github.com/jmhodges/jsonpp).\n\nAfter installing you can copy an object like the one above and paste it into its own file and then run the command:\n\n```\njsonpp path/to/file.json\n```\n\nWhich will produce the following output:\n\n```\n{\n  \"admin\": true,\n  \"email\": \"admin@gmail.com\"\n}%\n```\n\nFurther reading:\n- [Migrating to Elixir's Earmark for markdown processing](https://tinytechtuts.com/2021-elixir-earmark-code-parsing/)\n\n\n"},{"slug":"2022-how-to-read-ruby-open-source-code-locally","category":"blog","title":"How to read Ruby open source code locally","description":"How to read RubyGem code locally","tags":["ruby","oss"],"body":"\nI’m sure TMTOWTDI here but I hope this helps you get started. The end goal here is to be able to run the following command in your terminal `bundle open gem_name` and have the code for the library opened in your text editor.\n\nTo start, use your bash, zsh, or other terminal shell to export a variable called `BUNDLER_EDITOR`. Bundler will use this environment variable to open the ruby gem library code in your text editor I’m using vscode and pass the appropriate command to open it `code -a .`. The full command on the terminal looks like:\n\n`export BUNDLER_EDITOR=\"code -a .\"`\n\nFrom there navigate to the ruby project that is using the gem you want to read source code for, you will need to have the gem declared in your Gemfile for this to work. After the gem you want to read is included in a ruby project, navigate to the root directory of that project on your command line and run:\n\n`bundle open gem_name`\n\nA more explicit example:\n\nGenerate a new rails project:\n`rails new test_project`\n\nOpen the Gemfile and add the YAML gem to your dependencies:\n```ruby\ngem \"yaml\"\n```\n\nNavigate to the project root directory:\n```\ncd test_project\n```\n\nOpen the source code the for yaml gem:\n```\nbundle open yaml\n```\n\nAfter running the `bundle open` command the library code for YAML should be opened in your text editor. \n\nNote that if you run the `bundle open` command without setting a value for `BUNDLE_EDITOR` you will be met with the following message:\n\n\"To open a bundled gem, set `$EDITOR` or `$BUNDLER_EDITOR`\"\n\nSo you could alternatively set a value for `$EDITOR` and you should have the same outcome. Dealers choice.\n\nFurther reading:\n- [Ruby on Rails integration testing cheatsheet](https://tinytechtuts.com/2022-rails-integration-testing-cheatsheet/)\n"},{"slug":"2022-how-to-replace-string-content-in-ruby","category":"blog","title":"How to replace the contents of a string in Ruby","description":"How to replace the contents of a string in Ruby","tags":["ruby"],"body":"\nFor this example we will take the string `\"bacon, eggs\"` and using that string create a new string, `\"bacon, orange juice\"`, while leaving the original string intact.\n\nTo accomplish this task we will use the `String` class method `gsub`. In the most basic use case we will pass two arguments `gsub`:\n1. The contents of the string we want to replace.\n2. The replacement text.\n\nThe result will return a new string with the contents replaced:\n```\nbacon_and_eggs = \"bacon, eggs\"\nbacon_and_oj = bacon_and_eggs.gsub(\"eggs\", \"orange juice\")\n\n=> bacon_and_eggs\n\"bacon, eggs\"\n=> bacon_and_oj\n\"bacon, orange juice\"\n```\n\nIn more advanced use cases you can pass a pattern you want to match as the first argument to `gsub`.\n\nFurther reading:\n- [How to handle token auth in Rails](https://tinytechtuts.com/2022-how-to-handle-token-auth-in-rails/)\n"},{"slug":"2022-in-memory-pagination-by-example","category":"blog","title":"How to paginate an in memory array","description":"How to implement pagination using Elixirs Nimblepublisher","tags":["nimblepublisher","elixir"],"body":"\nThis is an example of how you can implement in memory pagination using Elixir and NimblePublisher. If you are unfamiliar with NimblePublisher you can check out this [blog post](https://dashbit.co/blog/welcome-to-our-blog-how-it-was-made) from Jose Valim and Dashbit.\n\nFirst I want to address that there are many different methods for handling pagination in an application, but what I wanted to do was paginate an in memory array, or List, in Elixir. This is a list of blog posts gets compiled with my Elixir application on startup. \n\nThe end goal here was to be able to render 10 posts per page with the first ten showing on the homepage of this website and every subsequent ten posts being displayed at https://tinytechtuts.com/page/2/, https://tinytechtuts.com/page/3/, etc.\n\nTo handle this you first need to define two routes in your `router.ex` file. You only need to define two routes if you want the same setup I have (homepage and /page), you could also just have a single route for `/page/:count`.\n\n```elixir\nget \"/\", BlogController, :index\nget \"/page/:count\", BlogController, :paginate\n```\n\nBelow is the code for accessing the list of blog posts. This code injects the NimblePublisher macro into the module which creates the `@posts` variable and then the posts are sorted by date and filtered for published posts, from there it sets the data for `@tags` and defines two getter methods for that data.\n\n```elixir\ndefmodule DevDecks.Blog do\n  alias DevDecks.Blog.Post\n\n  use NimblePublisher,\n    build: Post,\n    from: Application.app_dir(:dev_decks, \"priv/posts/**/*.md\"),\n    as: :posts,\n    highlighters: [:makeup_elixir, :makeup_erlang]\n\n  @posts Enum.sort_by(@posts, & &1.date, {:desc, Date})\n  @published_posts Enum.filter(@posts, fn (p)-> p.published end)\n  @tags @published_posts |> Enum.flat_map(& &1.tags) |> Enum.uniq() |> Enum.sort()\n\n  def all_posts, do: @published_posts\n  def all_tags, do: @tags\nend\n```\n\nThen in the controller define the two functions referenced in our router code, one for handling `index` requests and one for handling `paginate` requests.\n\nThe `index` action will only need to worry about setting state for `has_next_page` to see if a next page is available, `next_page_link`, which holds the next link for pagination and `posts` for paginated blog posts. The `paginate` action will declare an extra state value for `previous_page_link` to handle previous page navigation. The code for the `Blog` methods will be covered later.\n\n```elixir\ndefmodule DevDecksWeb.BlogController do\n  alias DevDecksWeb.Router.Helpers, as: Routes\n  use DevDecksWeb, :controller\n  alias DevDecks.Blog\n\n  def index(conn, _p) do\n    page = 1\n    next_page_link = \"/page/#{page + 1}\"\n\n    render(\n      conn,\n      \"index.html\",\n      posts: Blog.paginated_posts(page),\n      has_next_page: Blog.has_next_page(page),\n      next_page_link: next_page_link\n    )\n  end\n\n  def paginate(conn, %{\"count\" => count}) do\n    {count, _} = Integer.parse(count)\n    next_page = count + 1\n    previous_page = count - 1\n    next_page_link = next_page == 1 && \"/\" || \"/page/#{next_page}\"\n    previous_page_link = previous_page == 1 && \"/\" || \"/page/#{previous_page}\"\n\n    render(\n      conn,\n      \"paginate.html\",\n      posts: Blog.paginated_posts(count),\n      next_page: count + 1,\n      next_page_link: next_page_link,\n      previous_page_link: previous_page_link,\n    )\n  end\nend\n```\n\nIn the previously referenced `Blog` application context is where the behavior for the pagination functionality will live. The `paginated_posts` function below creates a range of a count up to 9, which will give us 10 items if using a starting point of 0, eg. `0..9`. The function then filters the NimblePublisher `@published_posts` using the index of each post and the `start..stop` range, if a post exists at the index, it will be included in the paginated page.\n\nThe `has_next_page` function takes the current page value and checks to see if there are any more posts in the collection at then next index value.\n\n```elixir\n  def paginated_posts(page) do\n    start = (page * 10) - 10\n    stop = start + 9\n\n    @published_posts\n    |> Enum.with_index\n    |> Enum.filter(fn({_, index}) ->\n      Enum.member?(start..stop, index)\n    end)\n    |> Enum.map(fn(tuple) ->\n      elem(tuple, 0)\n    end)\n  end\n\n  def has_next_page(page) do\n    first_index = (page * 10) - 10\n\n    cond do\n      Enum.at(@published_posts, first_index) -> true\n      true -> false\n    end\n  end\n```\n\nThen in the html template make use of the state delcared in the controllers by rendering the posts using an elixir comprehension and render a link for the next page if relevant.\n\nIndex page:\n```elixir\n  <%= for post <- @posts do %>\n    <div id=\"<%= post.id %>\" style=\"margin-bottom: 1.5rem;\">\n      <div class=\"flex-row-d-column-m\">\n        <h2>\n          <%= link post.title, to: Routes.blog_path(@conn, :show, post), class: \"blog-title\" %>\n        </h2>\n        <time><%= post.date %></time>\n      </div>\n\n      <div class=\"flex-row-no-space\">\n        <img class=\"icon-sm\" src=\"<%= Routes.static_path(DevDecksWeb.Endpoint, \"/images/tag.svg\") %>\" />&nbsp<%= Enum.map(post.tags, fn t -> link(\"#{t}\", to: \"/tags/#{t}\", class: \"blog-tag\") end) %>\n      </div>\n    </div>\n  <% end %>\n  <%= link(\"More Blog\", to: @next_page_link) %>\n```\n\n\nPaginate page:\n```elixir\n <%= for post <- @posts do %>\n    <div id=\"<%= post.id %>\" style=\"margin-bottom: 1.5rem;\">\n      <div class=\"flex-row-d-column-m\">\n        <h2>\n          <%= link post.title, to: Routes.blog_path(@conn, :show, post), class: \"blog-title\" %>\n        </h2>\n        <time><%= post.date %></time>\n      </div>\n\n      <div class=\"flex-row-no-space\">\n        <img class=\"icon-sm\" src=\"<%= Routes.static_path(DevDecksWeb.Endpoint, \"/images/tag.svg\") %>\" />&nbsp<%= Enum.map(post.tags, fn t -> link(\"#{t}\", to: \"/tags/#{t}\", class: \"blog-tag\") end) %>\n      </div>\n    </div>\n  <% end %>\n\n\n  <%= link(\"Less Blog\", to: @previous_page_link) %>\n  &nbsp\n  &nbsp\n  <%= if length(@posts) == 0 do %>\n  <% else %>\n    <%= link(\"More Blog\", to: @next_page_link) %>\n  <% end %>\n```"},{"slug":"2022-install-localstack-python-venv","category":"blog","title":"Installing Localstack in a Python virtual environment","description":"Learn how to instal Localstack in a Python virtual environment","tags":["python","localstack"],"body":"\nThis post assumes you are creating this environment on macOS.\n\nThe first step here is to create the virtual environment directory. The command below will install the virtual environment in the current directories venv folder:\n\n```\npython3 -m venv ./venv\n```\n\nThis will create a number of files for you, if you `cd` into the the venv directory you can list them:\n\n```\n=> cd venv && ls\nbin    include    lib    pyvenv.cfg\n```\n\nTo start the virtual environment execute the `activate` executable located in the bin folder of venv:\n```\n=> source bin/activate\n```\n\nRunning this will pull you into the virtual environment, which you can check by running: \n```\n=> which python\nvenv/bin/python\n```\n\nNow you can install the localstack package from within the virtual environment:\n```\n=> python3 -m pip install localstack\n```\n\nOnce complete check that you have successfully installed localstack by executing the command `localstack` in your terminal.\n\nEnjoy installing / configuring things? Then you may enjoy the post [Steps to configure Git and remote origin](https://tinytechtuts.com/2022-configure-git-and-remote/).\n"},{"slug":"2022-keyword-argument-must-be-followed-by-space-after","category":"blog","title":"Elixir: keyword argument must be followed by space after:","description":"solve error keyword argument must be followed by space after:","tags":["elixir"],"body":"\nThe other day I received this error when writing an elixir program:\n```\nkeyword argument must be followed by space after: key:\n```\n\nI ran into this Elixir issue trying to pass `key:` as a keyword argument in a tuple. This won’t work because tuple needs to be passed as `:key` inside a tuple (or anywhere that’s not using keywords) otherwise elixir thinks it’s a keyword argument for a map, struct or keyword list.\n\n```\nCache.upsert(pid, {key:, \"fff\"})\n```\n\nIn order to get my program to work I had to update the code to:\n```\nCache.upsert(pid, {:key, \"fff\"})\n```"},{"slug":"2022-list-with-index-in-elixir-example","category":"blog","title":"Iterating a List with_index in Elixir","description":"How to get an index value when iterating list in Elixir","tags":["elixir"],"body":"\nIn Ruby you can get the index value when iterating over a list by calling the method `each_with_index` on the array object itself. This method makes the iterable object and its index available to you inside of a block, like so:\n\n```ruby\narr = [\"one\", \"two\", \"three\"]\narr.each_with_index do |number, index|\n  # handle logic here\nend\n```\n\nThe way to handle this in Elixir is to use the `Enum` module which works with any enumerable data type in the Elixir language, including List. The `Enum` module has a function `.with_index` that can be used to get the index value for each item in the list on iteration. In practice that could look like:\n\n```elixir\n    list = [Post.find(1), Post.find(2)]\n    |> Enum.with_index\n    |> Enum.filter(fn({post, index}) ->\n      # handle logic here\n    end)\n```\n\nHere we are piping the list to the `Enum.with_index/2` and then piping the result of that to the `Enum.filter/2` function. As demonstrated in the code above the iterable object and it's index are available in the callback function of the `filter` function.\n\n\n"},{"slug":"2022-login-to-ngrok-on-the-command-line","category":"blog","title":"How to login to ngrok on the command line","description":"Login to ngrok account on the command line","tags":["ngrok"],"body":"\nThe only time I've found I've had to do this is when logging into an ngrok account for a company and the primary reason I've had to do that is to get access to custom domains the account has created for tunneling through a custom URL. If you're doing this individually you will need to create an ngrok account through their website and follow these same steps below.\n\nTo authenticate your ngrok account this way you will first need login credentials to the ngrok accounts web dashboard. Once logged into the system on the left sidebar navigation should be a link to \"Your auth token\" (or similar depending on how far into the future this is being read). Copy the token from that link and on your command line run `ngrok authtoken your_copied_auth_token`. \n\nFrom now on when you stand up an ngrok tunnel you will be logged into that account and have access to the custom domains and other features created in the account.\n\nFurther reading:\n- [DNS system request flow explained](https://tinytechtuts.com/2022-dns-system-request-flow-explained/)\n- [How subdomains work with DNS](https://tinytechtuts.com/2022-how-do-subdomains-work-with-dns/)\n"},{"slug":"2022-merge-nested-lists-elixir","category":"blog","title":"Elixir: merge nested Lists","description":"How to merge nested Lists in elixir","tags":["elixir"],"body":"\nAny time you build an application there will almost inevitably come a time when you need to combine multiple complex data structures into a single data structure. In the event you need to handle such an operation with a List of Lists or “nested Lists”, you can reach for a function on the List module `List.flatten/2`\n \n```\n=> list = [\n  [1, {:ok, \"The Cat Goes to Brazil\"}],\n  [2, {:ok, \"The Dog Barks at the Mailman\"}]\n]\n \n=> List.flatten(list)\n[1, {:ok, \"The Cat Goes to Brazil\"}, 2, {:ok, \"The Dog Barks at the Mailman\"}]\n```\n \nIllustrated above, the two nested Lists are combined into a single List with the elements in the first nested list being accounted for first and the items in the second nested list being accounted for second.\n\nI wrote another List post covering sorting a list of maps [here](https://tinytechtuts.com/2022-sort-list-of-maps-by-key/), if you indulge I hope you enjoy.\n\n"},{"slug":"2022-migrate-wireguard-through-export","category":"blog","title":"How to migrate wireguard tunnel through export","description":"Learn how to migrate wireguard tunnel through export","tags":["wireguard"],"body":"\nThis Wireguard tunnel migration took place on a Mac and was moved to another Mac. Steps may be slightly different on Windows.\n\nTo start, open the Wireguard application and navigate to the \"Manage Tunnel\" page, while on the manage tunnel page select the tunnel you need to migrate\n\nAfter that navigate to click on \"file\" and then \"export tunnels to zip\". If you get no response from this action, try quitting and restarting Wireguard, this was something that happened to me.\n\nFrom there complete the export and email yourself the zip file.\n\nOn your new computer download the zip file and extract the contents.\n\nIn the new Wireguard app click \"import tunnel(s) from file\" and select the unzipped config.\n\nYou should now be ready to connect to your VPN.\n\nWhile were on the topic of web routing you might find this article, [DNS system request flow explained](https://tinytechtuts.com/2022-dns-system-request-flow-explained/) interesting."},{"slug":"2022-multiline-inline-conditional-rendering-react","category":"blog","title":"Multiline inline conditional rendering React","description":"Inline multiline conditional rendering React","tags":["react"],"body":"\nThis style of rendering JSX can be thought of as less readable, but I prefer it for its conciseness and to me it looks pretty readable since once you know what a ternary expression is doing you know what this statement is doing. \n\nIn this JSX below if `condition` evaluates to `true`, then the `<img>` is rendered and if `condition` is `false` then `<button>` will be rendered.\n\n```javascript\nreturn(\n  <div>\n    {condition\n      ? (\n        <img src={icon} alt=\"close\" className=\"xl-btn\" onClick={onClick} type=\"button\" />\n      )\n      : (\n        <button aria-label=\"Close\" className=\"xl-btn\" onClick={onclick} type=\"button\">\n          <i className=\"fa xl-fa-times\" />\n        </button>\n      )\n    }\n  </div>\n)\n```\n"},{"slug":"2022-pg_ctl-vs-psql","category":"blog","title":"Postgres pg_ctl vs psql","description":"Learn the difference between pg_ctl vs psql","tags":["postgres"],"body":"\nThis article is based on my experience using these commands and my general understanding, there undoubtedly is more that can be accomplished with each, so please keep that in mind as you proceed through this wildly fun postgres post.\n\n<h2>pg_ctl</h2>\nAny time I reach for the `pg_ctl` command it is for administrating my postgres server. An example would be starting and stopping the server. The most common commands I've used:\n\nStart postgres server:\n```\npg_ctl start\n```\n\nStop postgres server:\n```\npg_ctl stop\n```\n\nCheck the status of the postgres server:\n```\npg_ctl status\n```\n\nRestart the postgres server:\n```\npg_ctl restart\n```\n\n\n\n<h2>psql</h2>\n\nThe `psql` command is used for accessing a database server. The documentation describes it as \"terminal based front-end to PostgreSQL\". There are different options you can use with this command to specify things like user and hostname. Below we cover some of the different options:\n\nConnect to a database under root access:\n```\npsql database_name\n```\n\nYou can also specify a specific user to connect to the database with:\n```\npsql -d database_name -U user_name -W\n```\n\nOr connect to a server on a different host:\n```\npsql -h host -d database_name -U user_name -W\t\n```\n\nDid this post make your day a little brighter? Why not take a swim in this other postgres article about [postgres with Homebrew](https://tinytechtuts.com/2022-start-stop-restart-postgres-redis-homebrew/) or learn how to access [table metadata](https://tinytechtuts.com/2022-get-column-names-and-types-postgres/) if that's more your cup of liquid iv.\n"},{"slug":"2022-pipe-to-function-with-multiple-arguments","category":"blog","title":"Pipe to function with multiple arguments","description":"How to pipe to a function with multiple arguments","tags":["elixir"],"body":"\nIn Elixir it is a common practice to use the pipe operator `|>` to express a series of steps needed to complete an operation. This allows us to define very readable workflows and makes for a cleaner codebase.\n\nWhen using this operator the data from each step will be included automatically as the first argument in the next step. \nIn the event you're only pipeing data to a function with one argument, that would look like this:\n```\npinteresting = %{\n  pumpkin: true,\n  snowfall: false,\n  apple: true,\n  pine_tree: false\n}\n\npinteresting |> Map.keys\n\n=> [:apple, :pine_tree, :pumpkin, :snowfall]\n```\n\nIn the above example `pinteresting` is passed as the first argument to `Map.keys/1` which only takes one argument. But what if we piped the data to a function that accepts multiple arguments? In this scenario it is already implied that the first argument will be the piped data, so when we pass our second argument to the function, it will read like it is the first argument. In the example below `%{coffee: true}` is actually the second argument being passed to `Map.merge/2` and `pinteresting` is the implied first argument:\n```\npinteresting |> Map.merge(%{coffee: true})\n=> %{apple: true, coffee: true, pine_tree: false, pumpkin: true, snowfall: false}\n```\n\n"},{"slug":"2022-pocket-reference-for-react-hocs","category":"blog","title":"A pocket reference for React HOCs (Higher Order Components)","description":"a reference guide to HOCs for React developers","tags":["react"],"body":"\nThis post aims to help those who have worked with and studied React Higher Order Components previously and want a quick brush up on key topics.\n\n<h4>At its most basic, what is a react HOC?</h4>\nA function that accepts a component as an argument and returns a new component \n\n<h4>What are you trying to accomplish by using a HOC?</h4>\nSharing state and behavior across like components.\n\n<h4>What is the name of the component being passing as a function parameter to the HOC?</h4>\nWrappedComponent. It’s called this because it’s literally wrapped in the HOC.\n\n<h4>HOC’s are a means of code reuse in react, what are some other forms of code reuse:</h4>\n- Components themselves\n- React Hooks"},{"slug":"2022-pocket-reference-for-react-hooks","category":"blog","title":"A pocket reference for React Hooks","description":"a reference guide to Hooks for React developers","tags":["react"],"body":"\nThis post aims to help those who have worked with and studied React Hooks previously and want a quick brush up on key topics.\n\n<h4>What type of component can make use of Hooks?</h4>\nFunction components\n\n<h4>Where can you use a hook inside of a component?</h4>\nHooks must always be used at the top level of a component and outside of any control structures.\n\n<h4>What to do if you need a useEffect hook to handle logic conditionally?</h4>\nPut the condition inside the hook and pass a callback function to the hook.\n\n<h4>Why do hooks need to be called in the same order each time?</h4>\nBecause this is how React keeps track of which state belongs to each useState hook. By keeping the order the same on each render React is able to associate some local state with each hook.\n\n<h4>When are useEffect hooks called?</h4>\nBy default they are called after every render, both the first render and on every DOM update.\n\n<h4>How do you handle side effect cleanup when using useEffect?</h4>\nSome side effects need to be cleaned up before a component is unmounted. To do this with useEffect, return a function from your useEffect hook, that function will be executed before the component is destroyed and you can handle any cleanup inside of it.\n\n<h4>What are a few examples of side effects you would want to handle inside a useEffect hook?</h4>\n- Making any network request.\n- Updating browser api attribute like document.title, which is [imperative](https://reactjs.org/docs/hooks-effect.html#example-using-hooks){:target=\"_blank}.\n- Handling any imperative updates, like the afore mentioned or file inputs.\n- Using setInterval and clearing the interval on unmount.\n"},{"slug":"2022-postgres-backslash-commands","category":"blog","title":"Postgres backslash commands","description":"List of postgres backslash commands","tags":["postgres"],"body":"\nWhen using PostgreSQL or any SQL database for that matter there are a number of useful commands you can use inside of the PostgreSQL terminal that begin with a backslash and are followed with one or two characters. This post is a non-exhaustive list explaining some of those commands.\n\nList all available databases:\n```\n\\l\n```\n\nQuit from terminal:\n```\n\\q\n```\n\nList all available tables in a database:\n```\n\\dt\n```\n\nRun the previously executed command:\n```\n\\g\n```\n\nList previously executed commands:\n```\n\\s\n```\n\nList of helpful postgres commands:\n```\n\\?\n```\n\nList all of the schemas of a database:\n```\n\\dn\n```\n\nList all functions:\n```\n\\df\n```\n\nList all of the tables views:\n```\n\\dv\n```\n\nLove databases more than your dog loves cheese? You might want to check out [this post](https://tinytechtuts.com/2022-pg_ctl-vs-psql/)."},{"slug":"2022-postgres-users-owners-privileges","category":"blog","title":"Postgres: users, owners, privileges","description":"learn about postgres users and privileges","tags":["postgres"],"body":"\nIn Postgres and similarly in other SQL databases users of a database have a certain level of access depending on the privileges set for the particular user. The reason you would want to have multiple users in a postgres table is to create different levels of access for each particular user. \n\nTo get a list of all users of a postgres database you will first need to access the database server using [psql](https://tinytechtuts.com/2022-pg_ctl-vs-psql/) and then you can run the command `\\du`, which will give you a list of users and the roles / privileges.\n\nThe different privileges that exist in postgres include:\nSELECT, INSERT, UPDATE, DELETE, TRUNCATE, REFERENCES, TRIGGER, CREATE, CONNECT, TEMPORARY, EXECUTE, and USAGE.\n\nTo add a role for a user you can use the GRANT keyword:\n```\nGRANT UPDATE ON reports TO ted.lasso;\n```\n\nTo remove a role from a user you can use the REVOKE keyword:\n```\nREVOKE UPDATE ON reports FROM ted.lasso;\n```\n\nAdding all privileges to a user defeats the purpose of creating a new user since the table owner aka Superuser will have the ability to do so. To change the owner of the table, you can use the following command:\n```\nALTER DATABASE dev_decks_dev OWNER TO ted.lasso;\n```\n\nTo create a new user for an existing database in postgres use the CREATE USER command like so:\n```\nCREATE USER new_user;\n```\n\nDo databases make you dancey? Maybe you'd enjoy dancing to the beat of [postgres stored procedures](https://tinytechtuts.com/2022-create-and-execute-stored-procedure-postgres/)."},{"slug":"2022-postgres-virtual-table","category":"blog","title":"Postgres: virtual table","description":"learn about virtual tables in postgres","tags":["postgres"],"body":"\nIn Postgres and other SQL databases there is the concept of a virtual table, you will see this arise when referring to another concept in SQL, a [view](https://tinytechtuts.com/2022-create-and-execute-db-view-postgres/). \n\nThe reason views are referred to as a virtual table is because they actually contain the rows and columns that the view created. So if a view returns a number of columns like first_name, last_name, email, etc. it will exist in basically the same form as an actual database table. \n"},{"slug":"2022-rails-integration-testing-cheatsheet","category":"blog","title":"Ruby on Rails integration testing cheatsheet","description":"rails integration testing","tags":["rails","testing"],"body":"\nThis particular guide uses Mocha for mocks and stubs, Minitest for the test framework, and FactoryBot for the test data. It is a brief summary of tips and examples I put together to help with producing integration tests.\n\n\n<h3>Mocks and Stubs using Mocha</h3>\n\nYou will notice other testing documentation online referring to various types of \"Test doubles\" you can use in your tests. These test doubles are replacement objects and behavior for actual objects defined in your application and many of the types build off of each other in terms of capability. Below is an overview of each type in increasing complexity:\n\n1. Dummy - This is the simplest form of test double. Used in tests when you just need a generic object, often implemented using `Object.new`.\n5. Fake - A fake object will largely mimic the applications implementation but will act as a replacement for something like an in-memory database.\n2. Stub - Used when you only want to produce a specific return value for an objects method. \n3. Spy - Records the number of times an Objects method was called, which can be used in a test expectation. It can also act as a stub and produce explicit return value.\n4. Mock - To use a mock object you need to declare how many times you expect a method to be invoked in advance and then verifies whether the expected number matches the actual number of invocations. It is the only type of double that enforces behavior verification. It can also act as a stub and produce explicit return value. \n\nThe Mocha library is used to implement two types of test doubles, stubs and mocks.\n\nBelow is an example mock from the [Mocha documentation](https://github.com/freerange/mocha). You can tell that it is a mock because it sets up an expectation before the additional `assert_equal` assertion by calling `Product.expects(:find)`, now the test will fail unless the find method is called on an instance of Product. It also implements stub behavior because we are returning an explicit product from a call to the method.\n\n```\ndef test_mocking_a_class_method\n  product = Product.new\n  Product.expects(:find).with(1).returns(product)\n  assert_equal product, Product.find(1)\nend\n```\n\nBelow is an example stub from the [Mocha documentation](https://github.com/freerange/mocha). You can tell it is a stub because it is not setting up any expectation around the number of times the stubbed method (in this case `:prices`) is invoked and it is returning an explicit object from a call to the stub.\n\n```\ndef test_stubbing_instance_methods_on_real_objects\n  prices = [stub(:pence => 1000), stub(:pence => 2000)]\n  product = Product.new\n  product.stubs(:prices).returns(prices)\n  assert_equal [1000, 2000], product.prices.collect {|p| p.pence}\nend\n```\n\nTip: If you are incurring the failure “expected to be called exactly once but was invoked 3 times” and you don't need to be explicit about the number of invocations for your tests accuracy try using the `.any_instance` method provided by mocha before setting the stub. In practice that looks like:\n\n```\naccount = Account.new\n\nSession.any_instance\n.stubs(:account)\n.returns(account)\n``` \n\nTip: If you are working with JavaScript and want an example on working with Jest [tests](https://tinytechtuts.com/2021-jest-testing-cheatsheet/) and [mocks](https://tinytechtuts.com/2021-mock-custom-react-hooks-with-jest/) I wrote previous on that [here](https://tinytechtuts.com/2021-jest-testing-cheatsheet/) and [here](https://tinytechtuts.com/2021-mock-custom-react-hooks-with-jest/)\n\n<h3>Making async controller requests</h3>\nTip: You can indicate that an HTTP request should be made asynchronously using the option `xhr: true`\n\n```\nget \"/application/integrations\", xhr: true\n```\n\n<h3>Setting session data for integration tests</h3>\n\nWhen I was first looking into integration testing I thought there might be a way for me to pass session data I needed as an argument to an HTTP GET request, like this:\n\n```\nget url, params: {}, session: {}\n```\n\nUnfortunately it is not that easy and simultaneously defeats the purpose of an integration test. Integration testing an endpoint in your Rails application means that whatever action sets that session data needs to take place within the test itself, so if the route requires a user to be logged into the application first, then the integration test should start off by logging in the user and then proceed to your specific endpoint.\n\n```\nit \"gets reports\" do\n  post(\n    \"https://myapp.com/user/session\",\n    params: {token: user.tokens.create()}\n  )\n  get \"https://myapp.com/user/reports\", xhr: true\n\n  assert_response 200\nend\n```\n\nYou may hear developers refer to bad tests that “aren’t really testing anything” even though the tests pass and the code coverage increases. This will happen when interactions that should be tested are bypassed, like I was looking to do with passing session data to the controller explicitly. This will often manifest itself in the form of excess stubs.\n\n<h3>Working with database transactions</h3>\n\nIf you’re using FactoryBot in your test suite configuration you should be using it to persist the data you need for your integration tests before the test is run. What follows is an example of defining a factory and then using it within a test file. The Factories must exist as data models within your application.\n\nThis factory defines a report object and two data attributes with default values `job_type` and `active`. \n\n```ruby\nFactoryBot.define do\n factory :report do\n   job_type{ \"recurring\" }\n   active{ true }\n end\nend\n```\n\nIn the test implementation call the `.create` method with the name of the factory you want to persist and optionally and data you want to override default values for. Another popular FactorBot method is `.build` which is called the same way as `.create` but instead of persisting the object it is just an object in memory.\n\n\n```ruby\nrequire \"test_helper\"\n\n class Api::ReportsControllerTest < ActionDispatch::IntegrationTest\n \n before do\n   10.times{\n     create(:report, active: false)\n   }\n end\n\n it \"gets reports\" do\n   post(\n     \"https://myapp.com/user/session\",\n     params: {token: user.tokens.create()}\n   )\n   get \"https://myapp.com/user/reports\", xhr: true\n   assert_response 200\n end\nend\n```\n\n<h3>Making requests external to your application</h3>\n\nThese can be microservices within your system or third party API’s that you interact with, in either event they should be stubbed and given an expected return value if relevant. The reason here is that your integration tests' success is independent of those external systems being up or down. You don’t want to try and push an urgent bug fix to production and then get stuck because your integration test is failing in your build pipeline at no fault of your own. There is also the danger of your test suite becoming too slow as your test suite gets larger or you unintentionally create bad data during the tests. \n\nTo stub HTTP calls you can either stub the method that issues the HTTP request or you can use a ruby HTTP stubbing library like [WebMock](https://github.com/bblimke/webmock).\n\nStubbing HTTP calls behaves the same as stubbing Object methods only instead of stubbing a method on an object you stub the URL, http method, headers, and parameters and optionally can ask for a specific return:\n\nFrom the webmock docs:\n```ruby\nstub_request(:post, \"www.example.com\").\n  with(body: /world$/, headers: {\"Content-Type\" => /image\\/.+/}).\n  to_return(body: \"abc\")\n```\n\nTip: For the stub to work the URL has to match exactly so make sure your query parameters and url path variables match exactly or the stub will not be set properly.\n\n\nSimilar posts:\n- [Same Database table parent/child relationship using Rails](https://tinytechtuts.com/2021-same-db-table-parent-child-relationship-rails)\n - [Rails nested resources completed example](https://tinytechtuts.com/2021-rails-nested-resources-mvc-complete-example)\n "},{"slug":"2022-random-date-generator","category":"blog","title":"Rails random date generator","description":"Learn how to generate random dates in Rails","tags":["rails"],"body":"\nTo generate random dates in Rails you can use the DateTime object and a random value to subtract from it. The following code byte will produce a random date in the last 4 weeks:\n\n```ruby\nDateTime.now - (rand * 28)\n```\n\nSo then to generate a random date within the last year you can use:\n\n```ruby\nDateTime.now - (rand * 365)\n```\n\n\n"},{"slug":"2022-random-element-from-elixir-list","category":"blog","title":"Get a random element from an Elixir List","description":"example of how to get a random element from a List","tags":["elixir"],"body":"\nIn order to complete this mission we will reach for the `Enum` module which has a function defined in it `random/1`. This function expects its single argument to be the enum passed to it, in this case an elixr `List`. Below is an example usage:\n\n```\niex(1)> list = [\"cat\", \"dog\", \"turtle\"]\n[\"cat\", \"dog\", \"turtle\"]\niex(2)> Enum.random(list)\n\"dog\"\n```"},{"slug":"2022-reading-force-casing-of-project","category":"blog","title":"Force casing of mix/elixir project module","description":"create a project name in all caps in elixir","tags":["elixir","mix"],"body":"\nBy default Elixir will create the new project module passed to the mix generate with the CamelCase format but if you want your project to have specific module casing (like uppercase) you can pass the --module flag to `mix.new`. That looks like this:\n\n```\nmix new dev_decks --module DEVDECKS\n```\n\nThe resulting project module:\n<image src=\"/images/blog/project-name-overrides-elixir.png\" alt=\"name-overrides\" />"},{"slug":"2022-reading-image-text-using-elixir","category":"blog","title":"Reading image text using Elixir","description":"Learn how to read text of an image using Elixirs OCR","tags":["elixir","ocr"],"body":"\nThis post will detail how you can read text off of an image using the Elixir programming language.\n\nTo handle this we will use a technology called Optical Character Recognition which is used to find printed or handwritten text characters inside of an image.\n\nThe steps we will take to complete this project are:\n\n1. Install the system package for tesseract (an OCR engine).\n2. Include the tesseract-ocr-elixir lib in your elixir dependencies.\n3. Test the library functionality using IEx.\n\n<h2> Important note before installation:</h2>\nIf you don't install the tesseract engine before trying to use the Elixir library tesseract-ocr-elixir you will likely be met with this error:\n\n```\niex(1)> TesseractOcr.read(\".lib/testocr.png\")\n\n** (ErlangError) Erlang error: :enoent\n\n    (elixir 1.12.0) lib/system.ex:1041: System.cmd(\"tesseract\", [\".lib/testocr.png\", \"stdout\"], [])\n\n    (tesseract_ocr 0.1.5) lib/tesseract_ocr.ex:19: TesseractOcr.read/2\n```\n\nThis error is letting you know you haven't installed tesseract, not that the file path is empty (which without reading the stacktrace you might suspect because of the :enoent eror).\n\nOnce you install tesseract this error should go away. You can see the system request to tesseract in the screenshot below:\n\nreplace_image_0_x\n\n<br />\n<h2>1. Installing Tesseract</h2>\n\nI use Homebrew to install system dependencies on my mac. So for me installing this library was straightforward:\n\n```\nbrew install tesseract\n```\n\nThe [tesseract website](https://tesseract-ocr.github.io/tessdoc/Installation.html) has more options for installation.\n\n<h2>2. Add tesseract-ocr-elixir lib to deps</h2>\n\nIn your mix application add the library tesseract-ocr-elixir to deps. This is an Elixir wrapper for OCR.\n\n```\ndef deps do\n  [\n    {:tesseract_ocr, \"~> 0.1.5\"}\n  ]\nend\n```\n\nRun `mix deps.get` to install the package.\n\n<h2>3. Test the library functionality</h2>\n\nTo do a quick test of the library you will need an image with text, so grab your favorite meme and then load your application using `iex -S mix`.\n\nNow you can test the library by the `read` function which will print out any words OCR finds:\n\n```\niex> TesseractOcr.read(\"test/resources/testocr.png\")\n\"OH YOU FOUND SOME INTERNET MEMES YOU MUST BE FUNNY\"\n```\n\nThat was the last step! You can also use the library to read PDFs and do other fun things.\n\n\n"},{"slug":"2022-reading-pdf-text-using-elixir","category":"blog","title":"Reading pdf text using Elixir","description":"Learn how to read text of an pdf using Elixirs OCR","tags":["elixir","ocr"],"body":"\nLet's say you want a use to be able to upload a PDF and then your system needs to understand what the text was in the PDF they uploaded, good news is there's an Elixir solution for that! It's OCR or Optical Character Recognition which is used to find printed or handwritten text characters inside of an [image](https://tinytechtuts.com/2022-reading-image-text-using-elixir/).\n\nTo quickly test how this works in Elixir we will take three steps:\n1. Install the binaries for tesseract (an OCR engine).\n2. Include the tesseract-ocr-elixir lib in your dependencies.\n3. Test the packages functionality using IEx.\n\n<h2>1. Installing Tesseract</h2>\n\nIf you're using a Mac you can install tesseract using Homebrew:\n\n```\nbrew install tesseract\n```\n\nIf not the [tesseract website](https://tesseract-ocr.github.io/tessdoc/Installation.html) has more options for installation.\n\n<h2>2. Add the tesseract-ocr-elixir lib to dependencies</h2>\n\nIn your application add the library tesseract-ocr-elixir to deps. This is an Elixir wrapper for OCR.\n\n```\ndef deps do\n  [\n    {:tesseract_ocr, \"~> 0.1.5\"}\n  ]\nend\n```\n\nTo install the new dependency run `mix deps.get`.\n\n<h2>3. Test the library functionality</h2>\n\nTo do a quick test run your application using `iex -S mix` or if you're using Phoenix `iex -S mix phx.server`.\n\nNow you can test the library by the `read` function which will print out any words OCR finds:\n\n```\niex> TesseractOcr.read(\"test/resources/testocr.pdf\")\n\"test pdf content\"\n```\n\n\n"},{"slug":"2022-remove-element-from-tuple-at-an-index","category":"blog","title":"How to remove an element from a tuple","description":"How to remove an element from a tuple in elixir","tags":["elixir"],"body":"\nIn a [previous example](https://tinytechtuts.com/2022-add-element-to-tuple-at-an-index/) we worked to add an element to a tuple at an index position. In this post we will handle the case of needing to remove that same element. \n\nFirst lets define the tuple. In the tuple below there is an item that doesn't match the string format of the rest of the elements, we'll remove that one.\n```\nfive_elem_tuple = {\"one\", \"one.five\", \"two\", \"three\", \"four\"}\n```\n\nTo handle the delete mechanism we will utilize the `Tuple.delete_at/2` function. This function accepts a tuple and an index position as arguments and returns a new tuple.\n```\nfive_elem_tuple = {\"one\", \"one.five\", \"two\", \"three\", \"four\"}\nfive_elem_tuple |> Tuple.delete_at(1)\n=> {\"one\", \"two\", \"three\", \"four\"}\n```\n\n"},{"slug":"2022-remove-multiple-key-value-pairs-from-map","category":"blog","title":"Elixir: remove multiple k/v pairs from a map","description":"How to remove multiple key value pairs from an elixir map","tags":["elixir"],"body":"\nIf you need to delete multiple entries in a map when using Elixir you can look at the `Map` module. On the `Map` module exists a function `drop/2`. The two arguments it takes are:\n1. A map to delete the entry from\n2. A list of keys to remove from the map\n \nIn practice that looks like this:\n```\niex(7)> map = %{k1: :v1, k2: :v2, k3: :v3}\n%{k1: :v1, k2: :v2, k3: :v3}\niex(8)> Map.drop(map, [:k2, :k1])\n%{k3: :v3}\n```\n\nIn the event you need to remove a single k/v pair there is a `delete` function on the `Map` module that can be utilized. I review that [here](https://tinytechtuts.com/2022-remove-multiple-key-value-pairs-from-map/)."},{"slug":"2022-remove-single-key-value-pair-from-map","category":"blog","title":"Elixir: remove a single k/v pair from a map","description":"How to remove a single key value pair from an elixir map","tags":["elixir"],"body":"\nWhen you need to delete a map entry in Elixir you can reach for the `Map` module. There is a function defined on the `Map` module called `delete/2`. The two arguments it takes are:\n\n1. A map to delete the entry from\n2. A key to remove from the map\n\nIn practice that looks like this:\n```\niex(3)> map = %{k1: :v1, k2: :v2}\n%{k1: :v1, k2: :v2}\niex(4)> Map.delete(map, :k2)\n%{k1: :v1}\n```\n\nNow if you need to remove multiple k/v pairs there is a `drop` function on the `Map` module that can be utilized. I review that [here](https://tinytechtuts.com/2022-remove-single-key-value-pair-from-map/).\n\n"},{"slug":"2022-rendering-a-collection-of-turbo-frames","category":"blog","title":"How to render a collection of turbo frames","description":"How to render a collection of turbo frames","tags":["rails","turbo"],"body":"\nThis is a code example of how to render a collection of Turbo Frames for inline editing within each frame. This is going to be a continuation from a previous post on [redering Turbo Frames within a form](https://tinytechtuts.com/2022-rendering-a-turbo-frame-inside-a-form/). \n\nTurbo Frames work by first rendering the html content within the frame and then if you click an internal link within a turbo frame it will make a network request to get new html that will replace the current contents of the frame. For this to happen a Turbo Frame with the same Turbo Frame ID needs to exist on both sides of the frame, later in this example that will see that as `name_frame_id`.\n\nTo handle this we will need to add an index action to the `OrdersController` that retrieves the orders collection from the database and an `edit_from_step` action to get the html contents of the other side of the Turbo Frame.\n\norders_controller.rb\n```ruby\nclass OrdersController < ApplicationController\n  def index\n    @orders = Order.all\n  end\n\n  def edit_from_step\n    @order = @order\n    @step = params[:step_id]\n\n    render :edit\n  end\nend\n```\n\nAnd then in the html template we will iterate over the list of orders and render a Turbo Frame partial for each order. In the partial there is a link to the `edit_from_step` path, which when clicked will execute an async request to get the html returned from that request and replace our current from contents with the new frame contents. So in this example the contents of the frame in `_order.html.erb` will be replaced with matching turbo frame contents of `_step_(step_id).html.erb`. \n\nIn this example the html at `_step_(step_id).html.erb` contains a form within the frame to edit the contents previously displayed by the frame before clicking the link, which can be used for inline editing.\n\nindex.html.erb\n```ruby\n<div id=\"orders\">\n  <% @orders.each_with_index do |order, index| %>\n    <%= render partial: \"order\", locals: { index: index, order: order }  %>\n  <% end %>\n</div>\n```\n\n_order.html.erb\n```ruby\n<% name_frame_id = dom_id(order, \"name\") %>\n<%= turbo_frame_tag name_frame_id, data: { turbo_frame: name_frame_id } do %>\n  <h3>NAME</h3>\n  <div><%= order.name %></div>\n  <%= link_to \"Edit Name\", edit_from_step_path(order, 1) %>\n  <br/>\n<% end %>\n\n<% toppings_frame_id = dom_id(order, \"toppings\") %>\n<%= turbo_frame_tag toppings_frame_id, data: { turbo_frame: toppings_frame_id } do %>\n  <h3>TOPPINGS</h3>\n  <% order.toppings.each do |topping| %>\n    <p><%= topping %></p>\n  <% end %>\n  <%= link_to \"Edit Toppings\", edit_from_step_path(order, 2) %>\n  <br />\n<% end %>\n```\n\nedit.html.erb\n```ruby\n<%= render partial: \"orders/separate_form_partials/_step_#{@step ? @step : order.step}\", locals: { order: @order } %>\n```\n\norders/separate_form_partials/_step_1.html.erb\n```ruby\n<h1>Name</h1>\n<% name_frame_id = dom_id(order, \"name\") %>\n<%= turbo_frame_tag name_frame_id, data: { turbo_frame: name_frame_id } do %>\n  <%= form_with(model: order) do |form| %>\n    <% if order.errors.any? %>\n      <div style=\"color: red\">\n        <h2><%= pluralize(order.errors.count, \"error\") %> prohibited this order from being saved:</h2>\n\n        <ul>\n          <% order.errors.each do |error| %>\n            <li><%= error.full_message %></li>\n          <% end %>\n        </ul>\n      </div>\n    <% end %>\n\n    <%= form.text_field :name %>\n    <%= form.submit \"Continue Order\" %>\n  <% end %>\n<% end %>\n```\n\n\n\n"},{"slug":"2022-rendering-a-turbo-frame-inside-a-form","category":"blog","title":"How to render turbo frames within a multi-part form","description":"How to render turbo frames within a multi-part form","tags":["rails","turbo"],"body":"\nThis is a code example of how to render a Turbo Frame within an html form. This is going to be an application that handles orders. You will need to generate an application and create the orders controller and order model. This was the command I used to generate this application, it uses esbuild for javascript and tailwind for the css. This is an example application I built to get exposure to Turbo.\n\n```ruby\nrails new kitchen -j esbuild --css tailwind\n```\n\nThe application functionality this examples is a multi-part form, which will show a new turbo frame for each step of the order the user has progressed to.\n\nThis is what my migration change method looked like for the orders model:\n```ruby\ndef change\n  create_table :orders do |t|\n    t.string :name\n    t.json :toppings, array: true, default: []\n    t.integer :step, default: 1\n\n    t.timestamps\n  end\nend\n```\n\nThen add a standard rails route and controller action to handle the incoming request that will render the html with the turbo frame(s).\n\nroutes.rb\n```ruby\nRails.application.routes.draw do\n  resources :orders\nend\n```\n\nOne thing to call out in the controller is on every update we redirect to the edit route so that the user can continue to fill out the multi-part form, until they hit the end of the steps in the form.\n\norders_controller.rb\n```ruby\nclass OrdersController < ApplicationController\n  before_action :set_order, only: %i[ edit ]\n\n  def edit\n  end\n\n  def update\n    order = @order.update(order_params)\n\n    if @order.step == 2\n      return head :ok\n    end\n\n    respond_to do |format|\n      if order\n        format.html { redirect_to edit_order_path(@order), notice: \"Order was successfully updated.\" }\n        format.json { render :show, status: :ok, location: @order }\n      else\n        format.html { render :edit, status: :unprocessable_entity }\n        format.json { render json: @order.errors, status: :unprocessable_entity }\n      end\n    end\n  end\n\n  def set_order\n      @order = Order.find(params[:id])\n  end\nend\n```\n\nBelow is the orders model, which contains some hard coded data we will use in our template to render html options for checkboxes. Remember this is an example application, the data for TOPPINGS and EXTRAS should really be stored in a database.\n\nThis model also contains a callback to increment each step on update. The `order#step` will be used to dyamically render the correct partial for the mutlti-step form.\n\norder.rb\n```ruby\nclass Order < ApplicationRecord\n  TOPPINGS = [\"perpperoni\", \"sausage\", \"red onion\", \"banana peppers\", \"anchovies\"]\n  EXTRAS = [\"extra cheese\", \"brownie\", \"breadsticks\"]\n\n  before_update :increment_step\n\n  private\n\n  def increment_step\n    return if step == 2\n\n    self.step = step + 1\n  end\nend\n```\n\nThen in the edit template render the form partial for order while passing in a local order variable:\n\n```ruby\n<%= render partial: \"form\", locals: { order: @order } %>\n```\n\nThis is the standard scaffolded form for the orders views, but within it there is rendered, step. Based off of the step of the process the order is in, we will render a differ turbo frame within the form.\n\n```ruby\n<%= form_with(model: order) do |form| %>\n  <% if order.errors.any? %>\n    <div style=\"color: red\">\n      <h2><%= pluralize(order.errors.count, \"error\") %> prohibited this order from being saved:</h2>\n\n      <ul>\n        <% order.errors.each do |error| %>\n          <li><%= error.full_message %></li>\n        <% end %>\n      </ul>\n    </div>\n  <% end %>\n\n  <%= render partial: \"orders/steps/step_#{@step ? @step : order.step}\", locals: { order: order, form: form } %>\n<% end %>\n```\n\nWhat follows are examples of two the step partials. In each of the individual partials we do a few things:\n1. Create a turbo frame using the `turbo_frame_tag` method.\n2. Create a unique id for the tag using the `dom_id` method and passing it arguments of `order` and the attribute on the order this specific tag is associate with, `\"name\"`. Pass the resulting value as the first argument to `turbo_frame_tag`. \n3. The html input for the part of the order the frame is associated with and a submit button (this could also be a partial).\n\nIt will be used by rails to make sure it is both grabbing the correct html on the other side of the turbo frame and then again use it to populate the html reponse within the correct frame.\n\n/views/orders/partials/steps/step_1.rb\n\nStep 1\n```ruby\n<h1>Name</h1>\n<% name_frame_id = dom_id(order, \"name\") %>\n<%= turbo_frame_tag name_frame_id, data: { turbo_frame: name_frame_id } do %>\n  <%= form.text_field :name %>\n  <%= form.submit \"Continue Order\" %>\n<% end %>\n```\n\n/views/orders/partials/steps/step_2.rb\n\nStep 2\n```ruby\n<h1>Toppings</h1>\n<% toppings_frame_id = dom_id(order, \"toppings\") %>\n<%= turbo_frame_tag toppings_frame_id, data: { turbo_frame: toppings_frame_id } do %>\n  <% Order::TOPPINGS.each do |topping| %>\n    <br />\n    <%= form.check_box :toppings, {multiple: true}, topping, false %>\n    <%= form.label topping %>\n  <% end %>\n  <%= form.submit \"Continue Order\" %>\n<% end %>\n```\n\nNow when you submit each form it will hit the update action in the controller async using Turbo Drive and redirect you to the edit path as long as the order still has steps to complete (in this example we stop the steps at 2). \n\nFurther reading:\n- [How to replace the contents of a string in Ruby](https://tinytechtuts.com/2022-how-to-replace-string-content-in-ruby/)\n"},{"slug":"2022-rendering-liveview-template-outside-of-router","category":"blog","title":"Rendering a LiveView template outside of router","description":"How to conditionally render a LiveView template outside of application router","tags":["liveview","elixir"],"body":"\nThis post assumes you have already developed your LiveView code and need a way to render the markup from your template in a different view. In this example that functionality ended up being for a modal that I wanted to render on different pages. \n\nIn your applications Web module, in my case `DevDecksWeb` you need to include an import for LiveView helpers, to get access to the function we will need, `live_render`:\n```\nimport Phoenix.LiveView.Helpers\n```\n\nIf you're using the Phoenix application development framework this will be imported when you generate your application.\n\nOnce this is imported you can call `live_render` in your template like so and pass it the `@socket` and your LiveView module `DevDecksWeb.EmailModalLive`:\n\n```\n<%= live_render(@socket, DevDecksWeb.EmailModalLive) %>\n```\n\nAnd if you need to conditionally render the template based off of some state you can do so with a single line conditional:\n```\n<%= if @show_modal do live_render(@socket, DevDecksWeb.EmailModalLive) end %>\n```\n"},{"slug":"2022-role-vs-user-vs-priviledge-postgres","category":"blog","title":"Postgres: role vs user vs privilege","description":"learn about roles, users, and privileges in postgres","tags":["postgres"],"body":"\nIn relational databases like postgres you will see the term “role” mentioned frequently and you might think “that sounds an awful lot like what I know to be a user”. That’s because in SQL a role acts exactly how a user of a web application would act. One notable difference is that a role can apply to either a single user or a group of users, depending on the context it is used. Roles have certain access rights, just like a user within a web application would have certain access rights. To learn more about altering a roles access level, check out [this post](https://tinytechtuts.com/2022-create-and-execute-stored-procedure-postgres/) on the topic.\n\nIn a database system like postgres a role is considered an entity that has ownership rights of certain database objects, such as a table or database itself. Privileges are access rights given to a particular role. You can query for a given roles privileges by using the `\\du` command inside of postgres which will display a table of roles and their associated privileges.\n\n\n"},{"slug":"2022-ruby-0..-2-explained","category":"blog","title":"Ruby [0..-2] explained","description":"Ruby [0..-2] range in an array explained","tags":["ruby"],"body":"\nWhen programming in Ruby you will sometimes see this code being run against an array or string [0..-1] or [0..-2], this is saying give me all the characters or the string or elements of the array that exist in this range. In ruby a negative index in a range means X from last with -1 one referencing the last item in the array or string.\n\nThis is best illustrated through a few examples. In the one below we use the negative integer to get the last item from a string and array and then we do the same thing but to get the second to last element from a string or array:\n\n```ruby\n\"string\"[-1]\n=> \"g\"\n\n\"string\"[-2]\n=> \"n\"\n``` \n\nSo then if we pass a range to a string or array we are saying \"give me everything in this range returned as a new array or string\". So if the range is 0..-1 that means give me the first element through the last (the entire element) and if we use 0..-2 it means give me the first element up to the second to last. Below are the examples in code:\n\n```\n\"string\"[0..-1]\n=> \"string\"\n\n\"string\"[0..-2]\n=> \"strin\"\n``` \n"},{"slug":"2022-ruby-hash-string-keys-to-symbol","category":"blog","title":"Convert ruby hash with string keys to symbol keys","description":"How to convert ruby hash with string keys to symbol keys","tags":["ruby"],"body":"\nIf you have a ruby hash with string / arrow keys like so:\n\n```ruby\n{\n  \"key1\" => \"val1\",\n  \"key2\" => \"val2\"\n}\n```\n\nBut you want the hash to have symbol keys, you can use the `transform_keys` method:\n\n```ruby\n{\n  \"key1\" => \"val1\",\n  \"key2\" => \"val2\"\n}.transform_keys(&:to_sym)\n\n=> {:key1=>\"val1\", :key2=>\"val2\"}\n```\n\n\nFurther reading:\n- [An example of when to expire a cache key](https://tinytechtuts.com/2021-example-of-when-to-expire-cache-key/)\n\n\n"},{"slug":"2022-ruby-keep_if-and-delete_if","category":"blog","title":"Ruby keep_if and delete_if methods","description":"Remove item from array if condition is met, ruby","tags":["ruby"],"body":"\nIn the situation where you need to remove an item from a collection based on a condition, you can use the `Array#delete_if` or `Hash#delete_if` methods.\n\n```ruby\nhash = {title: \"Awesome Possum\", count: 43}\nhash.delete_if {|key, value| key == :count }\n=> {:title=>\"Awesome Possum\"}\n\narray = [2, 3 ,4, 6, 7]\narray.delete_if {|int| int.even? }\n=> [3, 7]\n```\n\nAnother situation you are likely to encounter on your journey as a Ruby Programmer is the need to only keep items in a collection if a condition is met. For this you can use the `Array#keep_if` or `Hash##keep_if` methods.\n\n```ruby\nhash = {title: \"Awesome Possum\", count: 43}\nhash.keep_if {|key, value| key == :count }\n=> {:count=>43}\n\narray = [2, 3 ,4, 6, 7]\narray.keep_if {|int| int.even? }\n=> [2, 4, 6]\n```\n\n...\n\nSince you seem like keeping things, why not keep on reading with this ruby post on [\nHow to add a guard to a block in Ruby](https://tinytechtuts.com/2022-adding-a-guard-to-a-block/)?\n\n"},{"slug":"2022-running-two-git-branches-locally","category":"blog","title":"How to run two different git branches locally","description":"How to run two different git branches locally","tags":["git"],"body":"\nTo handle this you will need to use a git worktree. This will create a new directory in your local system that has the same git tracking information.\n\nTo accomplish this execute `git worktree add` and pass it the name of the directory and branch name (in that order). \n\n```\ngit worktree add ../new-directory branch-name\n```\n\nLater when you need to remove that worktree you can use the command `git worktree prune` from your original directory (not the newly created directory) which will remove the worktree, or you can use `git worktree remove path-to-worktree`.\n"},{"slug":"2022-set-a-primary-key-ecto","category":"blog","title":"How to set a DB primary key using Ecto","description":"set a DB primary key using Ecto","tags":["elixir","ecto"],"body":"\nWhen you use Ecto to manage your database(s) by default it will assume you want to use a primary key of `:id` for each of the tables you create.\nSometimes you will want to use a different primary key. Maybe you want to use a :uuid scheme instead. Whichever the reason, you can override this behavior by passing a keyword option of `primary_key: true` to your migration file. Example:\n\n```\nfield :store_uuid, :uuid, primary_key: true \n```\n\nI also wrote another post on DB [primary keys in Rails](https://tinytechtuts.com/2021-creating-a-table-with-different-primary-key-rails/) if it helps clear things up you're still uncertain about.\n"},{"slug":"2022-set-default-state-elixir-genserver","category":"blog","title":"How to set default state for a GenServer","description":"Learn how to set default state for a GenServer","tags":["elixir"],"body":"\nWhen you write a GenServer you will in almost every use case run it as a supervised process to get the added benefit Supervisors provide, fault tolerance.\n\n\n\nTo set the initial state for your supervised GenServer process you will need to make sure you have a `start_link` function defined in your GenServer that makes another call to the GenServer `init` callback. That is outlined below with function comments for additional context:\n\n\n\nlib/server.ex\n```\ndefmodule CacheServer.Server do\n  use GenServer\n  GenServer is passed as a child to\n\n  def start_link(initial_state) do\n    GenServer.start_link(__MODULE__, initial_state, name: Cache)\n  end\n\n  @impl true\n  def init(cache_store) do\n    {:ok, cache_store}\n  end\nend\n```\n\nNow that you’ve seen the functions that need to be defined in order to start your process. Navigate to your `application.ex` file. In the `children` list is where you will start all your genservers for your application. There are a couple of different ways you can format the tuple in the `children` list but below we optioned to pass the GenServer name and the initial state, in this case `%{a: :b}`. This will be passed to the `start_link` function we referenced above.\n\n\nlib/application.ex\n```\ndefmodule CacheServer.Application do\n  @moduledoc false\n  use Application\n\n  @impl true\n  def start(_type, _args) do\n    children = [\n      start_link(arg)\n      {CacheServer.Server, %{a: :b}}\n    ]\n\n    opts = [strategy: :one_for_one, name: CacheServer.Supervisor]\n    Supervisor.start_link(children, opts)\n  end\nend\n```"},{"slug":"2022-set-defaultprops-and-proptypes-functional-vs-class-component","category":"blog","title":"Setting defaultProps and propTypes in a functional vs a class component","description":"How to set defaultProps and propTypes in a functional vs a class component","tags":["react"],"body":"\nWhen defining our React components, if those components receive props then we need to declare what type of data those props are going to exist as and also give them default values when relevant. This will be different depending on if the component you are building is a functional or a class based component.\n\n<h3>Class component propTypes and defaultProps</h3>\nIn a class based component the defaultProps and propTypes will be set within the the component itself:\n\n```javascript\nexport default class Header extends Component {\n  static propTypes = {\n    // data definition\n  }\n  static defaultProps = {\n    // default data\n  }\n}\n```\n\n<h3>Functional component propTypes and defaultProps</h3>\nIn a functional component the propTypes and defaultProps will be set on the function outside of the function definition.\n\n```javascript\nfunction Header({...props}) {\n  return (\n    <>\n  )\n}\n\nHeader.propTypes = {\n  // data definition\n};\nHeader.defaultProps = {\n  // default data\n};\n\nexport default Header;\n```\n\nAre you also interested in learning how to set state based on the value of a URL in React? If so it's [your lucky day](https://tinytechtuts.com/2021-how-to-set-state-from-url-in-react/). If not, [space ham](https://giphy.com/gifs/space-ham-juDuRdAjXoH9m)."},{"slug":"2022-setting-asdf-package-versions","category":"blog","title":"Setting asdf package versions","description":"How to set asdf package versions","tags":["asdf"],"body":"\nThere a few different options you have when setting a package version in ASDF.\n\n1. You can set a version locally using a .tool-versions file\n2. You can set a version globally using a .tool-versions file\n3. You can set a version locally using an asdf command \n4. You can set a version globally using an asdf command \n\nIf you want to specify a local package version using a .tool-versions file, you will need to create the file at the root of your project directory and then list the packages you want to use for that project in the file.\n\n```\ntouch .tool-versions\n```\n\nAnd then in the file add packages, ex:\n\n```\nnodejs 14.11.0\nruby 2.7.1\n```\n\nIf you want to specify default packages for your computer you can create at your .tool-versions file at the user root directory and specify packages there. These packages will be overridden in any project specific (local) .tool-versions file.\n\nYou can also set package versions through the command line using the commands:\n```\nasdf local package_name version\nasdf global package_name version\n```"},{"slug":"2022-sort-list-of-maps-by-key","category":"blog","title":"Sort a list of maps by key value","description":"sort elixir list of maps based on property","tags":["elixir"],"body":"\nSuppose you have a list of maps that you need to sort by a specific key in each of the maps, you can do so using elixir’s Enum module, `Enum.sort_by/3`. \n\nThis function requires an enum and callback function and optionally accepts a third sorter argument, like `:asc` and `:desc`. The sorter will use :asc by default.\n\nThe callback function passed to the argument needs to return the value that is being sorted on and `sort_by` will do the rest.\n\nTo sort by one key in ascending order:\n```\nl = [%{payment: 34, tip: 5}, %{payment: 21, tip: 6}, %{payment: 10, tip: 5}]\n\nEnum.sort_by(l, fn(li) -> li.payment end)\n=> [%{payment: 10, tip: 5}, %{payment: 21, tip: 6}, %{payment: 34, tip: 5}]\n```\n\nTo sort by one key in descending order:\n```\nl = [%{payment: 34, tip: 5}, %{payment: 34, tip: 4}, %{payment: 21, tip: 7}, %{payment: 21, tip: 6}, %{payment: 10, tip: 5}]\n\nEnum.sort_by(l, fn(li) -> li.payment end, :desc)\n=> [%{payment: 34, tip: 5}, %{payment: 21, tip: 6}, %{payment: 10, tip: 5}]\n```\n\nTo sort by multiple keys, return a tuple from the callback function:\n```\nl = [\n  %{payment: 34, tip: 5},\n  %{payment: 34, tip: 4},\n  %{payment: 21, tip: 7},\n  %{payment: 21, tip: 6},\n  %{payment: 10, tip: 5}\n]\n\nEnum.sort_by(l, fn(li) -> {li.payment, li.tip } end)\n=> [\n  %{payment: 10, tip: 5},\n  %{payment: 21, tip: 6},\n  %{payment: 21, tip: 7},\n  %{payment: 34, tip: 4},\n  %{payment: 34, tip: 5}\n]\n```\n\nIf you enjoyed this elixir post you might also enjoy [Reading pdf text using Elixir](http://www.devdecks.io/2022-reading-pdf-text-using-elixir)"},{"slug":"2022-sql-inner-join-not-returning-records","category":"blog","title":"SQL inner join not returning records","description":"SQL inner join not returning records","tags":["sql"],"body":"\nAn inner join query is not returning any records for a table but you know there are records for the query in at least one of the tables and you want those records with null values being used for columns without data.\n\nIn this scenario you need to use an outer join, either a left outer join or a right outer join. It will accomplish exactly that, it will get all the data from the table running the join and it will provide null values for all of the columns that don't have data on the table being joined.\n\n\nFurther reading:\n- [Retroactively add timestamps to a Phoenix/Ecto project](https://tinytechtuts.com/2021-retroactively-add-timestamps-in-phoenix-ecto/)\n\n\n"},{"slug":"2022-sql-timeout-ordering","category":"blog","title":"SQL timeout from ordering","description":"Solve SQL timeout from ordering issue","tags":["sql"],"body":"\nThis example is in reference to the following technical problem:\n\nAn http request to your app requires querying the database and returning those records as JSON. I will be speaking to this issue with that reference in mind.\n\nIf you're querying for a set of records, say 1000 records in a single table and need to order them differently than asc/desc on ID or created_at, then you may encounter a gateway timeout in the query with a table with many records.\n\nFor example if you wanted to order a set of records on updated_at, and there are millions of rows in the table, then sql might need to look through millions of records for each time it places a next record in order. This can take a long time.\n\nTo help solve this issue it is best to add an index to the table on the column being queried.\n\nBe wary of any additional querying / app processing occurring after your query is returned because if it's a long running query then any additional processing time can also lead to your http connection timing out.\n\nFurther reading:\n- [Retroactively add timestamps to a Phoenix/Ecto project](https://tinytechtuts.com/2021-retroactively-add-timestamps-in-phoenix-ecto/)\n\n\n"},{"slug":"2022-start-stop-restart-postgres-redis-homebrew","category":"blog","title":"How to start, stop, and restart Redis or Postgres using Homebrew","description":"Learn how to start, stop, and restart Redis or Postgres using Homebrew","tags":["homebrew","postgres","redis"],"body":"\nIn the past I've had to look this up a couple of times and it took me longer than I would have liked to find the answer, so I hope this post can cut down on that time for you now and future me.\n\nAfter you’ve installed Homebrew you will have access to a `brew services` command for relevant packages. This command is for background services like in this case, database applications. \n\nTo start either of the titled services you can use the following commands:\n\nStart Postgres or Redis:\n```\nbrew services start redis\n\nbrew services start postgresql\n```\n\nIf you need to restart these services for any reason you can do so using these commands:\n\nRestart Postgres or Redis:\n```\nbrew services restart redis\n\nbrew services restart postgresql\n```\n\nAnd may you need to stop any of these background processes you can through these commands:\n\nStop Postgres or Redis:\n```\nbrew services kill redis\n\nbrew services kill postgresql\n```\n\nIf you're looking for more Postgres configuration fun, I've got the article of your desires: [How to use a ConfigMap file for postgres environment variables in Kubernetes](https://tinytechtuts.com/2021-how-to-use-a-configmap-file-for-postgres-url-kubernetes/).\n\n"},{"slug":"2022-system-auth-in-software-engineering","category":"blog","title":"Handling system authentication in software engineering","description":"different types of system authentication in software engineering","tags":["auth"],"body":"\nIn this post I hope to shed some light on authentication in software engineering. This post is starting out as a system to system authentication post, but I may revisit this to add end user authentication notes as well.\n\n<h2>System to system authentication:</h2>\nAny time you're trying to understand an authentication mechanism, it is fundamental to identify which interactions need to take place and on behalf of who. In the case of system to system auth I like to think of this as either \"a system acting on behalf of itself\" or \"a system acting on behalf of its client\". An example of the second type might be a SAAS system that has multiple organizations and the system is sending a request on behalf of that organization, usually as part of an integration.\n\n<h2>System acting on behalf of itself</h2>\nYou can think of this type of authentication as the root of authentication. This level won't give you access to individual client information, but rather let you do things like set configuration data for an integration that will be relevant to *all* clients. In this scenario the system we are communicating with only needs to know that we are the application we say we are.\n\nThese credentials are usually stored as environment variables within your application. Possibly as a token or a username/password combination:\n\n```\nENV[\"INTEGRATION_PARTNER_1_TOKEN\"]\n\nENV[\"INTEGRATION_PARTNER_2_USERNAME\"]\nENV[\"INTEGRATION_PARTNER_2_PASSWORD\"]\n```\n\n<h2>System acting on behalf of a client</h2>\nLet's say we create an integration with another company's system and now have multiple clients utilizing that system, we need to know how to identify which clients to send data back to or retrieve data from. There are a few different ways of handling this but one might be to store a config option for each client called `partner_username` and `partner_password` as columns in your database. These would be values you obtain from the client prior to kicking off the integration and can either be used to directly authenticate the client, or in exchange for a short lived token that you would then use when making requests. \n\nLikewise if a system needs to authenticate against your application for a specific client you will need a way to store and validate that data, `partner_incoming_username` and `partner_incoming_password` could be additional columns in your database to handle this information.\n\nIt should be noted that you won't always need both a `username` and `password` for this, sometimes you will only be provided one or the other.\n\n\nFurther reading:\n- [Ruby on Rails integration testing cheatsheet](https://tinytechtuts.com/2022-rails-integration-testing-cheatsheet/)"},{"slug":"2022-trim-spaces-vscode","category":"blog","title":"Trim trailing spaces using VScode","description":"setup vscode to trim spaces","tags":["vscode"],"body":"\nTo achieve this desired outcome, first install the trailing spaces extension.\n\nAfter that is installed, open VScode commands (mac shortcut I use is cmd+shift+p) and navigate to Preferences: Open User Settings. When you select this a settings.json file will be displayed.\n\nAdd this to the object:\n```\n\"trailing-spaces.trimOnSave\": true\n```\n\nOr if this is your first update to the file create the whole object:\n```\n{\"trailing-spaces.trimOnSave\": true}\n```\n\nNow all that's left to do is give it a try. \n"},{"slug":"2022-two-colons-before-a-class-name-ruby","category":"blog","title":"Two colons before a class name in ruby","description":"Two colons before a class name ruby","tags":["ruby"],"body":"\nWhen you see two colons before a constant reference in Ruby, like `::User` that code is saying “look for this constant” defined without any namespace or nesting.\n\nIt will not look up Admin::User even if you make a reference to `::User` from within the admin namespace.\n\nFurther reading:\n- [How to render a collection of turbo frames](https://tinytechtuts.com/2022-rendering-a-collection-of-turbo-frames/)\n\n\n"},{"slug":"2022-update-keyboard-shortcuts-vscode","category":"blog","title":"How to update keyboard shortcuts in VScode","description":"update vscode shortcuts","tags":["vscode"],"body":"\nIf you need to update your shortcuts in VScode first open the command palette, on a mac you can do this through `cmd+shift+p`. This is not to be confused with your [user settings](https://tinytechtuts.com/2022-trim-spaces-vscode/) file.\n\nNext type \"Open Keyboard Shortcuts\" and select it. This will open a JSON configuration file that you can paste your shortcuts in. Each configuration object has at two keys \"key\" and \"command\" which are fairly self explanatory and here is an example for reference:\n\n```\n[\n  {\n    \"key\": \"alt+x\",\n    \"command\": \"editor.action.selectToBracket\"\n  },\n  {\n    \"key\": \"cmd+k\",\n    \"command\": \"workbench.files.action.collapseExplorerFolders\"\n  }\n]\n```\n"},{"slug":"2022-update-npm-asdf","category":"blog","title":"Update NPM when using ASDF","description":"How to update npm is you're using asdf","tags":["npm","asdf"],"body":"\nTo be able to updated NPM first make sure node is installed and added to your tool-versions or set a local / global version of nodejs.\n\nYou can set a version locally using:\n```\nasdf local package version\n```\n\nOr globally through:\n```\nasdf global package version\n```\n\nYou can validate that npm and nodes are being run by asdf by running the command:\n```\nwhich npm\n```\n\nAnd that will print the working directory of the executable, which should have asdf in the path if you’re using npm through asdf. Something like:\n```\n/Users/user/.asdf/shims/npm\n```\n\nIf you have nodejs installed through asdf and a version set, you can then install a different version of npm with the `npm install` command:\n```\nnpm install -g npm@8.3.0\n```\n\nAfter that completes you will want to reshim:\n```\nasdf reshim\n```\n\nNo you should be ready to work.\n"},{"slug":"2022-update-what-ecto-considers-empty","category":"blog","title":"Update what Ecto considers nil / empty","description":"use changesets to update empty values","tags":["elixir","ecto"],"body":"\nThe Ecto library ships with a Changeset module to assist with make changes to our database safely. Out of the box the `cast/4` will consider blank strings and `nil` to be empty values. You can add to the list of values the changeset will consider empty using the `empty_values:` option. In practice that looks like:\n\n```\nparams = %{\"title\" => \"Movie Review\", \"author\" => \"NULL\"}\n\nchangeset = cast(%Post{}, params, [:title, :author], empty_values: [\"\", \"NULL\"]) \n\nchangeset.changes\n#=> %{title: \"Movie Review\"} \n```\n\nIn this example we added \"NULL\" to the empty values list and when we casted params the \"author\" key matched the \"NULL\" value so it was filtered out.\n"},{"slug":"2022-use-hardcoded-db-url-in-phoenix","category":"blog","title":"Using a hardcoded DB url in Phoenix","description":"how to use a db url in phoenix","tags":["elixir","phoenix"],"body":"\nWhen configuring a database connection, we usually supply values to the various keyword list elements in our config file like so:\n\n```\nconfig :store_db, Store.Repo, \ndatabase: \"store_db\", \nusername: \"postgres\", \npassword: \"postgres\", \nhostname: \"localhost\" \n```\nThese values are used to generate the url string we will use to authenticate and connect to the database. Alternatively if you want to explicitly set a hardcoded database url string you can do that as well. The example below uses the keywords to show which part of the url string maps to which keyword.\n\n\"postgres://username:password@hostname/db_name\"\n\nUsing our example above this would evaluate to:\n\n\"postgres://postgres:postgres@localhost/store_db\"\n\nAnd we can use that string in our config file like this:\n```\nconfig :music_db, MusicDB.Repo,\nurl: \"postgres://postgres:postgres@localhost/store_db\"\n```\n\nIf you enjoyed this post you may also enjoy [Postgres: create and execute database view](https://tinytechtuts.com/2022-create-and-execute-db-view-postgres/)"},{"slug":"2022-validate-string-length-using-ecto","category":"blog","title":"Validate string length using Ecto","description":"How to validate string length using Ecto","tags":["elixir","ecto"],"body":"\nAs a quick refresher, the Ecto library comes with a Changeset module to aid in making changes to our database safely. Many of the functions that you have access to are validation functions to ensure your data is formatted properly. \n\nOne of the validation functions `Ecto.Changeset` ships with is `validate_length/3`. This function accepts three arguments:\n1. A changeset\n2. The field to validate the length of\n3. Options (like `min:` and `max:`)\n\nThese functions are typically piped to after casting your parameters and creating a changeset. A typical implementation looks like this:\n\n```\nparams = %{\"title\" => \"Walking by Henry David Thoreau\"} \n\nchangeset =\t\t\t\t\t\n%Post{}\n|> cast(params, [:title])\n|> validate_length(:title, min: 5) \n```\n\nIn the above implementation we validated that the \"title\" key's value had at least 5 characters. We can also validate that it doesn't have more than X characters, below we validate that the title is no more than 30 characters:\n\n```\nparams = %{\"title\" => \"Walking by Henry David Thoreau\"} \n\nchangeset =\t\t\t\t\t\n%Post{}\n|> cast(params, [:title])\n|> validate_length(:title, max: 30) \n```\n"},{"slug":"2022-validating-string-is-a-url","category":"blog","title":"Validating a string is a URL in Rails","description":"Learn how to validate that a string is a URL in Rails","tags":["rails"],"body":"\nTried for a while to find a good example of this in Rails and ultimately came up with the following code:\n\n```ruby\n  validates :url,\n    allow_nil: true,\n    format: { :with => URI::regexp(%w(https)), :message => \"URL must be HTTPS\"}\n```\n\nThis ActiveRecord validation will use the Kernels URI::regexp to check for a regex match on the URL string for https, if the check fails an error will be returned on the object along with the message provided. If you need to validate for for both http and https you can pass an array to the regex:\n\n```ruby\nURI::regexp(%w([http, https])\n```\n\nFurther reading:\n- [Create a custom Mix task by example](https://tinytechtuts.com/2021-create-a-custom-mix-task-by-example/)\n\n"},{"slug":"2022-value-present-and-not-blank-string-javascript","category":"blog","title":"Check if a value is present and is not a blank string on one line in JavaScript","description":"JavaScript one line value present and not blank","tags":["javascript"],"body":"\nTo check if a reference is present and does not contain a blank string in JavaScript reference the following code snippet:\n\n```javascript\n(options.override_text && options.override_text !== \"\") ? \"some-className\" : \"other-className\"\n```\n\nThe first part of the code snippet checks to see if there is a truthy value for `options.override_text`, if that Boolean expression is true the second part of the logical conjunction (&&) checks to make sure that if it is a string, that string is not blank. \n"},{"slug":"2022-verify-http-header-signature-in-rails","category":"blog","title":"Verify HTTP header signature in Rails","description":"How to use rails to verify a header signature","tags":["rails","http"],"body":"\nWhat follows is an example of how to verify a header signature using `OpenSSL::Digest` and `OpenSSL::HMAC`.\n\nIf you would like more information on signing HTTP requests, here is a [link](https://tools.ietf.org/id/draft-cavage-http-signatures-07.html) to the IETF documentation.\n\nIn this scenario a client will be sending an HTTP request header, signature, to our application. This header contains a SHA key we will have previously generated and sent to our client/integration partner. \n\nTo generate this key you will need three things:\n1. The hashing algorithm you want to use, in this case we use sha256.\n2. A key that will be used to sign the data. This should be something you can programatically access, probably a config value for the client that exists in the db. In this example we will use the hard coded string \"some_identifying_key_like_org_password\".\n3. The data being authenticated.\n\nGenerating the key:\n```ruby\ndigest = OpenSSL::Digest.new(\"sha256\")\nOpenSSL::HMAC.hexdigest(\n  digest,\n  \"some_identifying_key_like_org_password\",\n  \"the protected data\"\n)\n=> 5a7976b21f6fe4d0e0ac7d9a95511d0e53fe41a36e5d60bd43a2784428764248\n```\n\nAfter you've generated the key and sent it to your client you will need to handle the key verification in your controller. In the controller below we created a `before_action` to verify the signature. It will return an `:unauthorized` status unless the key you distributed to your client matches what you are expecting. \n\nThe `verify_signature` method handles the equality check, the `signed_request` method generates the key on the application side and the `header_signature` method gets the key from the request header.\n\n```ruby\ndef ApiController < ApplicationController\n  before_action :verify_signature\n  \n  def show\n    # would be called if verify_signature passes\n  end\n\n  def verify_signature\n    head :unauthorized unless signed_request == header_signature\n  end\n\n  def signed_request\n    digest = OpenSSL::Digest.new(\"sha256\")\n    OpenSSL::HMAC.hexdigest(\n      digest,\n      \"some_identifying_key_like_org_password\",\n      \"the protected data\"\n    )\n  end\n\n  def header_signature  \n    # the header would contain \"sha256 5a7976b21f6fe4d0e0ac7d9a95511d0e53fe41a36e5d60bd43a2784428764248\"\n    request.headers[:signature].gsub(\"sha256 \", \"\")\n  end\nend\n```\n\nFurther reading:\n- [When to use polymorphic associations in Rails](https://tinytechtuts.com/2022-when-to-use-polymorphic-associations-rails/)\n"},{"slug":"2022-vscode-new-window-mac","category":"blog","title":"Opening VScode in new window on Mac + shortcut","description":"new vscode window mac","tags":["vscode"],"body":"\nOnce you've installed VScode you will have access to the following command to open a new window:\n```\ncode -n .\n```\n\nIn order to create an alias for this command open your .bashrc or .zshrc or equivalent and create the alias:\n```\nalias code=\"code -n .\"\n```\n\nAfter restarting your terminal you could now be able to execute `code` to open a new window."},{"slug":"2022-when-to-use-fragment-over-div-react","category":"blog","title":"When to use <> vs <div> in React","description":"Using shorthand react fragments","tags":["react"],"body":"\nWhen building views for our applications we often need to group elements together and that means wrapping them in container elements. When writing HTML files you might be used to doing that using `<div>` as a defacto wrapper element, but in React there is the concept of a [Fragment](https://reactjs.org/docs/fragments.html#short-syntax). \n\nFragments are JSX nodes that allow you to group JSX nodes together without actually adding more elements to the DOM itself. Use fragments when you need to logically group elements together but do not need a parent element containing them. Use a parent element (like a `<div>`) if you need the containing element to exist.\n"},{"slug":"2022-when-to-use-polymorphic-associations-rails","category":"blog","title":"When to use polymorphic associations in Rails","description":"Rails polymorphic associations, when to use them","tags":["rails","active-record"],"body":"\nDeclaring a polymorphic association in your Rails application allows you to setup a single `belongs_to` association and then have as many models as needed resuse this interface. \n\nIf you did not setup a polymorphic relationship then each of the models would need to declare a separate `has_many` and `belongs_to` association and a new migration would need to be run each time you wanted to add a newly associated model.\n\nWith a polymorphic association setup you do not need to alter the database, you only have to provie the new model name as the `_type` and the records `_id` to the polymorphic model and then declare the `has_many` association on the new model and your new model will be working as expected.\n\nTo see an example of a polmoyphic association check out [How to handle token auth in Rails](https://tinytechtuts.com/2022-how-to-handle-token-auth-in-rails/).\n"},{"slug":"2022-when-to-use-react.fragment-vs-shorthand","category":"blog","title":"When to use <React.fragment /> vs <>","description":"Using <React.fragment /> vs <></>","tags":["react"],"body":"\nIn a [previous post](https://tinytechtuts.com/2022-when-to-use-fragment-over-div-react/) I reviewed when you should use a fragment instead of a standard HTML element when building React applications. In this post I want to review when you should use the longhand `<React.Fragment>` instead of the shorthand version `<>`.\n\n1. Use `<React.Fragment>` for when you need to map over a collection of fragments.\n\n```react\nfunction Listicle(props) {\n  const {items} = props\n\n  return (\n    <dl>\n      {items.map(item => (\n        <React.Fragment key={item.id}>\n          <dt>{item.name}</dt>\n          <dt>{item.content}</dt>\n        </React.Fragment>\n      ))}\n    </dl>\n  );\n}\n```\n\n2. Use the shorthand `<>` any other time.\n\n"},{"slug":"2022-why-did-your-html-selectbox-get-wider","category":"blog","title":"Why did your HTML select get wider","description":"html select wider with more text","tags":["html"],"body":"\nLet's imagine you have a select box with a few options in it built from this JSON document. The text for the select is the city, in this case Tulsa or Reno.\n\n```\n{\n  \"Oklahoma\": \"Tulsa\",\n  \"Nevada\": \"Reno\"\n}\n```\n\nUnless you hard coded the width of your select, the HTMl would never be wider than the width of the text \"Tulsa\". But if you added another option to the JSON document, eg:\n\n```\n{\n  \"Oklahoma\": \"Tulsa\",\n  \"Nevada\": \"Reno\",\n  \"California\": \"Bonadelle Ranchos-Madera Ranchos\"\n}\n```\n\nNow the select would be a lot wider, as wide as \"Bonadelle Ranchos-Madera Ranchos\". This is something to keep in mind as you're working on building out the HTML for your webpages. \n\nI haven't had to deal with preventing this from happening but if you're in that scenario one suggestion would be to try hard coding the width of the select and adding the css property `overflow: hidden` to prevent the long text from making the box wider than its default.\n\n"},{"slug":"2022-why-is-your-html-element-font-weight-not-updating","category":"blog","title":"Why is your HTML elements font weight not updating?","description":"troubleshooting html element font weight","tags":["html","active-record"],"body":"\nIf you're dealing with this issue currently, I'd just like to offer some moral support. You know that increasing the font-weight up to a value of 900 should adjust the way the font appears, but nothing seems to be happening, right? Chances are in this situation you did not include the font specifically for that font-weight. That's right, if you didn't know that (like I didn't when troubleshooting this on my own) you need to specify each font-weight you want to use for each of the fonts in your application.\n\nIn practice in a Ruby on Rails web application that meant adjusting where I was loading the font and adding the value of the desired font-weight, you will need something similar in your application where you load your font types.\n\n```\n= stylesheet_link_tag \"//fonts.googleapis.com/css?family=Roboto:500,400,300\", media: \"all\"\n```"},{"slug":"2022-wrap-third-party-libraries","category":"blog","title":"Wrap third party librarys in your application code","description":"why wrap third party libraries","body":"\nWhen building applications in 2021 we use a lot of third party libraries that have been built to handle common recurring development problems. \n\nCommon client libraries you might reach for:\n1. HTTP library for formatting and executing HTTP requests.\n2. ORM or object relational mapper for simplified common database interactions.\n3. Encryption libraries to make sure your data is safe.\n\nWhen using these libraries in your application it is a good practice to wrap them as an interface to your application code (usually a class or module depending on the programming language or paradigm), that way when you need to add a new required header to an HTTP client (or some other unforseen update) all you need to do is change the code that the HTTP client is wrapped in and not add the new header to 100 different references to the third party HTTP client library.\n\nHere's an example implementation in ruby:\n```ruby\nclass HttpClient\n  def http\n    HTTP[\n      \"Authorization\": \"Bearer #{token}\",\n      accept: \"application/json\",\n      content_type: \"application/json\"\n    ]\n  end\n\n  def host_url\n    \"https://api.data.com\"\n  end\n\n  def token\n    # interfact to get access token\n  end\n\n  def get(path, params = nil)\n    JSON.parse(http.get(\"#{host_url}#{path}\", params: params))\n  end\n\n  def post(path, json)\n    response = http.post(\"#{host_url}#{path}\", json: json)\n\n    results(response)\n  end\n\n  def put(path, json)\n    response = http.put(\"#{host_url}#{path}\", json: json)\n\n    results(response)\n  end\n\n  def patch(path, json)\n    response = http.patch(\"#{host_url}#{path}\", json: json)\n\n    results(response)\n  end\nend\n```"},{"slug":"2023-create-db-record-ecto","category":"blog","title":"Create a new DB record using Ecto","description":"elixirs ecto library for db record inserts","tags":["elixir","ecto"],"body":"\nWhen using Ecto modules for your database adapter one of the first things you will want to learn how to do is insert records into your database. Typically if you're going to be inserting records from user input you will want to run those fields through an `Ecto.Changeset` but if you're just trying to test out insert functionality you can create an `Ecto.Schema` struct and then commit the insert using `Ecto.Repo` like so:\n```\niex(3)> o = Barks.Repo.get(Barks.Organization, \"733a7583-1a79-4c8d-b800-6a9a1513f80f\")\niex(4)> t = %Barks.Team{name: \"ddd\", organization: o}\niex(5)> Barks.Repo.insert(t)\n```\n\nSimilar posts:\n- [Retroactively add timestamps to an Ecto project](https://tinytechtuts.com/2021-retroactively-add-timestamps-in-phoenix-ecto/)\n"},{"slug":"2023-create-sidebar-ad-adsense","category":"blog","title":"Create sidebar ad using Google Adsense","description":"create a sidebar ad adsense","tags":["adsense"],"body":"\nThis post is a tutorial on creating a sidebar/siderail ad for a content website where you manage the code. I am using Astro as a SSG, for context, but the tutorial should apply to all static websites that want to run sidebar ads.\n\nTo accomplish this take the following actions:\n1. Create an ad unit in adsense management console\n2. Copy the script code \n3. Create the html element your ad will exist within\n\n## Create an ad unit in adsense management console\n\n After logging in to Google Adsense click on Ads in the left side nav.\n\nIn the navigation bar click By ad unit.\n\nClick Display ads.\n\nCreate a name for the ad unit, make sure responsive is selected. I found that \"Square, Horizontal, Vertical\" selections don't indicate which type of format the ad will be, but rather show what the ad unit will look like depending on how it is rendered, so no selection is needed there.\n\nClick create.\n\n<img src=\"/images/posts/adsense-by-ad-unit.png\" alt=\"adsense\">\n\n## Copy the script code\nAfter clicking create the ad code should pop up. Copy that and store if for later use.\n\n## Create the html element your ad will exist within\n\nIn the code below note the `style` attribute on the `ins` element, it contains the styling I used for this ad. Sidebar ads are longer than they are tall. Be sure to make the dimensions large enough so the ad has a place to render, otherwise you will receive an error.\n\nIf you receive the error `adsbygoogle is not defined` that means the Google Syndication script (the first script in the code) never loaded.\n\n```\n  <div>\n    <!-- sidebar vertical -->\n    <script src=\"https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-1123456789\"\n    crossorigin=\"anonymous\"></script>\n    <ins class=\"adsbygoogle\"\n        style=\"position: absolute; right: 50px; top: 200px; width: 300px; height: 1000px;\"\n        data-ad-client=\"ca-pub-1123456789\"\n        data-ad-slot=\"198347239\"\n        data-ad-format=\"auto\"\n        data-full-width-responsive=\"true\"></ins>\n    <script>\n        (adsbygoogle = window.adsbygoogle || []).push({});\n    </script>\n  </div>\n```\n\n"},{"slug":"2023-ecto-associations-with-uuids","category":"blog","title":"How to handle Ecto associations with UUIDs","description":"properly define ecto associations with uuids","tags":["elixir","ecto"],"body":"\nOverriding default database configurations can be tricky business and that's no exception when trying to go from using `id` for primary keys to using `UUID`. In a previous post I went over how to set [different primary keys](https://tinytechtuts.com/2023-set-primary-key-ecto/) in Ecto, which setup our app to use UUID's at the database level. \n\nNow we'll be working to make this function at the app level, and it only requires a few changes to our schema files. This example will use a standard `has_many` and `belongs_to` association, piggy backing off of the previously mentioned [post](https://tinytechtuts.com/2023-set-primary-key-ecto/).\n\nIn both the `has_many` and `belongs_to` side of the association the setup is going to look the same. It takes the format of `association_function: :ecto_schema, EctoSchemaModule, references :field_name`.\n\nFor the has many side that looks like this:\n```\ndefmodule Barks.Organization do\n  use Ecto.Schema\n  alias Barks.Team\n\n  @primary_key {:uuid, :binary_id, autogenerate: true}\n  @foreign_key_type :binary_id\n  schema \"organizations\" do\n    field :name, :string\n    has_many :teams, Team, references: :uuid\n  end\nend\n```\n\nAnd for the belongs_to side of the assocation that looks like:\n```\ndefmodule Barks.Team do\n  use Ecto.Schema\n  alias Barks.Organization\n\n  @primary_key {:uuid, :binary_id, autogenerate: true}\n  @foreign_key_type :binary_id\n  schema \"teams\" do\n    field :name, :string\n    belongs_to :organization, Organization, references: :uuid\n  end\nend\n```\n\nSimilar posts:\n- [invalid_foreign_key - no unique constraint](https://tinytechtuts.com/2023-invalid_foreign_key-no-unique-constraint/)\n"},{"slug":"2023-ecto-trigger-update-without-changeset","category":"blog","title":"Ecto: trigger update without changeset","description":"ecto db trigger update without changeset","tags":["elixir","ecto"],"body":"\nIf you need to trigger a database update for a specific table without committing an update to any of the other columns you can do so with\n\n```\n    Repo.update(my_ecto_schema_context, force: true)\n```\n\nThe `force: true` option in the above code snippet tells Ecto to trigger the write to update the tables `updated_at` column in my circumstance. It does this without needing to update any of the other columns.\n\nOne reason you might need to do this is to handle wanting an update to the table in question when another table completes a successful transaction.\n\n"},{"slug":"2023-fix-html-encodings-for-apostrophes","category":"blog","title":"Apostrophes showing as â€™ in html","description":"fix html encodings where apostrophes are not displaying correctly","tags":["html","utf"],"body":"\nIf you're building a webpage and you're seeing characters like `â€™` when you expect to see `'`, there is a good chance you are not using the correct charset for `'`. In this situation you likely want to be using `UTF-8`. \n\nIn an expanded example lets say you have this sentence you're trying to render as HTML text:\n\n```\nIt's the dog's day.\n```\n\nBut after rendering you're seeing this on the page:\n\n```\nItâ€™s the dogâ€™s day.\n```\n\nIn this case try adding a `<meta>` tag with the `charset` property to your markup as a child node to the `<head>` tag.\n\n```\n<html lang=\"en\">\n  <head>\n    <meta charset=\"UTF-8\" />\n    .....\n```\n\n\n"},{"slug":"2023-invalid-association-does-not-have-field-id","category":"blog","title":"Invalid association: associated schema does not have field :id","description":"fix invalid association ecto","tags":["elixir","ecto"],"body":"\nWhen I came across this error it read in full:\n```\ninvalid association `organization` in schema Barks.Team: associated schema Barks.Organization does not have field `id` \n```\n\nThis was because I hadn't updated what the new reference should be in my `belongs_to` association after I switched from [id to uuid](https://tinytechtuts.com/2023-set-primary-key-ecto/) for database primary keys.\n\nMy `belongs_to` declaration looked like the below when it was erroing:\n```\nbelongs_to :organization, Organization\n```\n\nBut what I need was to explicitly call out the reference:\n```\nbelongs_to :organization, Organization, references: :uuid\n```\n\nSimilar posts:\n- [How to handle Ecto associations with UUIDs](https://tinytechtuts.com/2023-ecto-associations-with-uuids/)\n"},{"slug":"2023-invalid_foreign_key-no-unique-constraint","category":"blog","title":"invalid_foreign_key - no unique constraint matching given keys for referenced table","description":"learn to override default primary keys ecto","tags":["ecto","elixir"],"body":"\nI encountered this error when trying to set associations for two related schemas. The error turned out to be an issue with how I set the created the original tables.\n\nMy initial table configuration looked like the below. I had used the `primary_key` keyword option when defining the field that was going to take the place of the default primary key, but I had missed the fact that I also needed to use that same keyword option when defining the table (though with a different value).\n\nThis is what I had written before:\n```\ndef change do\n  create table(\"organizations\") do\n    add :name, :string\n    add :logo, :string\n    add :subdomain, :string\n    add :uuid, :binary_id, primary_key: :true\n  end\nend\n```\n\nAfter rollback this migration with `mix ecto.rollback`, this is what fixed the error. Notice the `table` function now includes `primary_key: :false`.\n```\n  create table(\"organizations\", primary_key: :false) do\n    add :name, :string\n    add :logo, :string\n    add :subdomain, :string\n    add :uuid, :binary_id, primary_key: :true\n  end\n```\n\nSimilar posts:\n- [How to set a primary key using Ecto](https://tinytechtuts.com/2023-set-primary-key-ecto/)\n"},{"slug":"2023-push-to-github-pages-using-personal-access-token","category":"blog","title":"How to push to Github Pages using a personal access token","description":"using a personal access token to push to github pages","tags":["git","github","tokens"],"body":"\n<h2>Step 1: Generate a Personal Access Token</h2>\n-Navigate to the GitHub Settings page.\n<br>\n- Select \"Developer settings\" from the left sidebar.\n<br>\n- Click on \"Personal access tokens.\"\n<br>\n- *Important* when generating make sure you use the Tokens Classic token and not the Fine-grained one in this tutorial\n<br>\n- Click \"Generate token\" and provide a note, and select the scopes you want the token to have access to. In my case I selected `repo` which gave full access to the repository.\n<br>\n- Copy the generated token. Keep this private.\n\n<h2>Step 2: Add the origin with your token structure</h2>\nIf you currently have a remote origin set for the repository you're using make sure you remove it using the following command:\n\n```\ngit remote remove origin\n```\n\n<h2>Step 3: Add the origin with your token example</h2>\nAnd then using your newly generated access token run the next command:\n\n```\ngit remote add origin https://<your_token_here@github.com/yourgithubusername/yourgithubusername.github.io.git\n```\nIn practice that would look something like the below:\n\n```\ngit remote add origin https://ghp_1RKguuSgjhddjkhreBGB7hSMT0ddd3A@github.com/scadoo2/scadoo2.github.io.git\n```\n\n<h2>Step 4: Try using the token</h2>\nFrom there you can make updates to your repository like pushing to the main branch, try pushing a new commit using the command:\n\n```\ngit push origin main\n```\n"},{"slug":"2023-set-primary-key-ecto","category":"blog","title":"How to set a primary key using Ecto","description":"learn to override default primary keys ecto","tags":["elixir","ecto"],"body":"\nI had some trouble getting this right and the information across the internet had varrying strategies that often didn't include all of the details needed to get this right so hopefully this is the answer you're looking for. In this example I use the primary key `:uuid`.\n\nTo start generate your migration file with `mix ecto.gen.migration organizations`. From there you will need to include two `primary_key` keyword list options. The first in the `table` function and the second in the `field` function. Example setup:\n\n```\ndef change do\n  create table(\"organizations\", primary_key: :false) do\n    add :name, :string\n    add :uuid, :binary_id, primary_key: :true\n  end\nend\n```\n\nAnd then in your schema file at `lib/organization.ex` you will set the schema struct and use the module attributes `@primary_key` and `@foreign_key_type` to set the new primary key and foreign key (if needed) data.\n```\n@primary_key {:uuid, :binary_id, autogenerate: true}\n@foreign_key_type :binary_id\nschema \"organizations\" do\n  field :name, :string\nend\n```\n\nSimilar posts:\n- [Create a new DB record using Ecto](https://tinytechtuts.com/2023-create-db-record-ecto/)\n"},{"slug":"2023-visualizing-db-schema-ecto","category":"blog","title":"Visualize Database Schema Using Ecto","description":"print schema in ecto","tags":["elixir","ecto"],"body":"\nIt was hard for me find a way to create a db schema to visualize my apps tables and columns in Ecto. I was looking for something similar to rails `schema.rb`, but everything that came up discussed `Ecto.Schema`. If somehow you ended up here looking for an answer to the problem just mentioned you can use the mix task `ecto.dump` to accomplish this.\n\n```\nmix ecto.dump\n```\n\nThis will generate a `structure.sql` file containing the structure of your database in `priv/repo`\n\nSimilar posts:\n- [How to handle Ecto associations with UUIDs](https://tinytechtuts.com/2023-ecto-associations-with-uuids/)\n"},{"slug":"capitalize-first-letter-of-each-word-in-a-string-elixir","category":"blog","title":"Capitalize the first letter of each word in an Elixir string","description":"Capitalize the first letter of each word in an Elixir string","tags":["elixir"],"body":"\nLooking to capitalize the first letter of each word in an Elixir string? Let's take a look at an example using Elixir's String module.\n\nelixir\nCopy code\noriginal_string = \"capitalize the first letter\"\ncapitalized_string = original_string |> String.split(~r/\\s+/) |> Enum.map(&String.capitalize/1) |> Enum.join(\" \")\n\nThis is how it works:\n\n`String.split(~r/\\s+/)`: Splits the original string into words using a regular expression to identify spaces.\n`Enum.map(&String.capitalize/1)`: Applies String.capitalize/1 to each word, ensuring the first letter is capitalized.\n`Enum.join(\" \")`: Combines the capitalized words into a final string with spaces.\n\nBy using these functions, you can transform \"capitalize the first letter\" into \"Capitalize The First Letter\" pretty easily."},{"slug":"configure-private-email.com-in-a-web-application","category":"blog","title":"How to configure privateemail.com smpt connections","description":"learn to configure privateemail.com in a web application","tags":["smtp"],"body":"\nThe domain name provider (amongst other services), Namecheap, offers an email service through privateemail.com. It's a cost effective email provider that easily maps to whichever domain name you've registered with Namecheap. \n\nI had a need to send emails through the privatemeail.com smtp server in a Ruby on Rails web application I built. It took me some time to find the correct configuration to make this work, you can find that below:\n\n```\n  config.action_mailer.smtp_settings = {\n    address: \"mail.privateemail.com\",\n    port: 587,\n    domain: 'barksalot.com',\n    user_name: 'jack@barksalot.com’,\n    password: 'password',\n    authentication: 'plain',\n    enable_starttls: true\n  }\n```w\n\nFor your case the values `address`, `port`, `authentication`, and `enable_starttls` in the settings hash should be the same as mine. The `enable_starttls` is for the security requirement that privateemail.com has. You will need to update the values for `domain`, `password`, and `user_name`.\n\nI first tested the connection to the service in my `development.rb` file, this where you set your applications configuration for your development environment. I only set it here temporarily to test the connection. Typically you will want to use a third party gem like mailhog to catch your smtp requests and not actually send the emails, at least after you verifying everything is working the way you expect.\n\nAfter testing I was able to move this configuration to my `production.rb` configuration file to be used in my applications live environment. \n\nI hope this helped! Have a good one!"},{"slug":"convert-elixir-string-with-hyphens-to-string-with-spaces","category":"blog","title":"Convert elixir string with spaces to string with hyphens","description":"convert elixir string with spaces to string with hyphens","tags":["elixir"],"body":"\nIn a [previous tutorial](https://tinytechtuts.com/convert-elixir-string-with-spaces-to-string-with-hyphens/) I needed help converting an Elixir string with spaces to a string with hyphens and then downcasing the string. I figured I make another brief tut doing the opposite, converting a string with hyphens back to a string with spaces as a handy utility.\n\n```\n=> \"elixir-string-with-hyphens\" |> String.replace(\"-\", \" \")\n\n\"elixir string with hyphens\"\n```\n\nIf you need to downcase it for uniformity you can pipe it to `String.downcase/1` as well:\n\n```\n=> \"Elixir-String-with-Hyphens\" |> String.replace(\"-\", \" \") |> String.downcase()\n\n\"elixir string with hyphens\"\n```\n\nI hope this helped! Have a good one!\n\nCheck out another post:\n[ELIXIR ENUM.MAP/2 VS RUBY ARRAY#MAP](https://tinytechtuts.com/elixir-enum-map-vs-ruby-array-map/)\n"},{"slug":"convert-elixir-string-with-spaces-to-string-with-hyphens","category":"blog","title":"Convert elixir string with spaces to string with hyphens","description":"convert elixir string with spaces to string with hyphens","tags":["elixir"],"body":"\nI needed help converting an Elixir string with spaces to a string with hyphens and lowercase. I eventually found a winning example using the String.replace/3 and String.downcase/1 functions. Here's an example:\n\n```\n=> converted_string = \"Elixir string to hyphens\" |> String.replace(~r/\\s+/, \"-\") |> String.downcase()\n\n\"elixir-string-to-hyphens\"\n```\n\nIn this example:\n\n`String.replace(~r/\\s+/, \"-\")`: Replaces spaces with hyphens using a regular expression.\n`String.downcase()`: Converts the string to lowercase.\n\nThe resulting converted_string will be:\n```\"elixir-string-to-hyphens\"```\n\n\nI hope this helped! Have a good one!\n\nCheck out another post:\n[CREATE AND SET THE INNERTEXT FOR IN JAVASCRIPT FOR OPTION ELEMENT](https://tinytechtuts.com/create-and-set-inner-text-for-option-element-in-javascript/)\n"},{"slug":"create-and-set-inner-text-for-option-element-in-javascript","category":"blog","title":"Create and set the innerText for in JavaScript for option element","description":"Set the innerText for in JavaScript for option element","tags":["javascript","option"],"body":"\nThis is a quick code snippet post for someone having the same experience I did, which was \"why in the hecking heck can't I get this simple javascript action to work\". Lucky for you I finally got it.\n\n```\nlet exportBookmarksTeamOption = document.createElement(\"option\");\nexportBookmarksTeamOption.setAttribute(\"id\", user.team.id);\nexportBookmarksTeamOption.innerText = user.team.name;\n```\n\nIn the above code snippet I first create the option element, then add an id to it using the `setAttribute` function and finally set the `innerText` attribute. \n\nI hope this helped! Have a good one!"},{"slug":"ecto-save-nested-records-example","category":"blog","title":"Ecto: Save nested records example","description":"Using elixir ecto learn to save nested records by example","tags":["elixir"],"body":"\n\nTo start this tut let me introduce the Parent and Child schemas, engaged in a standard one-to-many relationship:\n\n```\ndefmodule MyApp.Parent do\n  use Ecto.Schema\n\n  schema \"parents\" do\n    field :name, :string\n    has_many :children, MyApp.Child\n  end\nend\n\ndefmodule MyApp.Child do\n  use Ecto.Schema\n\n  schema \"children\" do\n    field :name, :string\n    belongs_to :parent, MyApp.Parent\n  end\nend\n```\n\nThe crux lies in the changesets. Here are the structured changesets for both the parent and child records:\n\n```\ndefmodule MyApp.Parent do\n  # ...\n\n  def changeset(parent, attrs \\\\ %{}) do\n    parent\n    |> cast(attrs, [:name])\n    |> validate_required([:name])\n    |> cast_assoc(:children, with: &MyApp.Child.changeset/2)\n  end\nend\n\ndefmodule MyApp.Child do\n  # ...\n\n  def changeset(child, attrs \\\\ %{}) do\n    child\n    |> cast(attrs, [:name])\n    |> validate_required([:name])\n  end\nend\n```\n\nNow, let's navigate the process of creating and inserting records:\n\n```\nparent_attrs = %{name: \"Parent Name\", children: [%{name: \"Child 1\"}, %{name: \"Child 2\"}]}\n\nchangeset = MyApp.Parent.changeset(%MyApp.Parent{}, parent_attrs)\ncase MyApp.Repo.insert(changeset) do\n  {:ok, parent} ->\n    # Insertion successful\n  {:error, changeset} ->\n    # Handle errors\nend\n```\n\nThis example assumes the creation of a new parent with associated child records.\n\nFor those inclined towards updating existing records, the process is straightforward. Retrieve the parent, apply the updated attributes, and execute the update:\n\n```\nparent = MyApp.Repo.get!(MyApp.Parent, parent_id)\nupdated_attrs = %{name: \"Updated Parent Name\", children: [%{id: 1, name: \"Updated Child 1\"}, %{name: \"New Child\"}]}\n\nchangeset = MyApp.Parent.changeset(parent, updated_attrs)\ncase MyApp.Repo.update(changeset) do\n  {:ok, updated_parent} ->\n    # Update successful\n  {:error, changeset} ->\n    # Handle errors\nend\n```\n\nEnsure to provide the id for existing child records for the update to succeed.\n\nI hope this helped! Have a good one!\n\nCheck out another post:\n[ELIXIR ENUM.MAP/2 VS RUBY ARRAY#MAP](https://tinytechtuts.com/elixir-enum-map-vs-ruby-array-map/)\n"},{"slug":"elixir-enum-map-vs-ruby-array-map","category":"blog","title":"Elixir Enum.map/2 vs Ruby Array#map","description":"Elixir Enum.map/2 vs Ruby Array#map","tags":["elixir","ruby"],"body":"\nElixir's Enum.map and Ruby's Array#map are methods that help you transform each element in a collection. In Elixir, the Enum.map function, exists within the Enum module. It is designed for working with enumerable data structures. To use it provide an enumerable, such as a `List`, and a function to be applied to each element. For example:\n\n```\nnumbers = [1, 2, 3, 4, 5]\nresult = Enum.map(numbers, &(&1 * 2))\nIO.inspect(result)  # Output: [2, 4, 6, 8, 10]\nIn this Elixir example, Enum.map doubles each element in the numbers list, showcasing its simplicity and expressiveness.\n```\n\nOn the Ruby side, the Array#map method offers a similar functionality. Operating directly on the array itselfs, it transforms each element based on the provided block or proc. Here's a Ruby example:\n\n```\nnumbers = [1, 2, 3, 4, 5]\nresult = numbers.map { |n| n * 2 }\nputs result  # Output: [2, 4, 6, 8, 10]\n```\n\nIn this Ruby snippet, Array#map achieves the same doubling operation on each element of the numbers array. \n\nI hope this helped! Have a good one!\n\nCheck out another post:\n- [GET A COUNT OF ALL .MD FILES IN A DIRECTORY ON THE COMMAND LINE](https://tinytechtuts.com/get-page-count-on-command-line-md/)\n\n"},{"slug":"fix-github-pages-builds-for-astro-applications","category":"blog","title":"Github Pages builds for Astro applications not working","description":"fix github pages builds for astro applications","tags":["astro","github-pages"],"body":"\nI continuously received build errors from Github Pages when trying to deploy an Astro application I was working on (aka this website). \n\nIt turns out that Github Pages expects by default that your static site application is going to be a Jekyll application and so it will try to build it as a Jekyll application unless you explicitly tell it not to.\n\nFortunately for myself (and hopefully you as well) the fix was straightforward. \n\nAt the root of your codebase add the following dotfile, `.nojekyll`. You can leave the contents of the file empty, the only thing github pages looks for is the existence of that file in order to skip the Jekyll build process.\n\nI hope this helped you! Have a nice rest of your day!"},{"slug":"get-page-count-on-command-line-md","category":"blog","title":"Get a count of all .md files in a directory on the command line","description":"Get a count of all .md files on the command line","tags":["shell","script"],"body":"\nIn building my Astro website I wanted to know how many posts I had published to my webiste. I thought about finding a way to do this in the UI so I could just go to a certain page and visualize the post count there, but I found a simple command line script that gets the job done just fine for my purpose.\n\n```\nls -l src/pages | grep -c '\\.md'\n```\n\nThe above script will return a count of all files with the `.md` file extension in the `src/pages` directory, which is where all of my posts are stored. This could be done for any type of file extension you want to use.\n\n```\n=> ls -l src/pages | grep -c '\\.md'\n252\n```\n\nI hope this helped! Have a good one!\n\nCheck out another post:\n- [How to handle Ecto associations with UUIDs](https://tinytechtuts.com/2023-ecto-associations-with-uuids/)\n"},{"slug":"how-to-exclude-301-redirects-from-an-astro-website","category":"blog","title":"How to exclude astro redirects from sitemap.xml build","description":"How to exclude astro redirects from sitemap.xml build","tags":["astro","builds"],"body":"\nI am working on migrating a project to a different web domain, this one you're on in fact.\n\nTo do that I needed to setup redirects from URLs that point to the old domain to urls that pointed to the new domain. \n\nI'm using Astro for my website, setting up my redirects was done inside a file called `astro.config.mjs`, which is your astro configuration file.\n\nThe contents of that file in my instance included the use of the `defineConfig` function and `sitemap` function, which is used as an `integration` config list item. The `sitemap` function will run by default every time you use the command line `npx astro build`. If you define `redirects` like I did in my below config they will be included in your sitemap that is generated.\n\n```\nimport { defineConfig } from \"astro/config\";\nimport sitemap from \"@astrojs/sitemap\";\n\n// https://astro.build/config\nexport default defineConfig({\n  integrations: [sitemap()],\n  site: \"https://devdecks.io\",\n  redirects: {\n    '/2021-elixir-list-to-comma-separated-string': {\n      status: 301,\n      destination: 'https://tinytechtuts.com/2021-elixir-list-to-comma-separated-string'\n    },\n    '/2021-same-db-table-parent-child-relationship-rails': {\n      status: 301,\n      destination: 'https://tinytechtuts.com/2021-same-db-table-parent-child-relationship-rails'\n    }\n  }\n})\n```\n\nI didn't want those included in my sitemap, so I found a way to filter for only the urls I want included in the Astro sitemap. In the below you'll see the call to `sitemap` now filters for only the two specified urls in the condition. The filter option will run for every url in both your redirects and pages. \n\n\n```\nimport { defineConfig } from \"astro/config\";\nimport sitemap from \"@astrojs/sitemap\";\n\n// https://astro.build/config\nexport default defineConfig({\n  integrations: [sitemap({\n    filter: (page) => page == 'https://tinytechtuts.com/tiny-tech-tuts/' || page == 'https://tinytechtuts.com/', \n  })],\n  site: \"https://devdecks.io\",\n  redirects: {\n    '/2021-elixir-list-to-comma-separated-string': {\n      status: 301,\n      destination: 'https://tinytechtuts.com/2021-elixir-list-to-comma-separated-string/'\n    },\n    '/2021-same-db-table-parent-child-relationship-rails': {\n      status: 301,\n      destination: 'https://tinytechtuts.com/2021-same-db-table-parent-child-relationship-rails/'\n    }\n  }\n})\n```\n\nI hope this helped! Have a good one!"},{"slug":"transform-elixir-string-camelCase-to-snake_case","category":"blog","title":"Transform an Elixir string from CamelCase to snake_case","description":"Transform an Elixir string from CamelCase to snake_case","tags":["elixir"],"body":"\nOne common scenario you might encounter in Elixir programming is the need to transform strings from CamelCase to Snake_Case. This conversion is preferred in order to align with Elixir's naming convention and enhance code clarity.\n\nCamelCase strings, where words are concatenated without spaces and each word begins with a capital letter, can be prevalent in certain contexts. To bring uniformity to your code, it's often beneficial to convert these CamelCase strings to Snake_Case, where words are separated by underscores and all letters are in lowercase.\n\nThe transformation process involves breaking down the CamelCase string into individual words, converting each word to lowercase, and then joining them with underscores. In Elixir, the String module provides convenient functions to facilitate this conversion seamlessly.\n\nConsider the following example:\n\n```\ncamel_case_string = \"theTestString\"\nsnake_case_string = String.split(camel_case_string, ~r/([A-Z])/)\n  |> Enum.map(&String.downcase/1)\n  |> Enum.join(\"_\")\n```\n\nThis snippet demonstrates how to convert a CamelCase string to Snake_Case using Elixir's String module. By incorporating this transformation into your coding practices, you contribute to a more standardized and comprehensible Elixir codebase, ultimately fostering better collaboration and code maintainability.\n\nI hope this helped! Have a good one!\n\nCheck out another post:\n[ECTO: SAVE NESTED RECORDS EXAMPLE](https://tinytechtuts.com/ecto-save-nested-records-example/)"}]